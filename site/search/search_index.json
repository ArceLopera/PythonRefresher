{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Python Refresher Everyone can forget about grammar and vocabulary. The most important think is to know where to look. Basic Topics Advanced Topics Basics Useful Modules Data Structures Machine Learning Functions Algorithms Classes Exercises","title":"Home"},{"location":"#welcome-to-python-refresher","text":"Everyone can forget about grammar and vocabulary. The most important think is to know where to look. Basic Topics Advanced Topics Basics Useful Modules Data Structures Machine Learning Functions Algorithms Classes Exercises","title":"Welcome to Python Refresher"},{"location":"pythonRefresh/","text":"Python is strongly typed (i.e. types are enforced), dynamically, implicitly typed (i.e. you don\u2019t have to declare variables), case sensitive (i.e. var and VAR are two different variables) and object-oriented (i.e. everything is an object, Like C# and Java). A unique aspect of the Python language: indentation. While a language like C uses curly braces to contain code statements within loops or conditionals, Python indicates these statements through indentation. This feature lends Python code readability. Notice the colon at the end of the expression in the for, while and if statement. Python Resources Free e-book Python Like You Mean It , by Ryan Soklaski, will provide a more comprehensive introduction to Python for scientific computing. The website http://www.python.org , Tutorial and doc","title":"General"},{"location":"pythonRefresh/#python-resources","text":"Free e-book Python Like You Mean It , by Ryan Soklaski, will provide a more comprehensive introduction to Python for scientific computing. The website http://www.python.org , Tutorial and doc","title":"Python Resources"},{"location":"Algo/pyGen/","text":"Useful Algorithms Divide and Conquer Transform and Conquer Dynamic Programming Sorting Algorithms Searching Algorithms Array Algorithms Graph Algorithms Other Algorithms Greedy Algorithms Strategies Patterns","title":"General"},{"location":"Cls/pyAbsCls/","text":"An abstract class can be considered as a blueprint for other classes. It allows you to create a set of methods that must be created within any child classes built from the abstract class. A class which contains one or more abstract methods is called an abstract class. An abstract method is a method that has a declaration but does not have an implementation. While we are designing large functional units we use an abstract class. When we want to provide a common interface for different implementations of a component, we use an abstract class. Why use Abstract Base Classes : By defining an abstract base class, you can define a common Application Program Interface(API) for a set of subclasses. This capability is especially useful in situations where a third-party is going to provide implementations, such as with plugins, but can also help you when working in a large team or with a large code-base where keeping all classes in your mind is difficult or not possible. How Abstract Base classes work: By default, Python does not provide abstract classes. Python comes with a module that provides the base for defining Abstract Base classes(ABC) and that module name is ABC. ABC works by decorating methods of the base class as abstract and then registering concrete classes as implementations of the abstract base. A method becomes abstract when decorated with the keyword @abstractmethod. # Using Abstract Base Classes to enforce class constraints from abc import ABC , abstractmethod class GraphicShape ( ABC ): # Inheriting from ABC indicates that this is an abstract base class def __init__ ( self ): super () . __init__ () # declaring a method as abstract requires a subclass to implement it @abstractmethod def calcArea ( self ): pass class Circle ( GraphicShape ): def __init__ ( self , radius ): self . radius = radius def calcArea ( self ): return 3.14 * ( self . radius ** 2 ) class Square ( GraphicShape ): def __init__ ( self , side ): self . side = side def calcArea ( self ): return self . side * self . side # Abstract classes can't be instantiated themselves # g = GraphicShape() # this will error c = Circle ( 10 ) print ( c . calcArea ()) s = Square ( 12 ) print ( s . calcArea ()) 314.0 144","title":"Abstract Classes"},{"location":"Cls/pyClsStaMet/","text":"Methods of objects we've looked at so far are called by an instance of a class, which is then passed to the self parameter of the method. Class methods are different - they are called by a class, which is passed to the cls parameter of the method. A common use of these are factory methods, which instantiate an instance of a class, using different parameters than those usually passed to the class constructor. Class methods are marked with a classmethod decorator. Technically, the parameters self and cls are just conventions; they could be changed to anything else. However, they are universally followed, so it is wise to stick to using them. Static methods behave like plain functions, except for the fact that you can call them from an instance of the class. class Rectangle : def __init__ ( self , w , h ): self . w = w self . h = h def area ( self ): return self . w * self . h @classmethod def new_square ( cls , side_length ): return cls ( side_length , side_length ) @staticmethod def spam ( x ): print ( \"Spam and eggs\" + x ) square = Rectangle . new_square ( 5 ) print ( square . area ()) Rectangle . spam ( \" and Ham\" ) 25 Spam and eggs and Ham Class method vs Static Method A class method takes cls as the first parameter while a static method needs no specific parameters. A class method can access or modify the class state while a static method can\u2019t access or modify it. In general, static methods know nothing about the class state. They are utility-type methods that take some parameters and work upon those parameters. On the other hand class methods must have class as a parameter. We use @classmethod decorator in python to create a class method and we use @staticmethod decorator to create a static method in python. When to use what? We generally use class method to create factory methods. Factory methods return class objects ( similar to a constructor ) for different use cases. We generally use static methods to create utility functions. # Python program to demonstrate # use of class method and static method. from datetime import date class Person : def __init__ ( self , name , age ): self . name = name self . age = age # a class method to create a Person object by birth year. @classmethod def fromBirthYear ( cls , name , year ): return cls ( name , date . today () . year - year ) # a static method to check if a Person is adult or not. @staticmethod def isAdult ( age ): return age > 18 person1 = Person ( 'mayank' , 21 ) person2 = Person . fromBirthYear ( 'mayank' , 1996 ) print ( person1 . age ) print ( person2 . age ) # print the result print ( Person . isAdult ( 22 )) 21 25 True","title":"Class & Static Methods"},{"location":"Cls/pyConstructor/","text":"The init method is the constructor. All methods must have self as their first parameter, although it isn't explicitly passed, Python adds the self argument to the list for you; you do not need to include it when you call the methods. Within a method definition, self refers to the instance calling the method. Classes can have other methods defined to add functionality to them. Remember, that all methods must have self as their first parameter. Classes can also have class attributes, created by assigning variables within the body of the class. These can be accessed either from instances of the class, or the class itself. Class attributes are shared by all instances of the class. Trying to access an attribute of an instance that isn't defined causes an AttributeError. This also applies when you call an undefined method. class Dog : legs = 4 def __init__ ( self , name , color ): self . name = name self . color = color def bark ( self ): print ( \"WooF!\" ) fido = Dog ( \"Fido\" , \"Brown\" ) print ( fido . legs ) fido . bark () print ( Dog . legs ) 4 WooF! 4 Polymorphism Python does not support explicit multiple constructors, yet there are some ways in which using the multiple constructors can be achieved. If multiple init methods are written for the same class, then the latest one overwrites all the previous constructors. The class constructors can be made to exhibit polymorphism in three ways which are listed below. Overloading constructors based on arguments. Calling methods from init . Using @classmethod decorator. With python3, you can use Implementing Multiple Dispatch with Function Annotations as Python Cookbook Overloading constructors based on arguments class sample : # constructor overloading based on args def __init__ ( self , * args ): # if args are more than 1 # sum of args if len ( args ) > 1 : self . ans = 0 for i in args : self . ans += i # if arg is an integer # square the arg elif isinstance ( args [ 0 ], int ): self . ans = args [ 0 ] * args [ 0 ] # if arg is string # Print with hello elif isinstance ( args [ 0 ], str ): self . ans = \"Hello! \" + args [ 0 ] + \".\" s1 = sample ( 1 , 2 , 3 , 4 , 5 ) print ( \"Sum of list :\" , s1 . ans ) s2 = sample ( 5 ) print ( \"Square of int :\" , s2 . ans ) s3 = sample ( \"PolloPitas\" ) print ( \"String :\" , s3 . ans ) Sum of list : 15 Square of int : 25 String : Hello! PolloPitas. Calling methods from init class eval_equations : # single constructor to call other methods def __init__ ( self , * inp ): # when 2 arguments are passed if len ( inp ) == 2 : self . ans = self . eq2 ( inp ) # when 3 arguments are passed elif len ( inp ) == 3 : self . ans = self . eq1 ( inp ) # when more than 3 arguments are passed else : self . ans = self . eq3 ( inp ) def eq1 ( self , args ): x = ( args [ 0 ] * args [ 0 ]) + ( args [ 1 ] * args [ 1 ]) - args [ 2 ] return x def eq2 ( self , args ): y = ( args [ 0 ] * args [ 0 ]) - ( args [ 1 ] * args [ 1 ]) return y def eq3 ( self , args ): temp = 0 for i in range ( 0 , len ( args )): temp += args [ i ] * args [ i ] temp = temp / max ( args ) z = temp return z inp1 = eval_equations ( 1 , 2 ) inp2 = eval_equations ( 1 , 2 , 3 ) inp3 = eval_equations ( 1 , 2 , 3 , 4 , 5 ) print ( \"equation 2 :\" , inp1 . ans ) print ( \"equation 1 :\" , inp2 . ans ) print ( \"equation 3 :\" , inp3 . ans ) equation 2 : -3 equation 1 : 2 equation 3 : 11.0 Using @classmethod decorator class eval_equations : # basic constructor def __init__ ( self , a ): self . ans = a # expression 1 @classmethod def eq1 ( cls , args ): # create an object for the class to return x = cls (( args [ 0 ] * args [ 0 ]) + ( args [ 1 ] * args [ 1 ]) - args [ 2 ]) return x # expression 2 @classmethod def eq2 ( cls , args ): y = cls (( args [ 0 ] * args [ 0 ]) - ( args [ 1 ] * args [ 1 ])) return y # expression 3 @classmethod def eq3 ( cls , args ): temp = 0 # square of each element for i in range ( 0 , len ( args )): temp += args [ i ] * args [ i ] temp = temp / max ( args ) z = cls ( temp ) return z li = [[ 1 , 2 ], [ 1 , 2 , 3 ], [ 1 , 2 , 3 , 4 , 5 ]] i = 0 # loop to get input three times while i < 3 : inp = li [ i ] # no.of.arguments = 2 if len ( inp ) == 2 : p = eval_equations . eq2 ( inp ) print ( \"equation 2 :\" , p . ans ) # no.of.arguments = 3 elif len ( inp ) == 3 : p = eval_equations . eq1 ( inp ) print ( \"equation 1 :\" , p . ans ) # More than three arguments else : p = eval_equations . eq3 ( inp ) print ( \"equation 3 :\" , p . ans ) #increment loop i += 1 equation 2 : -3 equation 1 : 2 equation 3 : 11.0","title":"Constructor"},{"location":"Cls/pyConstructor/#polymorphism","text":"Python does not support explicit multiple constructors, yet there are some ways in which using the multiple constructors can be achieved. If multiple init methods are written for the same class, then the latest one overwrites all the previous constructors. The class constructors can be made to exhibit polymorphism in three ways which are listed below. Overloading constructors based on arguments. Calling methods from init . Using @classmethod decorator. With python3, you can use Implementing Multiple Dispatch with Function Annotations as Python Cookbook","title":"Polymorphism"},{"location":"Cls/pyConstructor/#overloading-constructors-based-on-arguments","text":"class sample : # constructor overloading based on args def __init__ ( self , * args ): # if args are more than 1 # sum of args if len ( args ) > 1 : self . ans = 0 for i in args : self . ans += i # if arg is an integer # square the arg elif isinstance ( args [ 0 ], int ): self . ans = args [ 0 ] * args [ 0 ] # if arg is string # Print with hello elif isinstance ( args [ 0 ], str ): self . ans = \"Hello! \" + args [ 0 ] + \".\" s1 = sample ( 1 , 2 , 3 , 4 , 5 ) print ( \"Sum of list :\" , s1 . ans ) s2 = sample ( 5 ) print ( \"Square of int :\" , s2 . ans ) s3 = sample ( \"PolloPitas\" ) print ( \"String :\" , s3 . ans ) Sum of list : 15 Square of int : 25 String : Hello! PolloPitas.","title":"Overloading constructors based on arguments"},{"location":"Cls/pyConstructor/#calling-methods-from-init","text":"class eval_equations : # single constructor to call other methods def __init__ ( self , * inp ): # when 2 arguments are passed if len ( inp ) == 2 : self . ans = self . eq2 ( inp ) # when 3 arguments are passed elif len ( inp ) == 3 : self . ans = self . eq1 ( inp ) # when more than 3 arguments are passed else : self . ans = self . eq3 ( inp ) def eq1 ( self , args ): x = ( args [ 0 ] * args [ 0 ]) + ( args [ 1 ] * args [ 1 ]) - args [ 2 ] return x def eq2 ( self , args ): y = ( args [ 0 ] * args [ 0 ]) - ( args [ 1 ] * args [ 1 ]) return y def eq3 ( self , args ): temp = 0 for i in range ( 0 , len ( args )): temp += args [ i ] * args [ i ] temp = temp / max ( args ) z = temp return z inp1 = eval_equations ( 1 , 2 ) inp2 = eval_equations ( 1 , 2 , 3 ) inp3 = eval_equations ( 1 , 2 , 3 , 4 , 5 ) print ( \"equation 2 :\" , inp1 . ans ) print ( \"equation 1 :\" , inp2 . ans ) print ( \"equation 3 :\" , inp3 . ans ) equation 2 : -3 equation 1 : 2 equation 3 : 11.0","title":"Calling methods from init"},{"location":"Cls/pyConstructor/#using-classmethod-decorator","text":"class eval_equations : # basic constructor def __init__ ( self , a ): self . ans = a # expression 1 @classmethod def eq1 ( cls , args ): # create an object for the class to return x = cls (( args [ 0 ] * args [ 0 ]) + ( args [ 1 ] * args [ 1 ]) - args [ 2 ]) return x # expression 2 @classmethod def eq2 ( cls , args ): y = cls (( args [ 0 ] * args [ 0 ]) - ( args [ 1 ] * args [ 1 ])) return y # expression 3 @classmethod def eq3 ( cls , args ): temp = 0 # square of each element for i in range ( 0 , len ( args )): temp += args [ i ] * args [ i ] temp = temp / max ( args ) z = cls ( temp ) return z li = [[ 1 , 2 ], [ 1 , 2 , 3 ], [ 1 , 2 , 3 , 4 , 5 ]] i = 0 # loop to get input three times while i < 3 : inp = li [ i ] # no.of.arguments = 2 if len ( inp ) == 2 : p = eval_equations . eq2 ( inp ) print ( \"equation 2 :\" , p . ans ) # no.of.arguments = 3 elif len ( inp ) == 3 : p = eval_equations . eq1 ( inp ) print ( \"equation 1 :\" , p . ans ) # More than three arguments else : p = eval_equations . eq3 ( inp ) print ( \"equation 3 :\" , p . ans ) #increment loop i += 1 equation 2 : -3 equation 1 : 2 equation 3 : 11.0","title":"Using @classmethod decorator"},{"location":"Cls/pyDataCls/","text":"dataclass module is introduced in Python 3.7 as a utility tool to make structured classes specially for storing data. These classes hold certain properties and functions to deal specifically with the data and its representation. Although the module was introduced in Python3.7, one can also use it in Python3.6 by installing dataclasses library. pip install dataclasses The DataClasses are implemented by using decorators with classes. Attributes are declared using Type Hints in Python which is essentially, specifying data type for variables in python. # A basic Data Class # Importing dataclass module from dataclasses import dataclass @dataclass class Mycle (): \"\"\"A class for holding an article content\"\"\" # Attributes Declaration # using Type Hints title : str author : str language : str upvotes : int # A DataClass object article = Mycle ( \"DataClasses\" , \"vynnyl\" , \"Python\" , 0 ) print ( article ) Mycle(title='DataClasses', author='vynnyl', language='Python', upvotes=0) The two noticeable points in above code: Without a __init__() constructor, the class accepted values and assigned it to appropriate variables. The output of printing object is a neat representation of the data present in it, without any explicit function coded to do this. That means it has a modified __repr__() function. __post_init__(): This function when made, is called by in-built __init__() after initialization of all the attributes of DataClass. Basically, object creation of DataClass starts with __init__() (constructor-calling) and ends with __post__init__() (post-init processing). from dataclasses import dataclass , field name = { 'viwal' : 'Vi Awal' } @dataclass class GArticle : title : str language : str author : str author_name : str = field ( init = False ) upvotes : int = 0 #default value def __post_init__ ( self ): self . author_name = name [ self . author ] dClassObj = GArticle ( \"DataClass\" , \"Python3\" , \"viwal\" ) print ( dClassObj ) GArticle(title='DataClass', language='Python3', author='viwal', author_name='Vi Awal', upvotes=0) Immutable data classes # Creating immutable data classes from dataclasses import dataclass @dataclass ( frozen = True ) # \"The \"frozen\" parameter makes the class immutable class ImmutableClass : value1 : str = \"Value 1\" value2 : int = 0 def somefunc ( self , newval ): self . value2 = newval obj = ImmutableClass () print ( obj . value1 ) # attempting to change the value of an immutable class throws an exception #obj.value1 = \"Another value\" #print(obj.value1) # Frozen classes can't modify themselves either #obj.somefunc(20) Value 1","title":"DataClasses"},{"location":"Cls/pyDataCls/#immutable-data-classes","text":"# Creating immutable data classes from dataclasses import dataclass @dataclass ( frozen = True ) # \"The \"frozen\" parameter makes the class immutable class ImmutableClass : value1 : str = \"Value 1\" value2 : int = 0 def somefunc ( self , newval ): self . value2 = newval obj = ImmutableClass () print ( obj . value1 ) # attempting to change the value of an immutable class throws an exception #obj.value1 = \"Another value\" #print(obj.value1) # Frozen classes can't modify themselves either #obj.somefunc(20) Value 1","title":"Immutable data classes"},{"location":"Cls/pyDataHid/","text":"A key part of object-oriented programming is encapsulation , which involves packaging of related variables and functions into a single easy-to-use object - an instance of a class. A related concept is data hiding , which states that implementation details of a class should be hidden, and a clean standard interface be presented for those who want to use the class. In other programming languages, this is usually done with private methods and attributes, which block external access to certain methods and attributes in a class. The Python philosophy is slightly different. It is often stated as \"we are all consenting adults here\", meaning that you shouldn't put arbitrary restrictions on accessing parts of a class. Hence there are no ways of enforcing a method or attribute be strictly private. Weakly private methods Weakly private methods and attributes have a single underscore at the beginning. This signals that they are private, and shouldn't be used by external code. However, it is mostly only a convention, and does not stop external code from accessing them. Its only actual effect is that from module_name import * won't import variables that start with a single underscore. class Queue : def __init__ ( self , contents ): self . _hiddenlist = list ( contents ) def push ( self , value ): self . _hiddenlist . insert ( 0 , value ) def pop ( self ): return self . _hiddenlist . pop ( - 1 ) def __repr__ ( self ): return \"Queue( {} )\" . format ( self . _hiddenlist ) queue = Queue ([ 1 , 2 , 3 ]) print ( queue ) queue . push ( 0 ) print ( queue ) queue . pop () print ( queue ) print ( queue . _hiddenlist ) Queue([1, 2, 3]) Queue([0, 1, 2, 3]) Queue([0, 1, 2]) [0, 1, 2] Strongly private methods Strongly private methods and attributes have a double underscore at the beginning of their names. This causes their names to be mangled, which means that they can't be accessed from outside the class. The purpose of this isn't to ensure that they are kept private, but to avoid bugs if there are subclasses that have methods or attributes with the same names. Name mangled methods can still be accessed externally, but by a different name. The method __privatemethod of class Spam could be accessed externally with _Spam__privatemethod. class Spam : __egg = 7 def print_egg ( self ): print ( self . __egg ) s = Spam () s . print_egg () print ( s . _Spam__egg ) #print(s.__egg) #AttributeError 7 7","title":"Data Hiding"},{"location":"Cls/pyDataHid/#weakly-private-methods","text":"Weakly private methods and attributes have a single underscore at the beginning. This signals that they are private, and shouldn't be used by external code. However, it is mostly only a convention, and does not stop external code from accessing them. Its only actual effect is that from module_name import * won't import variables that start with a single underscore. class Queue : def __init__ ( self , contents ): self . _hiddenlist = list ( contents ) def push ( self , value ): self . _hiddenlist . insert ( 0 , value ) def pop ( self ): return self . _hiddenlist . pop ( - 1 ) def __repr__ ( self ): return \"Queue( {} )\" . format ( self . _hiddenlist ) queue = Queue ([ 1 , 2 , 3 ]) print ( queue ) queue . push ( 0 ) print ( queue ) queue . pop () print ( queue ) print ( queue . _hiddenlist ) Queue([1, 2, 3]) Queue([0, 1, 2, 3]) Queue([0, 1, 2]) [0, 1, 2]","title":"Weakly private methods"},{"location":"Cls/pyDataHid/#strongly-private-methods","text":"Strongly private methods and attributes have a double underscore at the beginning of their names. This causes their names to be mangled, which means that they can't be accessed from outside the class. The purpose of this isn't to ensure that they are kept private, but to avoid bugs if there are subclasses that have methods or attributes with the same names. Name mangled methods can still be accessed externally, but by a different name. The method __privatemethod of class Spam could be accessed externally with _Spam__privatemethod. class Spam : __egg = 7 def print_egg ( self ): print ( self . __egg ) s = Spam () s . print_egg () print ( s . _Spam__egg ) #print(s.__egg) #AttributeError 7 7","title":"Strongly private methods"},{"location":"Cls/pyEnum/","text":"Enumerations in Python are implemented by using the module named \u201cenum\u201c.Enumerations are created using classes. Enums have names and values associated with them. Properties of enum: Enums can be displayed as string or repr. Enums can be checked for their types using type(). \u201cname\u201d keyword is used to display the name of the enum member. Enumerations are iterable. They can be iterated using loops Enumerations support hashing. Enums can be used in dictionaries or sets. # Python code to demonstrate enumerations # importing enum for enumerations import enum # creating enumerations using class class Animal ( enum . Enum ): dog = 1 cat = 2 lion = 3 # printing enum member as string print ( \"The string representation of enum member is : \" , end = \"\" ) print ( Animal . dog ) # printing enum member as repr print ( \"The repr representation of enum member is : \" , end = \"\" ) print ( repr ( Animal . dog )) # printing the type of enum member using type() print ( \"The type of enum member is : \" , end = \"\" ) print ( type ( Animal . dog )) # printing name of enum member using \"name\" keyword print ( \"The name of enum member is : \" , end = \"\" ) print ( Animal . dog . name ) The string representation of enum member is : Animal.dog The repr representation of enum member is : <Animal.dog: 1> The type of enum member is : <enum 'Animal'> The name of enum member is : dog # Python code to demonstrate enumerations # iterations and hashing # importing enum for enumerations import enum # creating enumerations using class class Animal ( enum . Enum ): dog = 1 cat = 2 lion = 3 # printing all enum members using loop print ( \"All the enum values are : \" ) for Anim in ( Animal ): print ( Anim ) # Hashing enum member as dictionary di = {} di [ Animal . dog ] = 'bark' di [ Animal . lion ] = 'roar' # checking if enum values are hashed successfully if di == { Animal . dog : 'bark' , Animal . lion : 'roar' }: print ( \"Enum is hashed\" ) else : print ( \"Enum is not hashed\" ) All the enum values are : Animal.dog Animal.cat Animal.lion Enum is hashed Accessing Modes : Enum members can be accessed by two ways By value :- In this method, the value of enum member is passed. By name :- In this method, the name of enum member is passed. Separate value or name can also be accessed using \u201cname\u201d or \u201cvalue\u201d keyword. Comparison : Enumerations supports two types of comparisons Identity :- These are checked using keywords \u201cis\u201d and \u201cis not\u201c. Equality :- Equality comparisons of \u201c==\u201d and \u201c!=\u201d types are also supported. # Python code to demonstrate enumerations # Access and comparison # importing enum for enumerations import enum # creating enumerations using class class Animal ( enum . Enum ): dog = 1 cat = 2 lion = 3 # Accessing enum member using value print ( \"The enum member associated with value 2 is : \" , end = \"\" ) print ( Animal ( 2 )) # Accessing enum member using name print ( \"The enum member associated with name lion is : \" , end = \"\" ) print ( Animal [ 'lion' ]) # Assigning enum member mem = Animal . dog # Displaying value print ( \"The value associated with dog is : \" , end = \"\" ) print ( mem . value ) # Displaying name print ( \"The name associated with dog is : \" , end = \"\" ) print ( mem . name ) # Comparison using \"is\" if Animal . dog is Animal . cat : print ( \"Dog and cat are same animals\" ) else : print ( \"Dog and cat are different animals\" ) # Comparison using \"!=\" if Animal . lion != Animal . cat : print ( \"Lions and cat are different\" ) else : print ( \"Lions and cat are same\" ) The enum member associated with value 2 is : Animal.cat The enum member associated with name lion is : Animal.lion The value associated with dog is : 1 The name associated with dog is : dog Dog and cat are different animals Lions and cat are different # define enumerations using the Enum base class from enum import Enum , unique , auto #Enum do not permit repeated names howewver #To avoid repeated values the unique decorator is used @unique class Fruit ( Enum ): APPLE = 1 BANANA = 2 ORANGE = 3 TOMATO = 4 PEAR = auto () def main (): # enums have human-readable values and types print ( Fruit . APPLE ) print ( type ( Fruit . APPLE )) print ( repr ( Fruit . APPLE )) # enums have name and value properties print ( Fruit . APPLE . name , Fruit . APPLE . value ) # print the auto-generated value print ( Fruit . PEAR . value ) # enums are hashable - can be used as keys myFruits = {} myFruits [ Fruit . BANANA ] = \"Come Mr. Tally-man\" print ( myFruits [ Fruit . BANANA ]) if __name__ == \"__main__\" : main () Fruit.APPLE <enum 'Fruit'> <Fruit.APPLE: 1> APPLE 1 5 Come Mr. Tally-man","title":"Enumerations"},{"location":"Cls/pyGen/","text":"Besides the first two paradigms of programming - imperative (using statements, loops, and functions as subroutines), and functional (using pure functions, higher-order functions, and recursion), there is the paradigm of object-oriented programming (OOP). Objects are created using classes, which are actually the focal point of OOP. The class describes what the object will be, but is separate from the object itself. In other words, a class can be described as an object's blueprint, description, or definition. You can use the same class as a blueprint for creating multiple different objects. Classes are created using the keyword class and an indented block, which contains class methods (which are functions). class Cat : def __init__ ( self , color , legs ): self . color = color self . legs = legs felix = Cat ( \"ginger\" , 4 ) rover = Cat ( \"dog-colored\" , 4 ) stumpy = Cat ( \"brown\" , 3 )","title":"General"},{"location":"Cls/pyInheritance/","text":"Inheritance provides a way to share functionality between classes. To inherit a class from another class, put the superclass name in parentheses after the class name. A class that inherits from another class is called a subclass. A class that is inherited from is called a superclass. If a class inherits from another with the same attributes or methods, it overrides them. One class can inherit from another, and that class can inherit from a third class. However, circular inheritance is not possible. The function super is a useful inheritance-related function that refers to the parent class. It can be used to find the method with a certain name in an object's superclass. class Animal : def __init__ ( self , name , color ): self . name = name self . color = color def walk ( self ): print ( \"walking...\" ) class Cat ( Animal ): def purr ( self ): print ( \"prrrr\" ) class Dog ( Animal ): def bark ( self ): print ( \"woof!\" ) super () . walk () fido = Dog ( \"fido\" , \"brown\" ) print ( fido . color ) fido . bark () brown woof! walking... class RevStr ( str ): def __str__ ( self ): return self [:: - 1 ] hello = RevStr ( 'Hello, World!' ) print ( hello ) !dlroW ,olleH Multiple Inheritance Method resolution order: In Python, every class whether built-in or user-defined is derived from the object class and all the objects are instances of the class object. Hence, the object class is the base class for all the other classes. In the case of multiple inheritance, a given attribute is first searched in the current class if it\u2019s not found then it\u2019s searched in the parent classes. The parent classes are searched in a depth-first, left-right fashion and each class is searched once. If we see the above example then the order of search for the attributes will be Derived, Base1, Base2, object. The order that is followed is known as a linearization of the class Derived and this order is found out using a set of rules called Method Resolution Order (MRO). To view the MRO of a class: Use the mro() method, it returns a list Eg. Class4.mro() Use the mro attribute, it returns a tuple Eg. Class4. mro # Understanding multiple inheritance class A : def __init__ ( self ): super () . __init__ () self . foo = \"foo\" self . name = \"Class A\" class B : def __init__ ( self ): super () . __init__ () self . bar = \"bar\" self . name = \"Class B\" class C ( B , A ): def __init__ ( self ): super () . __init__ () def showprops ( self ): print ( self . foo ) print ( self . bar ) print ( self . name ) # create the class and call showname() c = C () print ( C . mro ()) print ( C . __mro__ ) #Method resolution order c . showprops () [<class '__main__.C'>, <class '__main__.B'>, <class '__main__.A'>, <class 'object'>] (<class '__main__.C'>, <class '__main__.B'>, <class '__main__.A'>, <class 'object'>) foo bar Class B Interfaces Interfaces are not necessary in Python. This is because Python has proper multiple inheritance, and also ducktyping, which means that the places where you must have interfaces in Java, you don't have to have them in Python. That said, there are still several uses for interfaces. Some of them are covered by Pythons Abstract Base Classes, introduced in Python 2.6. They are useful, if you want to make base classes that cannot be instantiated, but provide a specific interface or part of an implementation. Another usage is if you somehow want to specify that an object implements a specific interface, and you can use ABC's for that too by subclassing from them. Another way is zope.interface, a module that is a part of the Zope Component Architecture, a really awesomely cool component framework. Here you don't subclass from the interfaces, but instead mark classes (or even instances) as implementing an interface. This can also be used to look up components from a component registry. Interface acts as a blueprint for designing classes, so interfaces are implemented using implementer decorator on class. If a class implements an interface, then the instances of the class provide the interface. Objects can provide interfaces directly, in addition to what their classes implement. pip install zope . interface Collecting zope.interface Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB) |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 251 kB 9.9 MB/s Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface) (57.4.0) Installing collected packages: zope.interface Successfully installed zope.interface-5.4.0 import zope.interface class MyInterface ( zope . interface . Interface ): x = zope . interface . Attribute ( 'foo' ) def method1 ( self , x , y , z ): pass def method2 ( self ): pass @zope . interface . implementer ( MyInterface ) class MyClass : def method1 ( self , x ): return x ** 2 def method2 ( self ): return \"foo\" obj = MyClass () # ask an interface whether it # is implemented by a class: print ( MyInterface . implementedBy ( MyClass )) # MyClass does not provide # MyInterface but implements it: print ( MyInterface . providedBy ( MyClass )) # ask whether an interface # is provided by an object: print ( MyInterface . providedBy ( obj )) # ask what interfaces are # implemented by a class: print ( list ( zope . interface . implementedBy ( MyClass ))) # ask what interfaces are # provided by an object: print ( list ( zope . interface . providedBy ( obj ))) # class does not provide interface print ( list ( zope . interface . providedBy ( MyClass ))) True False True [<InterfaceClass __main__.MyInterface>] [<InterfaceClass __main__.MyInterface>] []","title":"Inheritance"},{"location":"Cls/pyInheritance/#multiple-inheritance","text":"Method resolution order: In Python, every class whether built-in or user-defined is derived from the object class and all the objects are instances of the class object. Hence, the object class is the base class for all the other classes. In the case of multiple inheritance, a given attribute is first searched in the current class if it\u2019s not found then it\u2019s searched in the parent classes. The parent classes are searched in a depth-first, left-right fashion and each class is searched once. If we see the above example then the order of search for the attributes will be Derived, Base1, Base2, object. The order that is followed is known as a linearization of the class Derived and this order is found out using a set of rules called Method Resolution Order (MRO). To view the MRO of a class: Use the mro() method, it returns a list Eg. Class4.mro() Use the mro attribute, it returns a tuple Eg. Class4. mro # Understanding multiple inheritance class A : def __init__ ( self ): super () . __init__ () self . foo = \"foo\" self . name = \"Class A\" class B : def __init__ ( self ): super () . __init__ () self . bar = \"bar\" self . name = \"Class B\" class C ( B , A ): def __init__ ( self ): super () . __init__ () def showprops ( self ): print ( self . foo ) print ( self . bar ) print ( self . name ) # create the class and call showname() c = C () print ( C . mro ()) print ( C . __mro__ ) #Method resolution order c . showprops () [<class '__main__.C'>, <class '__main__.B'>, <class '__main__.A'>, <class 'object'>] (<class '__main__.C'>, <class '__main__.B'>, <class '__main__.A'>, <class 'object'>) foo bar Class B","title":"Multiple Inheritance"},{"location":"Cls/pyInheritance/#interfaces","text":"Interfaces are not necessary in Python. This is because Python has proper multiple inheritance, and also ducktyping, which means that the places where you must have interfaces in Java, you don't have to have them in Python. That said, there are still several uses for interfaces. Some of them are covered by Pythons Abstract Base Classes, introduced in Python 2.6. They are useful, if you want to make base classes that cannot be instantiated, but provide a specific interface or part of an implementation. Another usage is if you somehow want to specify that an object implements a specific interface, and you can use ABC's for that too by subclassing from them. Another way is zope.interface, a module that is a part of the Zope Component Architecture, a really awesomely cool component framework. Here you don't subclass from the interfaces, but instead mark classes (or even instances) as implementing an interface. This can also be used to look up components from a component registry. Interface acts as a blueprint for designing classes, so interfaces are implemented using implementer decorator on class. If a class implements an interface, then the instances of the class provide the interface. Objects can provide interfaces directly, in addition to what their classes implement. pip install zope . interface Collecting zope.interface Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB) |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 251 kB 9.9 MB/s Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface) (57.4.0) Installing collected packages: zope.interface Successfully installed zope.interface-5.4.0 import zope.interface class MyInterface ( zope . interface . Interface ): x = zope . interface . Attribute ( 'foo' ) def method1 ( self , x , y , z ): pass def method2 ( self ): pass @zope . interface . implementer ( MyInterface ) class MyClass : def method1 ( self , x ): return x ** 2 def method2 ( self ): return \"foo\" obj = MyClass () # ask an interface whether it # is implemented by a class: print ( MyInterface . implementedBy ( MyClass )) # MyClass does not provide # MyInterface but implements it: print ( MyInterface . providedBy ( MyClass )) # ask whether an interface # is provided by an object: print ( MyInterface . providedBy ( obj )) # ask what interfaces are # implemented by a class: print ( list ( zope . interface . implementedBy ( MyClass ))) # ask what interfaces are # provided by an object: print ( list ( zope . interface . providedBy ( obj ))) # class does not provide interface print ( list ( zope . interface . providedBy ( MyClass ))) True False True [<InterfaceClass __main__.MyInterface>] [<InterfaceClass __main__.MyInterface>] []","title":"Interfaces"},{"location":"Cls/pyMagicMet/","text":"Magic methods are special methods which have double underscores at the beginning and end of their names. They are also known as dunders . So far, the only one we have encountered is __init__ , but there are several others. They are used to create functionality that can't be represented as a normal method. One common use of them is operator overloading. This means defining operators for custom classes that allow operators such as + and * to be used on them. An example magic method is __add__ for +. The __add__ method allows for the definition of a custom behavior for the + operator in our class. class Vector2D : def __init__ ( self , x , y ): self . x = x self . y = y def __add__ ( self , other ): return Vector2D ( self . x + other . x , self . y + other . y ) first = Vector2D ( 5 , 7 ) second = Vector2D ( 3 , 9 ) result = first + second print ( result . x ) print ( result . y ) 8 16 Common OPs More magic methods for common operators: __sub__ for - __mul__ for * __floordiv__ for // __truediv__ for / __mod__ for % __pow__ for ** __and__ for & __xor__ for ^ __or__ for | The expression x + y is translated into x.__add__(y). However, if x hasn't implemented __add__, and x and y are of different types, then y.__radd__(x) is called. There are equivalent r methods for all magic methods just mentioned. class SpecialString : def __init__ ( self , cont ): self . cont = cont def __truediv__ ( self , other ): line = \"=\" * len ( other . cont ) return \" \\n \" . join ([ self . cont , line , other . cont ]) spam = SpecialString ( \"spam\" ) hello = SpecialString ( \"Hello world!\" ) print ( spam / hello ) spam ============ Hello world! Comparisons Python also provides magic methods for comparisons. __lt__ for < __le__ for <= __eq__ for == __ne__ for != __gt__ for > __ge__ for >= If __ne__ is not implemented, it returns the opposite of __eq__. There are no other relationships between the other operators. class SpecialString : def __init__ ( self , cont ): self . cont = cont def __gt__ ( self , other ): for i in range ( len ( other . cont ) + 1 ): res = other . cont [: i ] + \">\" + self . cont res += \">\" + other . cont [ i :] print ( res ) spam = SpecialString ( \"spam\" ) eggs = SpecialString ( \"eggs\" ) spam > eggs >spam>eggs e>spam>ggs eg>spam>gs egg>spam>s eggs>spam> String Magic methods for String representation: __str__ :The function is used to return a user-friendly string representation of the object __repr__ Attribute Access Magic methods for Attribute access: __getattribute__ __setattr__ __getattr__ class Book : def __init__ ( self , title , author , price ): super () . __init__ () self . title = title self . author = author self . price = price self . _discount = 0.1 # The __str__ function is used to return a user-friendly string # representation of the object def __str__ ( self ): return f \" { self . title } by { self . author } , costs { self . price } \" # Called when an attribute is retrieved. Be aware that you can't # directly access the attr name otherwise a recursive loop is created def __getattribute__ ( self , name ): if ( name == \"price\" ): p = super () . __getattribute__ ( \"price\" ) d = super () . __getattribute__ ( \"_discount\" ) return p - ( p * d ) return super () . __getattribute__ ( name ) # __setattr__ called when an attribute value is set. Don't set the attr # directly here otherwise a recursive loop causes a crash def __setattr__ ( self , name , value ): if ( name == \"price\" ): if type ( value ) is not float : raise ValueError ( \"The 'price' attribute must be a float\" ) return super () . __setattr__ ( name , value ) # __getattr__ called when __getattribute__ lookup fails - you can # pretty much generate attributes on the fly with this method def __getattr__ ( self , name ): return name + \" is not here!\" b1 = Book ( \"War and Peace\" , \"Leo Tolstoy\" , 39.95 ) b2 = Book ( \"The Catcher in the Rye\" , \"JD Salinger\" , 29.95 ) # Try setting and accessing the price b1 . price = 38.95 print ( b1 ) b2 . price = float ( 40 ) # using an int will raise an exception print ( b2 ) # If an attribute doesn't exist, __getattr__ will be called print ( b1 . randomprop ) War and Peace by Leo Tolstoy, costs 35.055 The Catcher in the Rye by JD Salinger, costs 36.0 randomprop is not here! Callable Objects class Book : def __init__ ( self , title , author , price ): super () . __init__ () self . title = title self . author = author self . price = price def __str__ ( self ): return f \" { self . title } by { self . author } , costs { self . price } \" # the __call__ method can be used to call the object like a function def __call__ ( self , title , author , price ): self . title = title self . author = author self . price = price b1 = Book ( \"War and Peace\" , \"Leo Tolstoy\" , 39.95 ) b2 = Book ( \"The Catcher in the Rye\" , \"JD Salinger\" , 29.95 ) # call the object as if it were a function print ( b1 ) b1 ( \"Anna Karenina\" , \"Leo Tolstoy\" , 49.95 ) print ( b1 ) War and Peace by Leo Tolstoy, costs 39.95 Anna Karenina by Leo Tolstoy, costs 49.95 Containers There are several magic methods for making classes act like containers. __len__ for len() __getitem__ for indexing __setitem__ for assigning to indexed values __delitem__ for deleting indexed values __iter__ for iteration over objects (e.g., in for loops) __contains__ for in import random class VagueList : def __init__ ( self , cont ): self . cont = cont def __getitem__ ( self , index ): return self . cont [ index + random . randint ( - 1 , 1 )] def __len__ ( self ): return random . randint ( 0 , len ( self . cont ) * 2 ) vague_list = VagueList ([ \"A\" , \"B\" , \"C\" , \"D\" , \"E\" ]) print ( len ( vague_list )) print ( len ( vague_list )) print ( vague_list [ 2 ]) print ( vague_list [ 2 ]) 10 0 D C Destructor Destructors are called when an object gets destroyed. In Python, destructors are not needed as much needed in C++ because Python has a garbage collector that handles memory management automatically. The __del__() method is a known as a destructor method in Python. It is called when all references to the object have been deleted i.e when an object is garbage collected. def __del__ ( self ): print ( \"Destructor called\" )","title":"Magic Methods"},{"location":"Cls/pyMagicMet/#common-ops","text":"More magic methods for common operators: __sub__ for - __mul__ for * __floordiv__ for // __truediv__ for / __mod__ for % __pow__ for ** __and__ for & __xor__ for ^ __or__ for | The expression x + y is translated into x.__add__(y). However, if x hasn't implemented __add__, and x and y are of different types, then y.__radd__(x) is called. There are equivalent r methods for all magic methods just mentioned. class SpecialString : def __init__ ( self , cont ): self . cont = cont def __truediv__ ( self , other ): line = \"=\" * len ( other . cont ) return \" \\n \" . join ([ self . cont , line , other . cont ]) spam = SpecialString ( \"spam\" ) hello = SpecialString ( \"Hello world!\" ) print ( spam / hello ) spam ============ Hello world!","title":"Common OPs"},{"location":"Cls/pyMagicMet/#comparisons","text":"Python also provides magic methods for comparisons. __lt__ for < __le__ for <= __eq__ for == __ne__ for != __gt__ for > __ge__ for >= If __ne__ is not implemented, it returns the opposite of __eq__. There are no other relationships between the other operators. class SpecialString : def __init__ ( self , cont ): self . cont = cont def __gt__ ( self , other ): for i in range ( len ( other . cont ) + 1 ): res = other . cont [: i ] + \">\" + self . cont res += \">\" + other . cont [ i :] print ( res ) spam = SpecialString ( \"spam\" ) eggs = SpecialString ( \"eggs\" ) spam > eggs >spam>eggs e>spam>ggs eg>spam>gs egg>spam>s eggs>spam>","title":"Comparisons"},{"location":"Cls/pyMagicMet/#string","text":"Magic methods for String representation: __str__ :The function is used to return a user-friendly string representation of the object __repr__","title":"String"},{"location":"Cls/pyMagicMet/#attribute-access","text":"Magic methods for Attribute access: __getattribute__ __setattr__ __getattr__ class Book : def __init__ ( self , title , author , price ): super () . __init__ () self . title = title self . author = author self . price = price self . _discount = 0.1 # The __str__ function is used to return a user-friendly string # representation of the object def __str__ ( self ): return f \" { self . title } by { self . author } , costs { self . price } \" # Called when an attribute is retrieved. Be aware that you can't # directly access the attr name otherwise a recursive loop is created def __getattribute__ ( self , name ): if ( name == \"price\" ): p = super () . __getattribute__ ( \"price\" ) d = super () . __getattribute__ ( \"_discount\" ) return p - ( p * d ) return super () . __getattribute__ ( name ) # __setattr__ called when an attribute value is set. Don't set the attr # directly here otherwise a recursive loop causes a crash def __setattr__ ( self , name , value ): if ( name == \"price\" ): if type ( value ) is not float : raise ValueError ( \"The 'price' attribute must be a float\" ) return super () . __setattr__ ( name , value ) # __getattr__ called when __getattribute__ lookup fails - you can # pretty much generate attributes on the fly with this method def __getattr__ ( self , name ): return name + \" is not here!\" b1 = Book ( \"War and Peace\" , \"Leo Tolstoy\" , 39.95 ) b2 = Book ( \"The Catcher in the Rye\" , \"JD Salinger\" , 29.95 ) # Try setting and accessing the price b1 . price = 38.95 print ( b1 ) b2 . price = float ( 40 ) # using an int will raise an exception print ( b2 ) # If an attribute doesn't exist, __getattr__ will be called print ( b1 . randomprop ) War and Peace by Leo Tolstoy, costs 35.055 The Catcher in the Rye by JD Salinger, costs 36.0 randomprop is not here!","title":"Attribute Access"},{"location":"Cls/pyMagicMet/#callable-objects","text":"class Book : def __init__ ( self , title , author , price ): super () . __init__ () self . title = title self . author = author self . price = price def __str__ ( self ): return f \" { self . title } by { self . author } , costs { self . price } \" # the __call__ method can be used to call the object like a function def __call__ ( self , title , author , price ): self . title = title self . author = author self . price = price b1 = Book ( \"War and Peace\" , \"Leo Tolstoy\" , 39.95 ) b2 = Book ( \"The Catcher in the Rye\" , \"JD Salinger\" , 29.95 ) # call the object as if it were a function print ( b1 ) b1 ( \"Anna Karenina\" , \"Leo Tolstoy\" , 49.95 ) print ( b1 ) War and Peace by Leo Tolstoy, costs 39.95 Anna Karenina by Leo Tolstoy, costs 49.95","title":"Callable Objects"},{"location":"Cls/pyMagicMet/#containers","text":"There are several magic methods for making classes act like containers. __len__ for len() __getitem__ for indexing __setitem__ for assigning to indexed values __delitem__ for deleting indexed values __iter__ for iteration over objects (e.g., in for loops) __contains__ for in import random class VagueList : def __init__ ( self , cont ): self . cont = cont def __getitem__ ( self , index ): return self . cont [ index + random . randint ( - 1 , 1 )] def __len__ ( self ): return random . randint ( 0 , len ( self . cont ) * 2 ) vague_list = VagueList ([ \"A\" , \"B\" , \"C\" , \"D\" , \"E\" ]) print ( len ( vague_list )) print ( len ( vague_list )) print ( vague_list [ 2 ]) print ( vague_list [ 2 ]) 10 0 D C","title":"Containers"},{"location":"Cls/pyMagicMet/#destructor","text":"Destructors are called when an object gets destroyed. In Python, destructors are not needed as much needed in C++ because Python has a garbage collector that handles memory management automatically. The __del__() method is a known as a destructor method in Python. It is called when all references to the object have been deleted i.e when an object is garbage collected. def __del__ ( self ): print ( \"Destructor called\" )","title":"Destructor"},{"location":"Cls/pyProp/","text":"Properties provide a way of customizing access to instance attributes. They are created by putting the property decorator above a method, which means when the instance attribute with the same name as the method is accessed, the method will be called instead. One common use of a property is to make an attribute read-only. class Pizza : def __init__ ( self , toppings ): self . toppings = toppings @property def pinapple_allowed ( self ): return False pizza = Pizza ([ \"cheese\" , \"tomato\" ]) print ( pizza . pinapple_allowed ) #pizza.pinapple_allowed=True #Read_only False Properties can also be set by defining setter/getter functions. The setter function sets the corresponding property's value. The getter gets the value. To define a setter, you need to use a decorator of the same name as the property, followed by a dot and the setter keyword. The same applies to defining getter functions. class Pizza : def __init__ ( self , toppings ): self . toppings = toppings self . _pinapple_allowed = False @property def pinapple_allowed ( self ): return self . _pinapple_allowed @pinapple_allowed . setter def pinapple_allowed ( self , value ): if value : password = input ( \"Enter password: \" ) if password == \"Sword\" : self . _pinapple_allowed = value else : raise ValueError ( \"Intruder\" ) pizza = Pizza ([ \"cheese\" , \"tomato\" ]) print ( pizza . pinapple_allowed ) pizza . pinapple_allowed = True print ( pizza . pinapple_allowed ) False Enter password: Sword True","title":"Properties"},{"location":"DS/pyArray/","text":"An array is a collection of items stored at contiguous memory locations. The idea is to store multiple items of the same type together. This makes it easier to calculate the position of each element by simply adding an offset to a base value, i.e., the memory location of the first element of the array # Python program to demonstrate # Creation of Array # importing \"array\" for array creations import array as arr # creating an array with integer type a = arr . array ( 'i' , [ 1 , 2 , 3 ]) # printing original array print ( \"The new created array is : \" , end = \" \" ) for i in range ( 0 , 3 ): print ( a [ i ], end = \" \" ) print () # creating an array with float type b = arr . array ( 'd' , [ 2.5 , 3.2 , 3.3 ]) # printing original array print ( \"The new created array is : \" , end = \" \" ) for i in range ( 0 , 3 ): print ( b [ i ], end = \" \" ) The new created array is : 1 2 3 The new created array is : 2.5 3.2 3.3 Here are the differences between List and Array in Python : List Array Can consist of elements belonging to different data types Only consists of elements belonging to the same data type No need to explicitly import a module for declaration Need to explicitly import a module for declaration Cannot directly handle arithmetic operations Can directly handle arithmetic operations Can be nested to contain different type of elements Must contain either all nested elements of same size Preferred for shorter sequence of data items Preferred for longer sequence of data items Greater flexibility allows easy modification (addition, deletion) of data Less flexibility since addition, deletion has to be done element wise The entire list can be printed without any explicit looping A loop has to be formed to print or access the components of array Consume larger memory for easy addition of elements Comparatively more compact in memory size","title":"Array"},{"location":"DS/pyChainMap/","text":"A ChainMap encapsulates many dictionaries into a single unit and returns a list of dictionaries. # Python program to demonstrate ChainMap from collections import ChainMap d1 = { 'a' : 1 , 'b' : 2 } d2 = { 'c' : 3 , 'd' : 4 } d3 = { 'e' : 5 , 'f' : 6 } # Defining the chainmap c = ChainMap ( d1 , d2 , d3 ) print ( c ) ChainMap({'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6}) Accessing Keys and Values from ChainMap Values from ChainMap can be accessed using the key name. They can also be accessed by using the keys() and values() method. from collections import ChainMap d1 = { 'a' : 1 , 'b' : 2 } d2 = { 'c' : 3 , 'd' : 4 } d3 = { 'e' : 5 , 'f' : 6 } # Defining the chainmap c = ChainMap ( d1 , d2 , d3 ) # Accessing Values using key name print ( c [ 'a' ]) # Accessing values using values() # method print ( c . values ()) # Accessing keys using keys() # method print ( c . keys ()) 1 ValuesView(ChainMap({'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6})) KeysView(ChainMap({'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6})) Adding new dictionary A new dictionary can be added by using the new_child() method. The newly added dictionary is added at the beginning of the ChainMap. import collections # initializing dictionaries dic1 = { 'a' : 1 , 'b' : 2 } dic2 = { 'b' : 3 , 'c' : 4 } dic3 = { 'f' : 5 } # initializing ChainMap chain = collections . ChainMap ( dic1 , dic2 ) # printing chainMap print ( \"All the ChainMap contents are : \" ) print ( chain ) # using new_child() to add new dictionary chain1 = chain . new_child ( dic3 ) # printing chainMap print ( \"Displaying new ChainMap : \" ) print ( chain1 ) All the ChainMap contents are : ChainMap({'a': 1, 'b': 2}, {'b': 3, 'c': 4}) Displaying new ChainMap : ChainMap({'f': 5}, {'a': 1, 'b': 2}, {'b': 3, 'c': 4})","title":"ChainMap"},{"location":"DS/pyChainMap/#adding-new-dictionary","text":"A new dictionary can be added by using the new_child() method. The newly added dictionary is added at the beginning of the ChainMap. import collections # initializing dictionaries dic1 = { 'a' : 1 , 'b' : 2 } dic2 = { 'b' : 3 , 'c' : 4 } dic3 = { 'f' : 5 } # initializing ChainMap chain = collections . ChainMap ( dic1 , dic2 ) # printing chainMap print ( \"All the ChainMap contents are : \" ) print ( chain ) # using new_child() to add new dictionary chain1 = chain . new_child ( dic3 ) # printing chainMap print ( \"Displaying new ChainMap : \" ) print ( chain1 ) All the ChainMap contents are : ChainMap({'a': 1, 'b': 2}, {'b': 3, 'c': 4}) Displaying new ChainMap : ChainMap({'f': 5}, {'a': 1, 'b': 2}, {'b': 3, 'c': 4})","title":"Adding new dictionary"},{"location":"DS/pyCounter/","text":"A Counter is a subclass of dict. Therefore it is an unordered collection where elements and their respective count are stored as a dictionary. This is equivalent to a bag or multiset of other languages. It is used to keep the count of the elements in an iterable in the form of an unordered dictionary where the key represents the element in the iterable and value represents the count of that element in the iterable. Counter class is a special type of object data-set provided with the collections module in Python3. Collections module provides the user with specialized container datatypes, thus, providing an alternative to Python\u2019s general-purpose built-ins like dictionaries, lists and tuples. Counter is a sub-class that is used to count hashable objects. It implicitly creates a hash table of an iterable when invoked. Counter object along with its functions are used collectively for processing huge amounts of data. Initialization The constructor of counter can be called in any one of the following ways : With sequence of items With dictionary containing keys and counts With keyword arguments mapping string names to counts # A Python program to show different ways to create # Counter from collections import Counter # With sequence of items print ( Counter ([ 'B' , 'B' , 'A' , 'B' , 'C' , 'A' , 'B' , 'B' , 'A' , 'C' ])) # with dictionary print ( Counter ({ 'A' : 3 , 'B' : 5 , 'C' : 2 })) # with keyword arguments print ( Counter ( A = 3 , B = 5 , C = 2 )) Counter({'B': 5, 'A': 3, 'C': 2}) Counter({'B': 5, 'A': 3, 'C': 2}) Counter({'B': 5, 'A': 3, 'C': 2}) Updation We can also create an empty counter and can be updated via update() method # A Python program to demonstrate update() from collections import Counter coun = Counter () coun . update ([ 1 , 2 , 3 , 1 , 2 , 1 , 1 , 2 ]) print ( coun ) coun . update ([ 1 , 2 , 4 ]) print ( coun ) Counter({1: 4, 2: 3, 3: 1}) Counter({1: 5, 2: 4, 3: 1, 4: 1}) Data can be provided in any of the three ways as mentioned in initialization and the counter\u2019s data will be increased not replaced. Counts can be zero and negative also. # Python program to demonstrate that counts in # Counter can be 0 and negative from collections import Counter c1 = Counter ( A = 4 , B = 3 , C = 10 ) c2 = Counter ( A = 10 , B = 3 , C = 4 ) c1 . subtract ( c2 ) print ( c1 ) Counter({'C': 6, 'B': 0, 'A': -6}) We can use Counter to count distinct elements of a list or other collections. # An example program where different list items are # counted using counter from collections import Counter # Create a list z = [ 'blue' , 'red' , 'blue' , 'yellow' , 'blue' , 'red' ] # Count distinct elements and print Counter object print ( Counter ( z )) Counter({'blue': 3, 'red': 2, 'yellow': 1}) Once initialized, counters are accessed just like dictionaries. Also, it does not raise the KeyValue error (if key is not present) instead the value\u2019s count is shown as 0. # Python program to demonstrate accessing of # Counter elements from collections import Counter # Create a list z = [ 'blue' , 'red' , 'blue' , 'yellow' , 'blue' , 'red' ] col_count = Counter ( z ) print ( col_count ) col = [ 'blue' , 'red' , 'yellow' , 'green' ] # Here green is not in col_count # so count of green will be zero for color in col : print ( color , col_count [ color ]) Counter({'blue': 3, 'red': 2, 'yellow': 1}) blue 3 red 2 yellow 1 green 0 items() The Counter.items() method helps to see the elements of the list along with their respective frequencies in a tuple. # importing the module from collections import Counter # making a list list = [ 1 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 2 , 3 , 4 , 8 ] # instantiating a Counter object ob = Counter ( list ) # Counter.items() items = ob . items () print ( \"The datatype is \" + str ( type ( items ))) # displaying the dict_items print ( items ) # iterating over the dict_items for i in items : print ( i ) The datatype is <class 'dict_items'> dict_items([(1, 2), (2, 2), (3, 2), (4, 2), (5, 1), (6, 1), (7, 1), (9, 1), (8, 1)]) (1, 2) (2, 2) (3, 2) (4, 2) (5, 1) (6, 1) (7, 1) (9, 1) (8, 1) keys() The Counter.keys() method helps to see the unique elements in the list. # importing the module from collections import Counter # making a list list = [ 1 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 2 , 3 , 4 , 8 ] # instantiating a Counter object ob = Counter ( list ) # Counter.keys() keys = ob . keys () print ( \"The datatype is \" + str ( type ( keys ))) # displaying the dict_items print ( keys ) # iterating over the dict_items for i in keys : print ( i ) The datatype is <class 'dict_keys'> dict_keys([1, 2, 3, 4, 5, 6, 7, 9, 8]) 1 2 3 4 5 6 7 9 8 values() The Counter.values() method helps to see the frequencies of each unique element. # importing the module from collections import Counter # making a list list = [ 1 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 2 , 3 , 4 , 8 ] # instantiating a Counter object ob = Counter ( list ) # Counter.values() values = ob . values () print ( \"The datatype is \" + str ( type ( values ))) # displaying the dict_items print ( values ) # iterating over the dict_items for i in values : print ( i ) The datatype is <class 'dict_values'> dict_values([2, 2, 2, 2, 1, 1, 1, 1, 1]) 2 2 2 2 1 1 1 1 1 elements() elements() is one of the functions of Counter class, when invoked on the Counter object will return an itertool of all the known elements in the Counter object. The elements() method returns an iterator that produces all of the items known to the Counter. Note : Elements with count <= 0 are not included. # import counter class from collections module from collections import Counter # Creation of a Counter Class object using # a string as an iterable data container # Example - 1 a = Counter ( \"treatortrips\" ) # Elements of counter object for i in a . elements (): print ( i , end = \" \" ) print () # Example - 2 b = Counter ({ 'trips' : 4 , 'for' : 1 , 'gfg' : 2 , 'Trean' : 3 }) for i in b . elements (): print ( i , end = \" \" ) print () # Example - 3 c = Counter ([ 1 , 2 , 21 , 12 , 2 , 44 , 5 , 13 , 15 , 5 , 19 , 21 , 5 ]) for i in c . elements (): print ( i , end = \" \" ) print () # Example - 4 d = Counter ( a = 2 , b = 3 , c = 6 , d = 1 , e = 5 ) for i in d . elements (): print ( i , end = \" \" ) t t t r r r e a o i p s trips trips trips trips for gfg gfg Trean Trean Trean 1 2 2 21 21 12 44 5 5 5 13 15 19 a a b b b c c c c c c d e e e e e most_common() most_common() is used to produce a sequence of the n most frequently encountered input values and their respective counts. # Python example to demonstrate most_elements() on # Counter from collections import Counter coun = Counter ( a = 1 , b = 2 , c = 3 , d = 120 , e = 1 , f = 219 ) # This prints 3 most frequent characters for letter , count in coun . most_common ( 3 ): print ( ' %s : %d ' % ( letter , count )) f: 219 d: 120 c: 3","title":"Counter"},{"location":"DS/pyCounter/#initialization","text":"The constructor of counter can be called in any one of the following ways : With sequence of items With dictionary containing keys and counts With keyword arguments mapping string names to counts # A Python program to show different ways to create # Counter from collections import Counter # With sequence of items print ( Counter ([ 'B' , 'B' , 'A' , 'B' , 'C' , 'A' , 'B' , 'B' , 'A' , 'C' ])) # with dictionary print ( Counter ({ 'A' : 3 , 'B' : 5 , 'C' : 2 })) # with keyword arguments print ( Counter ( A = 3 , B = 5 , C = 2 )) Counter({'B': 5, 'A': 3, 'C': 2}) Counter({'B': 5, 'A': 3, 'C': 2}) Counter({'B': 5, 'A': 3, 'C': 2})","title":"Initialization"},{"location":"DS/pyCounter/#updation","text":"We can also create an empty counter and can be updated via update() method # A Python program to demonstrate update() from collections import Counter coun = Counter () coun . update ([ 1 , 2 , 3 , 1 , 2 , 1 , 1 , 2 ]) print ( coun ) coun . update ([ 1 , 2 , 4 ]) print ( coun ) Counter({1: 4, 2: 3, 3: 1}) Counter({1: 5, 2: 4, 3: 1, 4: 1}) Data can be provided in any of the three ways as mentioned in initialization and the counter\u2019s data will be increased not replaced. Counts can be zero and negative also. # Python program to demonstrate that counts in # Counter can be 0 and negative from collections import Counter c1 = Counter ( A = 4 , B = 3 , C = 10 ) c2 = Counter ( A = 10 , B = 3 , C = 4 ) c1 . subtract ( c2 ) print ( c1 ) Counter({'C': 6, 'B': 0, 'A': -6}) We can use Counter to count distinct elements of a list or other collections. # An example program where different list items are # counted using counter from collections import Counter # Create a list z = [ 'blue' , 'red' , 'blue' , 'yellow' , 'blue' , 'red' ] # Count distinct elements and print Counter object print ( Counter ( z )) Counter({'blue': 3, 'red': 2, 'yellow': 1}) Once initialized, counters are accessed just like dictionaries. Also, it does not raise the KeyValue error (if key is not present) instead the value\u2019s count is shown as 0. # Python program to demonstrate accessing of # Counter elements from collections import Counter # Create a list z = [ 'blue' , 'red' , 'blue' , 'yellow' , 'blue' , 'red' ] col_count = Counter ( z ) print ( col_count ) col = [ 'blue' , 'red' , 'yellow' , 'green' ] # Here green is not in col_count # so count of green will be zero for color in col : print ( color , col_count [ color ]) Counter({'blue': 3, 'red': 2, 'yellow': 1}) blue 3 red 2 yellow 1 green 0","title":"Updation"},{"location":"DS/pyCounter/#items","text":"The Counter.items() method helps to see the elements of the list along with their respective frequencies in a tuple. # importing the module from collections import Counter # making a list list = [ 1 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 2 , 3 , 4 , 8 ] # instantiating a Counter object ob = Counter ( list ) # Counter.items() items = ob . items () print ( \"The datatype is \" + str ( type ( items ))) # displaying the dict_items print ( items ) # iterating over the dict_items for i in items : print ( i ) The datatype is <class 'dict_items'> dict_items([(1, 2), (2, 2), (3, 2), (4, 2), (5, 1), (6, 1), (7, 1), (9, 1), (8, 1)]) (1, 2) (2, 2) (3, 2) (4, 2) (5, 1) (6, 1) (7, 1) (9, 1) (8, 1)","title":"items()"},{"location":"DS/pyCounter/#keys","text":"The Counter.keys() method helps to see the unique elements in the list. # importing the module from collections import Counter # making a list list = [ 1 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 2 , 3 , 4 , 8 ] # instantiating a Counter object ob = Counter ( list ) # Counter.keys() keys = ob . keys () print ( \"The datatype is \" + str ( type ( keys ))) # displaying the dict_items print ( keys ) # iterating over the dict_items for i in keys : print ( i ) The datatype is <class 'dict_keys'> dict_keys([1, 2, 3, 4, 5, 6, 7, 9, 8]) 1 2 3 4 5 6 7 9 8","title":"keys()"},{"location":"DS/pyCounter/#values","text":"The Counter.values() method helps to see the frequencies of each unique element. # importing the module from collections import Counter # making a list list = [ 1 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 9 , 2 , 3 , 4 , 8 ] # instantiating a Counter object ob = Counter ( list ) # Counter.values() values = ob . values () print ( \"The datatype is \" + str ( type ( values ))) # displaying the dict_items print ( values ) # iterating over the dict_items for i in values : print ( i ) The datatype is <class 'dict_values'> dict_values([2, 2, 2, 2, 1, 1, 1, 1, 1]) 2 2 2 2 1 1 1 1 1","title":"values()"},{"location":"DS/pyCounter/#elements","text":"elements() is one of the functions of Counter class, when invoked on the Counter object will return an itertool of all the known elements in the Counter object. The elements() method returns an iterator that produces all of the items known to the Counter. Note : Elements with count <= 0 are not included. # import counter class from collections module from collections import Counter # Creation of a Counter Class object using # a string as an iterable data container # Example - 1 a = Counter ( \"treatortrips\" ) # Elements of counter object for i in a . elements (): print ( i , end = \" \" ) print () # Example - 2 b = Counter ({ 'trips' : 4 , 'for' : 1 , 'gfg' : 2 , 'Trean' : 3 }) for i in b . elements (): print ( i , end = \" \" ) print () # Example - 3 c = Counter ([ 1 , 2 , 21 , 12 , 2 , 44 , 5 , 13 , 15 , 5 , 19 , 21 , 5 ]) for i in c . elements (): print ( i , end = \" \" ) print () # Example - 4 d = Counter ( a = 2 , b = 3 , c = 6 , d = 1 , e = 5 ) for i in d . elements (): print ( i , end = \" \" ) t t t r r r e a o i p s trips trips trips trips for gfg gfg Trean Trean Trean 1 2 2 21 21 12 44 5 5 5 13 15 19 a a b b b c c c c c c d e e e e e","title":"elements()"},{"location":"DS/pyCounter/#most_common","text":"most_common() is used to produce a sequence of the n most frequently encountered input values and their respective counts. # Python example to demonstrate most_elements() on # Counter from collections import Counter coun = Counter ( a = 1 , b = 2 , c = 3 , d = 120 , e = 1 , f = 219 ) # This prints 3 most frequent characters for letter , count in coun . most_common ( 3 ): print ( ' %s : %d ' % ( letter , count )) f: 219 d: 120 c: 3","title":"most_common()"},{"location":"DS/pyDS/","text":"Python Collections Iterable Anything that you can loop over using a for loop e.g: list, tuples, strings, set and dictionaries Sequence a subset of Iterables that have: 1. A length 2. An Index 3. Can be sliced e.g: Strings, list, tuples Not dictionaries, sets, files and generators Data Structures Python supports the following data structures: lists , dictionaries , tuples , sets . For arrays, see array or numpy array . When to use a dictionary: - When you need a logical association between a key:value pair. - When you need fast lookup for your data, based on a custom key. - When your data is being constantly modified. Remember, dictionaries are mutable. When to use the other types: - Use lists if you have a collection of data that does not need random access. Try to choose lists when you need a simple, iterable collection that is modified frequently. - Use a set if you need uniqueness for the elements. - Use tuples when your data cannot change. Many times, a tuple is used in combination with a dictionary, for example, a tuple might represent a key, because it's immutable. Tuples Lists Dict Sets ( ) [ ] {k:v} { } Immutable Mutable Mutable Mutable Ordered Ordered Ordered(>3.7) Unordered Iterable Iterable Iterable Iterable Constant time Linear time Constant time Constant time mytuple[0] mylist[0] mydict['somekey'] myset[0] Allow repetition Allow repetition Allow repetition Unique data len(mytuple) len(mylist) len(mydict) len(myset) .count() .append() and .insert() .keys(), .values() and .items() .add() and .update() .index() .pop() and .remove() .pop() or del mydict['somekey'] .remove() .reverse() and sort()","title":"General"},{"location":"DS/pyDS/#python-collections","text":"","title":"Python Collections"},{"location":"DS/pyDS/#iterable","text":"Anything that you can loop over using a for loop e.g: list, tuples, strings, set and dictionaries","title":"Iterable"},{"location":"DS/pyDS/#sequence","text":"a subset of Iterables that have: 1. A length 2. An Index 3. Can be sliced e.g: Strings, list, tuples Not dictionaries, sets, files and generators","title":"Sequence"},{"location":"DS/pyDS/#data-structures","text":"Python supports the following data structures: lists , dictionaries , tuples , sets . For arrays, see array or numpy array . When to use a dictionary: - When you need a logical association between a key:value pair. - When you need fast lookup for your data, based on a custom key. - When your data is being constantly modified. Remember, dictionaries are mutable. When to use the other types: - Use lists if you have a collection of data that does not need random access. Try to choose lists when you need a simple, iterable collection that is modified frequently. - Use a set if you need uniqueness for the elements. - Use tuples when your data cannot change. Many times, a tuple is used in combination with a dictionary, for example, a tuple might represent a key, because it's immutable. Tuples Lists Dict Sets ( ) [ ] {k:v} { } Immutable Mutable Mutable Mutable Ordered Ordered Ordered(>3.7) Unordered Iterable Iterable Iterable Iterable Constant time Linear time Constant time Constant time mytuple[0] mylist[0] mydict['somekey'] myset[0] Allow repetition Allow repetition Allow repetition Unique data len(mytuple) len(mylist) len(mydict) len(myset) .count() .append() and .insert() .keys(), .values() and .items() .add() and .update() .index() .pop() and .remove() .pop() or del mydict['somekey'] .remove() .reverse() and sort()","title":"Data Structures"},{"location":"DS/pyDefaultdict/","text":"Dictionary in Python is an unordered collection of data values that are used to store data values like a map. Unlike other Data Types that hold only single value as an element, the Dictionary holds key-value pair. In Dictionary, the key must be unique and immutable. This means that a Python Tuple can be a key whereas a Python List can not. A Dictionary can be created by placing a sequence of elements within curly {} braces, separated by \u2018comma\u2019. # Python program to demonstrate # dictionary Dict = { 1 : 'Treats' , 2 : 'For' , 3 : 'Pricks' } print ( \"Dictionary:\" ) print ( Dict ) print ( Dict [ 1 ]) # Uncommenting this print(Dict[4]) # will raise a KeyError as the # 4 is not present in the dictionary Dictionary: {1: 'Treats', 2: 'For', 3: 'Pricks'} Treats Sometimes, when the KeyError is raised, it might become a problem. To overcome this Python introduces another dictionary like container known as Defaultdict which is present inside the collections module. Defaultdict is a container like dictionaries present in the module collections. Defaultdict is a sub-class of the dictionary class that returns a dictionary-like object. The functionality of both dictionaries and defaultdict are almost same except for the fact that defaultdict never raises a KeyError. It provides a default value for the key that does not exists. # Python program to demonstrate defaultdict from collections import defaultdict # Function to return a default # values for keys that are not present def def_value (): return \"Not Present\" # Defining the dict d = defaultdict ( def_value ) d [ \"a\" ] = 1 d [ \"b\" ] = 2 print ( d [ \"a\" ]) print ( d [ \"b\" ]) print ( d [ \"c\" ]) 1 2 Not Present Inner Working of defaultdict Defaultdict adds one writable instance variable and one method in addition to the standard dictionary operations. The instance variable is the default_factory parameter and the method provided is missing. Default_factory: It is a function returning the default value for the dictionary defined. If this argument is absent then the dictionary raises a KeyError. # Python program to demonstrate # default_factory argument of # defaultdict from collections import defaultdict # Defining the dict and passing # lambda as default_factory argument d = defaultdict ( lambda : \"Not Present\" ) d [ \"a\" ] = 1 d [ \"b\" ] = 2 print ( d [ \"a\" ]) print ( d [ \"b\" ]) print ( d [ \"c\" ]) 1 2 Not Present from collections import defaultdict # Correct instantiation def_dict = defaultdict ( list ) # Pass list to .default_factory def_dict [ 'one' ] = 1 # Add a key-value pair def_dict [ 'missing' ] # Access a missing key returns an empty list [] def_dict [ 'another_missing' ] . append ( 4 ) # Modify a missing key def_dict defaultdict(list, {'another_missing': [4], 'missing': [], 'one': 1}) dep = [( 'Sales' , 'John Doe' ), ( 'Sales' , 'Martin Smith' ), ( 'Accounting' , 'Jane Doe' ), ( 'Marketing' , 'Elizabeth Smith' ), ( 'Marketing' , 'Adam Doe' )] from collections import defaultdict dep_dd = defaultdict ( list ) #For uniqueness instead of list use set for department , employee in dep : dep_dd [ department ] . append ( employee ) print ( dep_dd ) defaultdict(<class 'list'>, {'Sales': ['John Doe', 'Martin Smith'], 'Accounting': ['Jane Doe'], 'Marketing': ['Elizabeth Smith', 'Adam Doe']}) In this example, you group the employees by their department using a defaultdict with .default_factory set to list. To do this with a regular dictionary, you can use dict.setdefault() as follows: dep_d = dict () for department , employee in dep : dep_d . setdefault ( department , []) . append ( employee ) print ( dep_d ) {'Sales': ['John Doe', 'Martin Smith'], 'Accounting': ['Jane Doe'], 'Marketing': ['Elizabeth Smith', 'Adam Doe']} This code is straightforward, and you\u2019ll find similar code quite often in your work as a Python coder. However, the defaultdict version is arguably more readable, and for large datasets, it can also be a lot faster and more efficient. So, if speed is a concern for you, then you should consider using a defaultdict instead of a standard dict. Auto-vivification Defauldict are used to easily make nested dicts. It is called Auto-vivification. from collections import defaultdict import json def turtles (): return defaultdict ( turtles ) data = turtles () data [ \"Hello\" ] = \"Hey!\" data [ \"Foo\" ][ \"bar\" ][ \"baz\" ] = \"hmmm\" print ( json . dumps ( data , indent = 1 )) { \"Hello\": \"Hey!\", \"Foo\": { \"bar\": { \"baz\": \"hmmm\" } } }","title":"Defaultdict"},{"location":"DS/pyDefaultdict/#inner-working-of-defaultdict","text":"Defaultdict adds one writable instance variable and one method in addition to the standard dictionary operations. The instance variable is the default_factory parameter and the method provided is missing. Default_factory: It is a function returning the default value for the dictionary defined. If this argument is absent then the dictionary raises a KeyError. # Python program to demonstrate # default_factory argument of # defaultdict from collections import defaultdict # Defining the dict and passing # lambda as default_factory argument d = defaultdict ( lambda : \"Not Present\" ) d [ \"a\" ] = 1 d [ \"b\" ] = 2 print ( d [ \"a\" ]) print ( d [ \"b\" ]) print ( d [ \"c\" ]) 1 2 Not Present from collections import defaultdict # Correct instantiation def_dict = defaultdict ( list ) # Pass list to .default_factory def_dict [ 'one' ] = 1 # Add a key-value pair def_dict [ 'missing' ] # Access a missing key returns an empty list [] def_dict [ 'another_missing' ] . append ( 4 ) # Modify a missing key def_dict defaultdict(list, {'another_missing': [4], 'missing': [], 'one': 1}) dep = [( 'Sales' , 'John Doe' ), ( 'Sales' , 'Martin Smith' ), ( 'Accounting' , 'Jane Doe' ), ( 'Marketing' , 'Elizabeth Smith' ), ( 'Marketing' , 'Adam Doe' )] from collections import defaultdict dep_dd = defaultdict ( list ) #For uniqueness instead of list use set for department , employee in dep : dep_dd [ department ] . append ( employee ) print ( dep_dd ) defaultdict(<class 'list'>, {'Sales': ['John Doe', 'Martin Smith'], 'Accounting': ['Jane Doe'], 'Marketing': ['Elizabeth Smith', 'Adam Doe']}) In this example, you group the employees by their department using a defaultdict with .default_factory set to list. To do this with a regular dictionary, you can use dict.setdefault() as follows: dep_d = dict () for department , employee in dep : dep_d . setdefault ( department , []) . append ( employee ) print ( dep_d ) {'Sales': ['John Doe', 'Martin Smith'], 'Accounting': ['Jane Doe'], 'Marketing': ['Elizabeth Smith', 'Adam Doe']} This code is straightforward, and you\u2019ll find similar code quite often in your work as a Python coder. However, the defaultdict version is arguably more readable, and for large datasets, it can also be a lot faster and more efficient. So, if speed is a concern for you, then you should consider using a defaultdict instead of a standard dict.","title":"Inner Working of defaultdict"},{"location":"DS/pyDefaultdict/#auto-vivification","text":"Defauldict are used to easily make nested dicts. It is called Auto-vivification. from collections import defaultdict import json def turtles (): return defaultdict ( turtles ) data = turtles () data [ \"Hello\" ] = \"Hey!\" data [ \"Foo\" ][ \"bar\" ][ \"baz\" ] = \"hmmm\" print ( json . dumps ( data , indent = 1 )) { \"Hello\": \"Hey!\", \"Foo\": { \"bar\": { \"baz\": \"hmmm\" } } }","title":"Auto-vivification"},{"location":"DS/pyDict/","text":"Since you've seen parenthesis (for tuples) and square brackets (for lists), you may be wondering what curly braces are used for in Python. The answer: Python dictionaries. The defining feature of a Python dictionary is that it has keys and values that are associated with each other. When defining a dictionary, this association may be accomplished using the colon (:) as is done below. Dictionaries are data structures used to map arbitrary keys to values. Lists can be thought of as dictionaries with integer keys within a certain range. Dictionaries can be indexed in the same way as lists, using square brackets containing keys. Dict Creation An empty dictionary is defined as {}. Dictionary can also be created by the built-in function dict(). # Creating an empty Dictionary Dict = {} print ( \"Empty Dictionary: \" ) print ( Dict ) # Creating a Dictionary # with dict() method Dict = dict ({ 1 : 'Trips' , 2 : 'For' , 3 : 'chips' }) print ( \" \\n Dictionary with the use of dict(): \" ) print ( Dict ) # Creating a Dictionary # with each item as a Pair Dict = dict ([( 1 , 'Trips' ), ( 2 , 'For' )]) print ( \" \\n Dictionary with each item as a pair: \" ) print ( Dict ) Empty Dictionary: {} Dictionary with the use of dict(): {1: 'Trips', 2: 'For', 3: 'chips'} Dictionary with each item as a pair: {1: 'Trips', 2: 'For'} Dict = {} #Set default value Dict . setdefault ( 1 , 'Trips' ) Dict . setdefault ( 3 , 'chips' ) print ( Dict ) {1: 'Trips', 3: 'chips'} empty_dic = {} book_dictionary = { \"Title\" : \"Frankenstein\" , \"Author\" : \"Mary Shelley\" , \"Year\" : 1818 } print ( book_dictionary [ \"Author\" ]) Mary Shelley Above, the keys of the book_dictionary are \"Title\", \"Author\", and \"Year\", and each of these keys has a corresponding value associated with it. Notice that the key-value pairs are separated by a comma. Using keys allows us to access a piece of the dictionary by its name, rather than needing to know the index of the piece that we want, as is the case with lists and tuples. For instance, above we could get the author of Frankenstein using the \"Author\" key, rather than using an index. In fact, unlike in a list or tuple, the order of elements in a dictionary doesn't matter, and dictionaries cannot be indexed using integers, which we see below when we try to access the second element of the dictionary using an integer: print ( book_dictionary [ 1 ]) --------------------------------------------------------------------------- KeyError Traceback (most recent call last) <ipython-input-11-43bbaea82a52> in <module>() ----> 1 print(book_dictionary[1]) KeyError: 1 Just like lists, dictionary keys can be assigned to different values. However, unlike lists, a new dictionary key can also be assigned a value, not just ones that already exist. squares = { 1 : 1 , 2 : 4 , 3 : \"Error\" , 4 : 16 ,} squares [ 8 ] = 64 squares [ 3 ] = 9 print ( squares ) {1: 1, 2: 4, 3: 9, 4: 16, 8: 64} in operator To determine whether a key is in a dictionary, you can use in and not in, just as you can for a list. nums = { 1 : \"one\" , 2 : \"two\" , 3 : \"three\" ,} print ( 1 in nums ) print ( \"three\" in nums ) print ( 4 not in nums ) True False True Dictionary Functions get() A useful dictionary method is get. It does the same thing as indexing, but if the key is not found in the dictionary it returns another specified value instead ('None', by default). pairs = { 1 : \"apple\" , \"orange\" :[ 2 , 3 , 4 ], True : False , None : \"True\" } print ( pairs . get ( \"orange\" )) print ( pairs . get ( 7 )) print ( pairs . get ( 12345 , \"not in dictionary\" )) ##Default message when not found fib = { 1 : 1 , 2 : 1 , 3 : 2 , 4 : 3 ,} print ( fib . get ( 4 , 0 ) + fib . get ( 7 , 5 )) [2, 3, 4] None not in dictionary 8 values() To iterate over the values of a dictionary, you can use the .values() function: for value in data . values (): pass Other funtions: copy() They copy() method returns a shallow copy of the dictionary. clear() The clear() method removes all items from the dictionary. pop() Removes and returns an element from a dictionary having the given key. popitem() Removes the arbitrary key-value pair from the dictionary and returns it as tuple. get() It is a conventional method to access a value for a key. dictionary_name.values() returns a list of all the values available in a given dictionary. str() Produces a printable string representation of a dictionary. update() Adds dictionary dict2\u2019s key-values pairs to dict setdefault() Set dict[key]=default if key is not already in dict keys() Returns list of dictionary dict\u2019s keys items() Returns a list of dict\u2019s (key, value) tuple pairs has_key() Returns true if key in dictionary dict, false otherwise fromkeys() Create a new dictionary with keys from seq and values set to value. type() Returns the type of the passed variable. cmp() Compares elements of both dict.","title":"Dictionary"},{"location":"DS/pyDict/#dict-creation","text":"An empty dictionary is defined as {}. Dictionary can also be created by the built-in function dict(). # Creating an empty Dictionary Dict = {} print ( \"Empty Dictionary: \" ) print ( Dict ) # Creating a Dictionary # with dict() method Dict = dict ({ 1 : 'Trips' , 2 : 'For' , 3 : 'chips' }) print ( \" \\n Dictionary with the use of dict(): \" ) print ( Dict ) # Creating a Dictionary # with each item as a Pair Dict = dict ([( 1 , 'Trips' ), ( 2 , 'For' )]) print ( \" \\n Dictionary with each item as a pair: \" ) print ( Dict ) Empty Dictionary: {} Dictionary with the use of dict(): {1: 'Trips', 2: 'For', 3: 'chips'} Dictionary with each item as a pair: {1: 'Trips', 2: 'For'} Dict = {} #Set default value Dict . setdefault ( 1 , 'Trips' ) Dict . setdefault ( 3 , 'chips' ) print ( Dict ) {1: 'Trips', 3: 'chips'} empty_dic = {} book_dictionary = { \"Title\" : \"Frankenstein\" , \"Author\" : \"Mary Shelley\" , \"Year\" : 1818 } print ( book_dictionary [ \"Author\" ]) Mary Shelley Above, the keys of the book_dictionary are \"Title\", \"Author\", and \"Year\", and each of these keys has a corresponding value associated with it. Notice that the key-value pairs are separated by a comma. Using keys allows us to access a piece of the dictionary by its name, rather than needing to know the index of the piece that we want, as is the case with lists and tuples. For instance, above we could get the author of Frankenstein using the \"Author\" key, rather than using an index. In fact, unlike in a list or tuple, the order of elements in a dictionary doesn't matter, and dictionaries cannot be indexed using integers, which we see below when we try to access the second element of the dictionary using an integer: print ( book_dictionary [ 1 ]) --------------------------------------------------------------------------- KeyError Traceback (most recent call last) <ipython-input-11-43bbaea82a52> in <module>() ----> 1 print(book_dictionary[1]) KeyError: 1 Just like lists, dictionary keys can be assigned to different values. However, unlike lists, a new dictionary key can also be assigned a value, not just ones that already exist. squares = { 1 : 1 , 2 : 4 , 3 : \"Error\" , 4 : 16 ,} squares [ 8 ] = 64 squares [ 3 ] = 9 print ( squares ) {1: 1, 2: 4, 3: 9, 4: 16, 8: 64}","title":"Dict Creation"},{"location":"DS/pyDict/#in-operator","text":"To determine whether a key is in a dictionary, you can use in and not in, just as you can for a list. nums = { 1 : \"one\" , 2 : \"two\" , 3 : \"three\" ,} print ( 1 in nums ) print ( \"three\" in nums ) print ( 4 not in nums ) True False True","title":"in operator"},{"location":"DS/pyDict/#dictionary-functions","text":"","title":"Dictionary Functions"},{"location":"DS/pyDict/#get","text":"A useful dictionary method is get. It does the same thing as indexing, but if the key is not found in the dictionary it returns another specified value instead ('None', by default). pairs = { 1 : \"apple\" , \"orange\" :[ 2 , 3 , 4 ], True : False , None : \"True\" } print ( pairs . get ( \"orange\" )) print ( pairs . get ( 7 )) print ( pairs . get ( 12345 , \"not in dictionary\" )) ##Default message when not found fib = { 1 : 1 , 2 : 1 , 3 : 2 , 4 : 3 ,} print ( fib . get ( 4 , 0 ) + fib . get ( 7 , 5 )) [2, 3, 4] None not in dictionary 8","title":"get()"},{"location":"DS/pyDict/#values","text":"To iterate over the values of a dictionary, you can use the .values() function: for value in data . values (): pass","title":"values()"},{"location":"DS/pyDict/#other-funtions","text":"copy() They copy() method returns a shallow copy of the dictionary. clear() The clear() method removes all items from the dictionary. pop() Removes and returns an element from a dictionary having the given key. popitem() Removes the arbitrary key-value pair from the dictionary and returns it as tuple. get() It is a conventional method to access a value for a key. dictionary_name.values() returns a list of all the values available in a given dictionary. str() Produces a printable string representation of a dictionary. update() Adds dictionary dict2\u2019s key-values pairs to dict setdefault() Set dict[key]=default if key is not already in dict keys() Returns list of dictionary dict\u2019s keys items() Returns a list of dict\u2019s (key, value) tuple pairs has_key() Returns true if key in dictionary dict, false otherwise fromkeys() Create a new dictionary with keys from seq and values set to value. type() Returns the type of the passed variable. cmp() Compares elements of both dict.","title":"Other funtions:"},{"location":"DS/pyGen/","text":"Generators are a type of iterable, like lists or tuples. Unlike lists, they don't allow indexing with arbitrary indices, but they can still be iterated through with for loops. They can be created using functions and the yield statement. The yield statement is used to define a generator, replacing the return of a function to provide a result to its caller without destroying local variables. Generators are a shortcut to write functions that implement iterators. def countdown (): i = 5 while i > 0 : yield i i -= 1 for i in countdown (): print ( i ) 5 4 3 2 1 Due to the fact that they yield one item at a time, generators don't have the memory restrictions of lists. In fact, they can be infinite! generators allow you to declare a function that behaves like an iterator, i.e. it can be used in a for loop. Finite generators can be converted into lists by passing them as arguments to the list function.Using generators results in improved performance, which is the result of the lazy (on demand) generation of values, which translates to lower memory usage. Furthermore, we do not need to wait until all the elements have been generated before we start to use them. def numbers ( x ): for i in range ( x ): if i % 2 == 0 : yield i print ( list ( numbers ( 11 ))) [0, 2, 4, 6, 8, 10]","title":"Generators"},{"location":"DS/pyGenX/","text":"These are almost comprehension, but we don\u00b4t want to collect the results in a list, dict or set. Rather, we want to consume them inmediately, one by one. No data structure is created so we save memory and time. Sum the squares of the first 10 even numbers sum ( i ** 2 for i in range ( 20 ) if i % 2 == 0 ) 1140 even = i ** 2 for i in range ( 20 ) if i % 2 == 0 even = i**2 for i in range(20) if i%2 == 0 ^ SyntaxError: invalid syntax It needs parentheses!! even = ( i ** 2 for i in range ( 20 ) if i % 2 == 0 ) What is even? It is a generator object. So it implements the iterator protocol. Therefore, we can used it in loops or feed it to functions like sum that accept iterators. even <generator object <genexpr> at 0x7f8ff8005cd0> even . __next__ () 0 even . __next__ () 4 even . __next__ () 16 When one line is not sufficient but you still want the convinience of iterators. You can write a function called generator which has the special keyword yield def fibonacci () : print ( \"Let's get set!\" ) f1 , f2 = 0 , 1 while True : yield f2 f1 , f2 = f2 , f1 + f2 f = fibonacci () f <generator object fibonacci at 0x7f2ec8ba3550> f . __next__ () f . __next__ () f . __next__ () #the same as next ( f ) next ( f ) for x in fibonacci (): if x > 1000 : break print ( x ) Let's get set! 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 def fibonacci ( fmax ) : print ( \"Let's get set!\" ) f1 , f2 = 0 , 1 while True : yield f2 f1 , f2 = f2 , f1 + f2 if f2 > fmax : return [ x for x in fibonacci ( 1000 )] Let's get set! [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987] Advance concepts for generators Context Managers Coroutines","title":"Generator Expressions"},{"location":"DS/pyGenX/#advance-concepts-for-generators","text":"Context Managers Coroutines","title":"Advance concepts for generators"},{"location":"DS/pyGraph/","text":"Graphs are used to represent many real-life applications like networks, transportation paths of a city, and social network connections. A graph is a set of connected nodes where each node is called a Vertex and the connection between two of them is called an Edge. A graph can be represented using a square matrix, where each element represents the edges: 0 indicates no edge, while 1 indicates an edge. The rows and columns represent the vertices. This type of matrix is called an adjacency matrix, because it shows if the corresponding vertices are adjacent or not. class Graph (): def __init__ ( self , size ): self . adj = [ [ 0 ] * size for i in range ( size )] self . size = size def add_edge ( self , orig , dest ): if orig > self . size or dest > self . size or orig < 0 or dest < 0 : print ( \"Invalid Edge\" ) else : self . adj [ orig - 1 ][ dest - 1 ] = 1 self . adj [ dest - 1 ][ orig - 1 ] = 1 def remove_edge ( self , orig , dest ): if orig > self . size or dest > self . size or orig < 0 or dest < 0 : print ( \"Invalid Edge\" ) else : self . adj [ orig - 1 ][ dest - 1 ] = 0 self . adj [ dest - 1 ][ orig - 1 ] = 0 def display ( self ): for row in self . adj : print () for val in row : print ( ' {:4} ' . format ( val ), end = \"\" ) A graph is a collection of nodes and edges, where nodes often represent objects or ideas, and edges represent relationships among them. For example, in a graph that represents a social network, nodes might represent people and edges might represent friendships between them. NetworkX provides data structures to represent graphs and function that implement graph algorithms. To show how it works, we\u2019ll make a small graph that represents a social network. Here\u2019s how we make a graph and add nodes. import networkx as nx G = nx . Graph () G . add_node ( 'Alice' ) G . add_node ( 'Bob' , age = 23 ) G . add_node ( 'Carol' , cat = 'mittens' ) list ( G . nodes ()) ['Alice', 'Bob', 'Carol'] Optionally, you can provide attributes that are associated with the node. In this example, Bob has an age attribute and Carol has a cat. Here\u2019s how we add edges between nodes. G . add_edge ( 'Alice' , 'Bob' ) G . add_edge ( 'Alice' , 'Carol' , type = 'enemy' ) list ( G . edges ()) [('Alice', 'Bob'), ('Alice', 'Carol')] Optionally, you can provide attributes that are associated with the edge. In this example, the second edge has an attribute called type that indicates the nature of the relationship. Here\u2019s how to draw the graph. def draw_graph ( G ): nx . draw_circular ( G , node_size = 1500 , with_labels = True ) draw_graph ( G ) Graph Representation NetworkX represents graphs using a dictionary that maps from each node to a dictionary that maps from nodes to edges. If we select an element from the top-level dictionary, the result is a dictionary-like object. G [ 'Alice' ] AtlasView({'Bob': {}, 'Carol': {'type': 'enemy'}}) So we can iterate through the neighbors of a node like this: for neighbor in G [ 'Alice' ]: print ( neighbor ) Bob Carol Or enumerate the neighbors and edges like this: for key , value in G [ 'Alice' ] . items (): print ( key , value ) Bob {} Carol {'type': 'enemy'} Edges are represented by dictionaries of attributes. In this example, the first edge has no attributes and the second has an attribute named type. We can select an edge like this: G [ 'Alice' ][ 'Carol' ] {'type': 'enemy'} To check whether there is an edge from one node to another, we can use the in operator: def has_edge ( G , u , v ): return v in G [ u ] has_edge ( G , 'Alice' , 'Bob' ) True But there\u2019s a method that does the same thing. G . has_edge ( 'Alice' , 'Bob' ) True Complete Graphs In a complete graph, all nodes are connected to each other. To make a complete graph, we\u2019ll use the following generator function, iterates through all pairs of nodes. def all_pairs ( nodes ): for i , u in enumerate ( nodes ): for j , v in enumerate ( nodes ): if i < j : yield u , v Here\u2019s a complete graph with 10 nodes: def make_complete_graph ( n ): nodes = range ( n ) G = nx . Graph () G . add_nodes_from ( nodes ) G . add_edges_from ( all_pairs ( nodes )) return G complete = make_complete_graph ( 10 ) And here\u2019s what it looks like. draw_graph ( complete ) Random Graphs Next we\u2019ll make an Erdos-Renyi graph, which is a random graph where the probability of an edge between each pair of nodes is . The helper function flip returns True with probability p and False with probability 1-p import random def flip ( p ): return random . random () < p random_pairs is a generator function that enumerates all possible pairs of nodes and yields each one with probability p def random_pairs ( nodes , p ): for edge in all_pairs ( nodes ): if flip ( p ): yield edge make_random_graph makes an ER graph where the probability of an edge between each pair of nodes is p. def make_random_graph ( n , p ): nodes = range ( n ) G = nx . Graph () G . add_nodes_from ( nodes ) G . add_edges_from ( random_pairs ( nodes , p )) return G Here\u2019s an example with n=10 and p=0.3 random_graph = make_random_graph ( 10 , 0.3 ) len ( random_graph . edges ()) 10 And here\u2019s what it looks like: draw_graph ( random_graph ) Connectivity A graph is connected if you can start from any node and follow a sequence of edges to reach any other node. To check whether a graph is connected, we\u2019ll use a version of a depth-first search. For most graphs, the basic version of DFS runs forever, because it visits the same nodes over and over. The solution is to keep track of the nodes we\u2019ve seen and avoid visiting them more than once. In the complete graph, starting from node 0, we can reach all nodes. In a random graph, it may or may not be possible to reach all nodes. Watts-Strogatz Graphs A Watts-Strogatz (WS) graph is a random graph, like an Erdos-Renyi graph, but the construction process is different. A WS graph starts with a ring lattice and randomly \u201crewires\u201d some of the edges. NetworkX provides a function that makes a WS graph, so we can see what it looks like. Here\u2019s an example with n=10 nodes, each connected to k=2 neighbors, with probability p=0 of rewiring each edge. import networkx as nx G = nx . watts_strogatz_graph ( n = 10 , k = 3 , p = 0 ) G . nodes () NodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9)) The result is a ring where each node holds hands with its immediate neighbors. def draw_graph ( G ): nx . draw_circular ( G , node_size = 1000 , with_labels = True ) draw_graph ( G ) Note: If k is odd, it gets \u201crounded down\u201d to an even number. Depth-First Search def reachable_nodes ( G , start ): seen = set () stack = [ start ] while stack : node = stack . pop () if node not in seen : seen . add ( node ) stack . extend ( G [ node ]) return seen reachable_nodes ( G , 0 ) {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} Fast Breadth-First Search NetworkX provides a simple, fast implementation of BFS, available from the NetworkX repository on GitHub. Here is a version I modified to return a set of nodes: def plain_bfs ( G , start ): seen = set () nextlevel = { start } while nextlevel : thislevel = nextlevel nextlevel = set () for v in thislevel : if v not in seen : seen . add ( v ) nextlevel . update ( G [ v ]) return seen Let\u2019s compare this function to reachable_nodes_bfs and see which is faster. G = nx . watts_strogatz_graph ( 1000 , 10 , 0.01 ) % timeit plain_bfs ( G , 0 ) 100 loops, best of 5: 1.98 ms per loop","title":"Graphs"},{"location":"DS/pyGraph/#graph-representation","text":"NetworkX represents graphs using a dictionary that maps from each node to a dictionary that maps from nodes to edges. If we select an element from the top-level dictionary, the result is a dictionary-like object. G [ 'Alice' ] AtlasView({'Bob': {}, 'Carol': {'type': 'enemy'}}) So we can iterate through the neighbors of a node like this: for neighbor in G [ 'Alice' ]: print ( neighbor ) Bob Carol Or enumerate the neighbors and edges like this: for key , value in G [ 'Alice' ] . items (): print ( key , value ) Bob {} Carol {'type': 'enemy'} Edges are represented by dictionaries of attributes. In this example, the first edge has no attributes and the second has an attribute named type. We can select an edge like this: G [ 'Alice' ][ 'Carol' ] {'type': 'enemy'} To check whether there is an edge from one node to another, we can use the in operator: def has_edge ( G , u , v ): return v in G [ u ] has_edge ( G , 'Alice' , 'Bob' ) True But there\u2019s a method that does the same thing. G . has_edge ( 'Alice' , 'Bob' ) True","title":"Graph Representation"},{"location":"DS/pyGraph/#complete-graphs","text":"In a complete graph, all nodes are connected to each other. To make a complete graph, we\u2019ll use the following generator function, iterates through all pairs of nodes. def all_pairs ( nodes ): for i , u in enumerate ( nodes ): for j , v in enumerate ( nodes ): if i < j : yield u , v Here\u2019s a complete graph with 10 nodes: def make_complete_graph ( n ): nodes = range ( n ) G = nx . Graph () G . add_nodes_from ( nodes ) G . add_edges_from ( all_pairs ( nodes )) return G complete = make_complete_graph ( 10 ) And here\u2019s what it looks like. draw_graph ( complete )","title":"Complete Graphs"},{"location":"DS/pyGraph/#random-graphs","text":"Next we\u2019ll make an Erdos-Renyi graph, which is a random graph where the probability of an edge between each pair of nodes is . The helper function flip returns True with probability p and False with probability 1-p import random def flip ( p ): return random . random () < p random_pairs is a generator function that enumerates all possible pairs of nodes and yields each one with probability p def random_pairs ( nodes , p ): for edge in all_pairs ( nodes ): if flip ( p ): yield edge make_random_graph makes an ER graph where the probability of an edge between each pair of nodes is p. def make_random_graph ( n , p ): nodes = range ( n ) G = nx . Graph () G . add_nodes_from ( nodes ) G . add_edges_from ( random_pairs ( nodes , p )) return G Here\u2019s an example with n=10 and p=0.3 random_graph = make_random_graph ( 10 , 0.3 ) len ( random_graph . edges ()) 10 And here\u2019s what it looks like: draw_graph ( random_graph )","title":"Random Graphs"},{"location":"DS/pyGraph/#connectivity","text":"A graph is connected if you can start from any node and follow a sequence of edges to reach any other node. To check whether a graph is connected, we\u2019ll use a version of a depth-first search. For most graphs, the basic version of DFS runs forever, because it visits the same nodes over and over. The solution is to keep track of the nodes we\u2019ve seen and avoid visiting them more than once. In the complete graph, starting from node 0, we can reach all nodes. In a random graph, it may or may not be possible to reach all nodes.","title":"Connectivity"},{"location":"DS/pyGraph/#watts-strogatz-graphs","text":"A Watts-Strogatz (WS) graph is a random graph, like an Erdos-Renyi graph, but the construction process is different. A WS graph starts with a ring lattice and randomly \u201crewires\u201d some of the edges. NetworkX provides a function that makes a WS graph, so we can see what it looks like. Here\u2019s an example with n=10 nodes, each connected to k=2 neighbors, with probability p=0 of rewiring each edge. import networkx as nx G = nx . watts_strogatz_graph ( n = 10 , k = 3 , p = 0 ) G . nodes () NodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9)) The result is a ring where each node holds hands with its immediate neighbors. def draw_graph ( G ): nx . draw_circular ( G , node_size = 1000 , with_labels = True ) draw_graph ( G ) Note: If k is odd, it gets \u201crounded down\u201d to an even number.","title":"Watts-Strogatz Graphs"},{"location":"DS/pyGraph/#depth-first-search","text":"def reachable_nodes ( G , start ): seen = set () stack = [ start ] while stack : node = stack . pop () if node not in seen : seen . add ( node ) stack . extend ( G [ node ]) return seen reachable_nodes ( G , 0 ) {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}","title":"Depth-First Search"},{"location":"DS/pyGraph/#fast-breadth-first-search","text":"NetworkX provides a simple, fast implementation of BFS, available from the NetworkX repository on GitHub. Here is a version I modified to return a set of nodes: def plain_bfs ( G , start ): seen = set () nextlevel = { start } while nextlevel : thislevel = nextlevel nextlevel = set () for v in thislevel : if v not in seen : seen . add ( v ) nextlevel . update ( G [ v ]) return seen Let\u2019s compare this function to reachable_nodes_bfs and see which is faster. G = nx . watts_strogatz_graph ( 1000 , 10 , 0.01 ) % timeit plain_bfs ( G , 0 ) 100 loops, best of 5: 1.98 ms per loop","title":"Fast Breadth-First Search"},{"location":"DS/pyHeapQueue/","text":"Heap data structure is mainly used to represent a priority queue. In Python, it is available using \u201cheapq\u201d module. The property of this data structure in Python is that each time the smallest of heap element is popped(min heap). Whenever elements are pushed or popped, heap structure is maintained. The heap[0] element also returns the smallest element each time. If the list is a heap, the tree should have the heap property: Every parent is less than or equal to its children. heapify(iterable) This function is used to convert the iterable into a heap data structure. i.e. in heap order. heappush(heap, ele) This function is used to insert the element mentioned in its arguments into heap. The order is adjusted, so as heap structure is maintained. heappop(heap) This function is used to remove and return the smallest element from heap. The order is adjusted, so as heap structure is maintained. # Python code to demonstrate working of # heapify(), heappush() and heappop() # importing \"heapq\" to implement heap queue import heapq # initializing list li = [ 5 , 7 , 9 , 1 , 3 ] # using heapify to convert list into heap heapq . heapify ( li ) # printing created heap print ( \"The created heap is : \" , end = \"\" ) print ( list ( li )) # using heappush() to push elements into heap # pushes 4 heapq . heappush ( li , 4 ) # printing modified heap print ( \"The modified heap after push is : \" , end = \"\" ) print ( list ( li )) # using heappop() to pop smallest element print ( \"The popped and smallest element is : \" , end = \"\" ) print ( heapq . heappop ( li )) The created heap is : [1, 3, 9, 7, 5] The modified heap after push is : [1, 3, 4, 7, 5, 9] The popped and smallest element is : 1 heappushpop(heap, ele) This function combines the functioning of both push and pop operations in one statement, increasing efficiency. Heap order is maintained after this operation. heapreplace(heap, ele) This function also inserts and pops element in one statement, but it is different from above function. In this, element is first popped, then the element is pushed.i.e, the value larger than the pushed value can be returned. heapreplace() returns the smallest value originally in heap regardless of the pushed element as opposed to heappushpop(). # Python code to demonstrate working of # heappushpop() and heapreplce() # importing \"heapq\" to implement heap queue import heapq # initializing list 1 li1 = [ 5 , 7 , 9 , 4 , 3 ] # initializing list 2 li2 = [ 5 , 7 , 9 , 4 , 3 ] # using heapify() to convert list into heap heapq . heapify ( li1 ) heapq . heapify ( li2 ) # using heappushpop() to push and pop items simultaneously # pops 2 print ( \"The popped item using heappushpop() is : \" , end = \"\" ) print ( heapq . heappushpop ( li1 , 2 )) # using heapreplace() to push and pop items simultaneously # pops 3 print ( \"The popped item using heapreplace() is : \" , end = \"\" ) print ( heapq . heapreplace ( li2 , 2 )) The popped item using heappushpop() is : 2 The popped item using heapreplace() is : 3 nlargest(k, iterable, key = fun) This function is used to return the k largest elements from the iterable specified and satisfying the key if mentioned. nsmallest(k, iterable, key = fun) This function is used to return the k smallest elements from the iterable specified and satisfying the key if mentioned. # Python code to demonstrate working of # nlargest() and nsmallest() # importing \"heapq\" to implement heap queue import heapq # initializing list li1 = [ 6 , 7 , 9 , 4 , 3 , 5 , 8 , 10 , 1 ] # using heapify() to convert list into heap heapq . heapify ( li1 ) # using nlargest to print 3 largest numbers # prints 10, 9 and 8 print ( \"The 3 largest numbers in list are : \" , end = \"\" ) print ( heapq . nlargest ( 3 , li1 )) # using nsmallest to print 3 smallest numbers # prints 1, 3 and 4 print ( \"The 3 smallest numbers in list are : \" , end = \"\" ) print ( heapq . nsmallest ( 3 , li1 )) The 3 largest numbers in list are : [10, 9, 8] The 3 smallest numbers in list are : [1, 3, 4]","title":"HeapQueue"},{"location":"DS/pyHeapQueue/#heapifyiterable","text":"This function is used to convert the iterable into a heap data structure. i.e. in heap order.","title":"heapify(iterable)"},{"location":"DS/pyHeapQueue/#heappushheap-ele","text":"This function is used to insert the element mentioned in its arguments into heap. The order is adjusted, so as heap structure is maintained.","title":"heappush(heap, ele)"},{"location":"DS/pyHeapQueue/#heappopheap","text":"This function is used to remove and return the smallest element from heap. The order is adjusted, so as heap structure is maintained. # Python code to demonstrate working of # heapify(), heappush() and heappop() # importing \"heapq\" to implement heap queue import heapq # initializing list li = [ 5 , 7 , 9 , 1 , 3 ] # using heapify to convert list into heap heapq . heapify ( li ) # printing created heap print ( \"The created heap is : \" , end = \"\" ) print ( list ( li )) # using heappush() to push elements into heap # pushes 4 heapq . heappush ( li , 4 ) # printing modified heap print ( \"The modified heap after push is : \" , end = \"\" ) print ( list ( li )) # using heappop() to pop smallest element print ( \"The popped and smallest element is : \" , end = \"\" ) print ( heapq . heappop ( li )) The created heap is : [1, 3, 9, 7, 5] The modified heap after push is : [1, 3, 4, 7, 5, 9] The popped and smallest element is : 1","title":"heappop(heap)"},{"location":"DS/pyHeapQueue/#heappushpopheap-ele","text":"This function combines the functioning of both push and pop operations in one statement, increasing efficiency. Heap order is maintained after this operation.","title":"heappushpop(heap, ele)"},{"location":"DS/pyHeapQueue/#heapreplaceheap-ele","text":"This function also inserts and pops element in one statement, but it is different from above function. In this, element is first popped, then the element is pushed.i.e, the value larger than the pushed value can be returned. heapreplace() returns the smallest value originally in heap regardless of the pushed element as opposed to heappushpop(). # Python code to demonstrate working of # heappushpop() and heapreplce() # importing \"heapq\" to implement heap queue import heapq # initializing list 1 li1 = [ 5 , 7 , 9 , 4 , 3 ] # initializing list 2 li2 = [ 5 , 7 , 9 , 4 , 3 ] # using heapify() to convert list into heap heapq . heapify ( li1 ) heapq . heapify ( li2 ) # using heappushpop() to push and pop items simultaneously # pops 2 print ( \"The popped item using heappushpop() is : \" , end = \"\" ) print ( heapq . heappushpop ( li1 , 2 )) # using heapreplace() to push and pop items simultaneously # pops 3 print ( \"The popped item using heapreplace() is : \" , end = \"\" ) print ( heapq . heapreplace ( li2 , 2 )) The popped item using heappushpop() is : 2 The popped item using heapreplace() is : 3","title":"heapreplace(heap, ele)"},{"location":"DS/pyHeapQueue/#nlargestk-iterable-key-fun","text":"This function is used to return the k largest elements from the iterable specified and satisfying the key if mentioned.","title":"nlargest(k, iterable, key = fun)"},{"location":"DS/pyHeapQueue/#nsmallestk-iterable-key-fun","text":"This function is used to return the k smallest elements from the iterable specified and satisfying the key if mentioned. # Python code to demonstrate working of # nlargest() and nsmallest() # importing \"heapq\" to implement heap queue import heapq # initializing list li1 = [ 6 , 7 , 9 , 4 , 3 , 5 , 8 , 10 , 1 ] # using heapify() to convert list into heap heapq . heapify ( li1 ) # using nlargest to print 3 largest numbers # prints 10, 9 and 8 print ( \"The 3 largest numbers in list are : \" , end = \"\" ) print ( heapq . nlargest ( 3 , li1 )) # using nsmallest to print 3 smallest numbers # prints 1, 3 and 4 print ( \"The 3 smallest numbers in list are : \" , end = \"\" ) print ( heapq . nsmallest ( 3 , li1 )) The 3 largest numbers in list are : [10, 9, 8] The 3 smallest numbers in list are : [1, 3, 4]","title":"nsmallest(k, iterable, key = fun)"},{"location":"DS/pyIterAllAny/","text":"Often used in conditional statements, all and any take a list as an argument, and return True if all or any (respectively) of their arguments evaluate to True (and False otherwise). nums = [ 55 , 44 , 33 , 22 , 11 ,] if all ([ i > 5 for i in nums ]): print ( \"All larger than 5\" ) if any ([ i % 2 == 0 for i in nums ]): print ( \"At least one is even\" ) All larger than 5 At least one is even","title":"All & Any"},{"location":"DS/pyIterEnumerate/","text":"The function enumerate can be used to iterate through the values and indices of a list simultaneously. Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method. nums = [ 55 , 44 , 33 , 22 , 11 ,] #Without enumerate use index variable index = 0 for value in nums : print ( index , value ) index += 1 0 55 1 44 2 33 3 22 4 11 nums = [ 55 , 44 , 33 , 22 , 11 ,] #Using range and len for index in range ( len ( nums )): value = nums [ index ] print ( index , value ) 0 55 1 44 2 33 3 22 4 11 #using enumarate nums = [ 55 , 44 , 33 , 22 , 11 ,] for v in enumerate ( nums ): print ( v ) (0, 55) (1, 44) (2, 33) (3, 22) (4, 11) nums = [ 55 , 44 , 33 , 22 , 11 ,] for i , v in enumerate ( nums ): print ( f \"value { v } is at { i } position\" ) value 55 is at 0 position value 44 is at 1 position value 33 is at 2 position value 22 is at 3 position value 11 is at 4 position nums = [ 55 , 44 , 33 , 22 , 11 ,] for i , v in enumerate ( nums , start = 10 ): print ( f \"value { v } is at { i } position\" ) value 55 is at 10 position value 44 is at 11 position value 33 is at 12 position value 22 is at 13 position value 11 is at 14 position","title":"Enumerate"},{"location":"DS/pyIterMapFilter/","text":"The built-in functions map and filter are very useful higher-order functions that operate on lists (or similar objects called iterables). Map The function map takes a function and an iterable as arguments, and returns a new iterable with the function applied to each argument. def add_five ( x ): return x + 5 nums = [ 11 , 22 , 33 , 44 , 55 ] result = list ( map ( add_five , nums )) print ( result ) <class 'list'> [16, 27, 38, 49, 60] #the same using lambda syntax result = list ( map ( lambda x : x + 5 , nums )) print ( result ) [16, 27, 38, 49, 60] Filter The function filter filters an iterable by removing items that don't match a predicate (a function that returns a Boolean). Like map, the result has to be explicitly converted to a list if you want to print it. nums = [ 11 , 22 , 33 , 44 , 55 ] res = list ( filter ( lambda x : x % 2 == 0 , nums )) print ( res ) [22, 44] # use transform functions like sorted, filter, map def filterFunc ( x ): if x % 2 == 0 : return False return True def filterFunc2 ( x ): if x . isupper (): return False return True def squareFunc ( x ): return x ** 2 def toGrade ( x ): if ( x >= 90 ): return \"A\" elif ( x >= 80 and x < 90 ): return \"B\" elif ( x >= 70 and x < 80 ): return \"C\" elif ( x >= 65 and x < 70 ): return \"D\" return \"F\" def main (): # define some sample sequences to operate on nums = ( 1 , 8 , 4 , 5 , 13 , 26 , 381 , 410 , 58 , 47 ) chars = \"abcDeFGHiJklmnoP\" grades = ( 81 , 89 , 94 , 78 , 61 , 66 , 99 , 74 ) # use filter to remove items from a list odds = list ( filter ( filterFunc , nums )) print ( odds ) # use filter on non-numeric sequence lowers = list ( filter ( filterFunc2 , chars )) print ( lowers ) # use map to create a new sequence of values squares = list ( map ( squareFunc , nums )) print ( squares ) # use sorted and map to change numbers to grades grades = sorted ( grades ) letters = list ( map ( toGrade , grades )) print ( letters ) if __name__ == \"__main__\" : main () [1, 5, 13, 381, 47] ['a', 'b', 'c', 'e', 'i', 'k', 'l', 'm', 'n', 'o'] [1, 64, 16, 25, 169, 676, 145161, 168100, 3364, 2209] ['F', 'D', 'C', 'C', 'B', 'B', 'A', 'A']","title":"Map & Filter"},{"location":"DS/pyIterMapFilter/#map","text":"The function map takes a function and an iterable as arguments, and returns a new iterable with the function applied to each argument. def add_five ( x ): return x + 5 nums = [ 11 , 22 , 33 , 44 , 55 ] result = list ( map ( add_five , nums )) print ( result ) <class 'list'> [16, 27, 38, 49, 60] #the same using lambda syntax result = list ( map ( lambda x : x + 5 , nums )) print ( result ) [16, 27, 38, 49, 60]","title":"Map"},{"location":"DS/pyIterMapFilter/#filter","text":"The function filter filters an iterable by removing items that don't match a predicate (a function that returns a Boolean). Like map, the result has to be explicitly converted to a list if you want to print it. nums = [ 11 , 22 , 33 , 44 , 55 ] res = list ( filter ( lambda x : x % 2 == 0 , nums )) print ( res ) [22, 44] # use transform functions like sorted, filter, map def filterFunc ( x ): if x % 2 == 0 : return False return True def filterFunc2 ( x ): if x . isupper (): return False return True def squareFunc ( x ): return x ** 2 def toGrade ( x ): if ( x >= 90 ): return \"A\" elif ( x >= 80 and x < 90 ): return \"B\" elif ( x >= 70 and x < 80 ): return \"C\" elif ( x >= 65 and x < 70 ): return \"D\" return \"F\" def main (): # define some sample sequences to operate on nums = ( 1 , 8 , 4 , 5 , 13 , 26 , 381 , 410 , 58 , 47 ) chars = \"abcDeFGHiJklmnoP\" grades = ( 81 , 89 , 94 , 78 , 61 , 66 , 99 , 74 ) # use filter to remove items from a list odds = list ( filter ( filterFunc , nums )) print ( odds ) # use filter on non-numeric sequence lowers = list ( filter ( filterFunc2 , chars )) print ( lowers ) # use map to create a new sequence of values squares = list ( map ( squareFunc , nums )) print ( squares ) # use sorted and map to change numbers to grades grades = sorted ( grades ) letters = list ( map ( toGrade , grades )) print ( letters ) if __name__ == \"__main__\" : main () [1, 5, 13, 381, 47] ['a', 'b', 'c', 'e', 'i', 'k', 'l', 'm', 'n', 'o'] [1, 64, 16, 25, 169, 676, 145161, 168100, 3364, 2209] ['F', 'D', 'C', 'C', 'B', 'B', 'A', 'A']","title":"Filter"},{"location":"DS/pyIterReversed/","text":"Returns an iterator Python reversed() method returns an iterator that accesses the given sequence in the reverse order. 3 ways to reverse a sequence: iter.reverse() reverses a mutable sequence in place and is not available for inmutable sequences Slicing [::-1] creates a reversed copy of a sequence, it is the fastest but creates a copy of the sequence. Memory considerations to reverse millions of items. Used for both mutable and inmutable sequences. reversed() returns a reversed iterator, scales well to millions of items. Used for both mutable and inmutable sequences. # Python code to demonstrate working of # reversed() # For tuple seqTuple = ( 'm' , 'o' , 'r' , 'p' , 's' ) print ( list ( reversed ( seqTuple ))) # For range seqRange = range ( 1 , 5 ) print ( list ( reversed ( seqRange ))) ['s', 'p', 'r', 'o', 'm'] [4, 3, 2, 1] class pyp : vowels = [ 'a' , 'e' , 'i' , 'o' , 'u' ] # Function to reverse the list def __reversed__ ( self ): return reversed ( self . vowels ) ['u', 'o', 'i', 'e', 'a']","title":"Reversed"},{"location":"DS/pyIterSorted/","text":"Python sorted() function returns a sorted list from the iterable object. Sorted() sorts any sequence (list, tuple) and always returns a list with the elements in a sorted manner, without modifying the original sequence. x = [ 2 , 8 , 1 , 4 , 6 , 3 , 7 ] print ( \"Sorted List returned :\" ), print ( sorted ( x )) print ( \" \\n Reverse sort :\" ), print ( sorted ( x , reverse = True )) print ( \" \\n Original list not modified :\" ), print ( x ) Sorted List returned : [1, 2, 3, 4, 6, 7, 8] Reverse sort : [8, 7, 6, 4, 3, 2, 1] Original list not modified : [2, 8, 1, 4, 6, 3, 7] # List x = [ 'q' , 'w' , 'r' , 'e' , 't' , 'y' ] print ( f 'List : { sorted ( x ) } ' ) # Tuple x = ( 'q' , 'w' , 'e' , 'r' , 't' , 'y' ) print ( f 'Tuple : { sorted ( x ) } ' ) # String-sorted based on ASCII translations x = \"python\" print ( f 'String : { sorted ( x ) } ' ) # Dictionary x = { 'q' : 1 , 'w' : 2 , 'e' : 3 , 'r' : 4 , 't' : 5 , 'y' : 6 } print ( f 'Dict : { sorted ( x ) } ' ) # Set x = { 'q' , 'w' , 'e' , 'r' , 't' , 'y' } print ( f 'Set : { sorted ( x ) } ' ) # Frozen Set x = frozenset (( 'q' , 'w' , 'e' , 'r' , 't' , 'y' )) print ( f 'Frozen Set : { sorted ( x ) } ' ) List : ['e', 'q', 'r', 't', 'w', 'y'] Tuple : ['e', 'q', 'r', 't', 'w', 'y'] String : ['h', 'n', 'o', 'p', 't', 'y'] Dict : ['e', 'q', 'r', 't', 'w', 'y'] Set : ['e', 'q', 'r', 't', 'w', 'y'] Frozen Set : ['e', 'q', 'r', 't', 'w', 'y'] L = [ \"cccc\" , \"b\" , \"dd\" , \"aaa\" ] print ( \"Normal sort :\" , sorted ( L )) print ( \"Sort with len :\" , sorted ( L , key = len )) Normal sort : ['aaa', 'b', 'cccc', 'dd'] Sort with len : ['b', 'dd', 'aaa', 'cccc'] # Sort a list of integers based on # their remainder on dividing from 7 def func ( x ): return x % 7 L = [ 15 , 3 , 11 , 7 ] print ( \"Normal sort :\" , sorted ( L )) print ( \"Sorted with key:\" , sorted ( L , key = func )) Normal sort : [3, 7, 11, 15] Sorted with key: [7, 15, 3, 11]","title":"Sorted"},{"location":"DS/pyIterZip/","text":"Zip Python zip() method takes iterable or containers and returns a single iterator object, having mapped values from all the containers. It is used to map the similar index of multiple containers so that they can be used just using a single entity. name = [ \"Manjeet\" , \"Nikhil\" , \"Shambhavi\" , \"Astha\" ] roll_no = [ 4 , 1 , 3 , 2 ] # using zip() to map values mapped = zip ( name , roll_no ) print ( set ( mapped )) {('Shambhavi', 3), ('Nikhil', 1), ('Astha', 2), ('Manjeet', 4)} names = [ 'Mukesh' , 'Roni' , 'Chari' ] ages = [ 24 , 50 , 18 ] for i , ( name , age ) in enumerate ( zip ( names , ages )): print ( i , name , age ) 0 Mukesh 24 1 Roni 50 2 Chari 18 stocks = [ 'reliance' , 'infosys' , 'tcs' ] prices = [ 2175 , 1127 , 2750 ] new_dict = { stocks : prices for stocks , prices in zip ( stocks , prices )} print ( new_dict ) {'reliance': 2175, 'infosys': 1127, 'tcs': 2750} Unzip How to unzip? Unzipping means converting the zipped values back to the individual self as they were. This is done with the help of \u201c*\u201d operator. # Python code to demonstrate the working of # unzip # initializing lists name = [ \"Manjeet\" , \"Nikhil\" , \"Shambhavi\" , \"Astha\" ] roll_no = [ 4 , 1 , 3 , 2 ] marks = [ 40 , 50 , 60 , 70 ] # using zip() to map values mapped = zip ( name , roll_no , marks ) # converting values to print as list mapped = list ( mapped ) # printing resultant values print ( \"The zipped result is : \" , end = \"\" ) print ( mapped ) print ( \" \\n \" ) # unzipping values namz , roll_noz , marksz = zip ( * mapped ) print ( \"The unzipped result: \\n \" , end = \"\" ) # printing initial lists print ( \"The name list is : \" , end = \"\" ) print ( namz ) print ( \"The roll_no list is : \" , end = \"\" ) print ( roll_noz ) print ( \"The marks list is : \" , end = \"\" ) print ( marksz ) The zipped result is : [('Manjeet', 4, 40), ('Nikhil', 1, 50), ('Shambhavi', 3, 60), ('Astha', 2, 70)] The unzipped result: The name list is : ('Manjeet', 'Nikhil', 'Shambhavi', 'Astha') The roll_no list is : (4, 1, 3, 2) The marks list is : (40, 50, 60, 70)","title":"Zip"},{"location":"DS/pyIterZip/#zip","text":"Python zip() method takes iterable or containers and returns a single iterator object, having mapped values from all the containers. It is used to map the similar index of multiple containers so that they can be used just using a single entity. name = [ \"Manjeet\" , \"Nikhil\" , \"Shambhavi\" , \"Astha\" ] roll_no = [ 4 , 1 , 3 , 2 ] # using zip() to map values mapped = zip ( name , roll_no ) print ( set ( mapped )) {('Shambhavi', 3), ('Nikhil', 1), ('Astha', 2), ('Manjeet', 4)} names = [ 'Mukesh' , 'Roni' , 'Chari' ] ages = [ 24 , 50 , 18 ] for i , ( name , age ) in enumerate ( zip ( names , ages )): print ( i , name , age ) 0 Mukesh 24 1 Roni 50 2 Chari 18 stocks = [ 'reliance' , 'infosys' , 'tcs' ] prices = [ 2175 , 1127 , 2750 ] new_dict = { stocks : prices for stocks , prices in zip ( stocks , prices )} print ( new_dict ) {'reliance': 2175, 'infosys': 1127, 'tcs': 2750}","title":"Zip"},{"location":"DS/pyIterZip/#unzip","text":"How to unzip? Unzipping means converting the zipped values back to the individual self as they were. This is done with the help of \u201c*\u201d operator. # Python code to demonstrate the working of # unzip # initializing lists name = [ \"Manjeet\" , \"Nikhil\" , \"Shambhavi\" , \"Astha\" ] roll_no = [ 4 , 1 , 3 , 2 ] marks = [ 40 , 50 , 60 , 70 ] # using zip() to map values mapped = zip ( name , roll_no , marks ) # converting values to print as list mapped = list ( mapped ) # printing resultant values print ( \"The zipped result is : \" , end = \"\" ) print ( mapped ) print ( \" \\n \" ) # unzipping values namz , roll_noz , marksz = zip ( * mapped ) print ( \"The unzipped result: \\n \" , end = \"\" ) # printing initial lists print ( \"The name list is : \" , end = \"\" ) print ( namz ) print ( \"The roll_no list is : \" , end = \"\" ) print ( roll_noz ) print ( \"The marks list is : \" , end = \"\" ) print ( marksz ) The zipped result is : [('Manjeet', 4, 40), ('Nikhil', 1, 50), ('Shambhavi', 3, 60), ('Astha', 2, 70)] The unzipped result: The name list is : ('Manjeet', 'Nikhil', 'Shambhavi', 'Astha') The roll_no list is : (4, 1, 3, 2) The marks list is : (40, 50, 60, 70)","title":"Unzip"},{"location":"DS/pyLinkedList/","text":"A linked list is a sequence of nodes where each node stores its own data and a link to the next node. One node links to another forming what can be thought of as a linked chain. The first node is called the head, and it's used as the starting point for any iteration through the list. The last node must have its link pointing to None to determine the end of the list. Unlike stacks and queues, you can insert and remove nodes in any position of the linked list (similar to a standard list). Applications Linked lists are useful when your data is linked. For example when you need undo/redo functionality, the nodes can represent the state with links to the previous and next states. Another example would be a playlist of music, where each clip is linked with the next one. Linked lists can also be used to create other data structures, such as stack, queues and graphs. class Node : def __init__ ( self , data , next ): self . data = data self . next = next class LinkedList : def __init__ ( self ): self . head = None def add_at_front ( self , data ): self . head = Node ( data , self . head ) def add_at_end ( self , data ): if not self . head : self . head = Node ( data , None ) return curr = self . head while curr . next : curr = curr . next curr . next = Node ( data , None ) def get_last_node ( self ): n = self . head while ( n . next != None ): n = n . next return n . data def print_list ( self ): n = self . head while n != None : print ( n . data , end = \" => \" ) n = n . next print () There are two types of linked list: Single-Linked List: In this, the nodes point to the node immediately after it Doubly Linked List: In this, the nodes not only reference the node next to it but also the node before it. To start with Python, it does not have a linked list library built into it like the classical programming languages. Python does have an inbuilt type list that works as a dynamic array but its operation shouldn\u2019t be confused with a typical function of a linked list. This doesn\u2019t mean one cannot implement a linked list in Python, they can but it will not be straight up. Using deque() package When to use deque() as a linked list? Inserting and deleting elements at front and back respectively is the only need. Inserting and removing elements from the middle becomes time-consuming. In-place reversal since Python now allows elements to be reversed in the place itself. Storage is preferred over performance and not all elements get a separate node of their own # importing module import collections # initialising a deque() of arbitrary length linked_lst = collections . deque () # filling deque() with elements linked_lst . append ( 'first' ) linked_lst . append ( 'second' ) linked_lst . append ( 'third' ) print ( \"elements in the linked_list:\" ) print ( linked_lst ) # adding element at an arbitrary position linked_lst . insert ( 1 , 'fourth' ) print ( \"elements in the linked_list:\" ) print ( linked_lst ) # deleting the last element linked_lst . pop () print ( \"elements in the linked_list:\" ) print ( linked_lst ) # removing a specific element linked_lst . remove ( 'fourth' ) print ( \"elements in the linked_list:\" ) print ( linked_lst ) elements in the linked_list: deque(['first', 'second', 'third']) elements in the linked_list: deque(['first', 'fourth', 'second', 'third']) elements in the linked_list: deque(['first', 'fourth', 'second']) elements in the linked_list: deque(['first', 'second']) Using llist package The llist is an extension module for CPython providing basic linked list data structures. pip install llist # importing packages import llist from llist import sllist , sllistnode # creating a singly linked list lst = sllist ([ 'first' , 'second' , 'third' ]) print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () # adding and inserting values lst . append ( 'fourth' ) node = lst . nodeat ( 2 ) lst . insertafter ( 'fifth' , node ) print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () # poping a value #i.e. removing the last entry # of the list lst . pop () print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () # removing a specific element node = lst . nodeat ( 1 ) lst . remove ( node ) print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () sllist([first, second, third]) sllistnode(first) sllistnode(third) 3 sllist([first, second, third, fifth, fourth]) sllistnode(first) sllistnode(fourth) 5 sllist([first, second, third, fifth]) sllistnode(first) sllistnode(fifth) 4 sllist([first, third, fifth]) sllistnode(first) sllistnode(fifth) 3 Using StructLinks package StructLinks is used to easily Access and visualize different Data structures including Linked lists, Doubly Linked lists, Binary trees, Graphs, Stacks, and Queues. The structlinks.LinkedList and structlinks.DoublyLikedList modules could be used to make linked lists. All the operations that could be performed with a list could also be performed with structlinks.LinkedList class. # 1. Download the repo and set it as the current directory git clone https : // github . com / eeshannarula29 / structlinks # 2. Add the project directory to the path import os , sys sys . path . append ( os . getcwd ()) cd LinkedList / import LinkedList as ll # create an empty linked list lst = ll . LinkedList () # create a linked list with initial values lst = ll . LinkedList ([ 1 , 10.0 , 'string' ]) print ( lst ) print () print ( 'Elements of list:' ) # elements of the list element0 = lst [ 0 ] element1 = lst [ 1 ] element2 = lst [ 2 ] print ( f 'first element : { element0 } ' ) print ( f 'second element : { element1 } ' ) print ( f 'third element : { element2 } ' ) print () print ( 'Length of list:' ) # Length of the list length = len ( lst ) print ( f 'size of the list : { length } ' ) print () print ( 'Set item:' ) # Set item lst [ 0 ] = 10 print ( f 'list after setting lst[0] to 10 : { lst } ' ) print () print ( 'Append And Insert:' ) # Append And Insert lst . append ( 'another string' ) lst . insert ( 1 , 0.0 ) print ( f 'list after appedning and inserting: { lst } ' ) print () print ( 'Pop and Remove' ) # Pop and Remove element = lst . pop ( 0 ) lst . remove ( 10.0 ) print ( f 'list after poping and removing : { lst } ' ) print ( f 'pop function also returns the element : { element } ' ) [1 -> 10 -> -3 -> 5] Elements of list: first element : 1 second element : 10 third element : -3 Length of list: size of the list : 4 Set item: list after setting lst[0] to 10 : [10 -> 10 -> -3 -> 5] Append And Insert: list after appedning and inserting: [10 -> 0.0 -> 10 -> -3 -> 5 -> another string] Pop and Remove list after poping and removing : [0.0 -> -3 -> 5 -> another string] pop function also returns the element : 10","title":"LinkedList"},{"location":"DS/pyLinkedList/#using-deque-package","text":"When to use deque() as a linked list? Inserting and deleting elements at front and back respectively is the only need. Inserting and removing elements from the middle becomes time-consuming. In-place reversal since Python now allows elements to be reversed in the place itself. Storage is preferred over performance and not all elements get a separate node of their own # importing module import collections # initialising a deque() of arbitrary length linked_lst = collections . deque () # filling deque() with elements linked_lst . append ( 'first' ) linked_lst . append ( 'second' ) linked_lst . append ( 'third' ) print ( \"elements in the linked_list:\" ) print ( linked_lst ) # adding element at an arbitrary position linked_lst . insert ( 1 , 'fourth' ) print ( \"elements in the linked_list:\" ) print ( linked_lst ) # deleting the last element linked_lst . pop () print ( \"elements in the linked_list:\" ) print ( linked_lst ) # removing a specific element linked_lst . remove ( 'fourth' ) print ( \"elements in the linked_list:\" ) print ( linked_lst ) elements in the linked_list: deque(['first', 'second', 'third']) elements in the linked_list: deque(['first', 'fourth', 'second', 'third']) elements in the linked_list: deque(['first', 'fourth', 'second']) elements in the linked_list: deque(['first', 'second'])","title":"Using deque() package"},{"location":"DS/pyLinkedList/#using-llist-package","text":"The llist is an extension module for CPython providing basic linked list data structures. pip install llist # importing packages import llist from llist import sllist , sllistnode # creating a singly linked list lst = sllist ([ 'first' , 'second' , 'third' ]) print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () # adding and inserting values lst . append ( 'fourth' ) node = lst . nodeat ( 2 ) lst . insertafter ( 'fifth' , node ) print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () # poping a value #i.e. removing the last entry # of the list lst . pop () print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () # removing a specific element node = lst . nodeat ( 1 ) lst . remove ( node ) print ( lst ) print ( lst . first ) print ( lst . last ) print ( lst . size ) print () sllist([first, second, third]) sllistnode(first) sllistnode(third) 3 sllist([first, second, third, fifth, fourth]) sllistnode(first) sllistnode(fourth) 5 sllist([first, second, third, fifth]) sllistnode(first) sllistnode(fifth) 4 sllist([first, third, fifth]) sllistnode(first) sllistnode(fifth) 3","title":"Using llist package"},{"location":"DS/pyLinkedList/#using-structlinks-package","text":"StructLinks is used to easily Access and visualize different Data structures including Linked lists, Doubly Linked lists, Binary trees, Graphs, Stacks, and Queues. The structlinks.LinkedList and structlinks.DoublyLikedList modules could be used to make linked lists. All the operations that could be performed with a list could also be performed with structlinks.LinkedList class. # 1. Download the repo and set it as the current directory git clone https : // github . com / eeshannarula29 / structlinks # 2. Add the project directory to the path import os , sys sys . path . append ( os . getcwd ()) cd LinkedList / import LinkedList as ll # create an empty linked list lst = ll . LinkedList () # create a linked list with initial values lst = ll . LinkedList ([ 1 , 10.0 , 'string' ]) print ( lst ) print () print ( 'Elements of list:' ) # elements of the list element0 = lst [ 0 ] element1 = lst [ 1 ] element2 = lst [ 2 ] print ( f 'first element : { element0 } ' ) print ( f 'second element : { element1 } ' ) print ( f 'third element : { element2 } ' ) print () print ( 'Length of list:' ) # Length of the list length = len ( lst ) print ( f 'size of the list : { length } ' ) print () print ( 'Set item:' ) # Set item lst [ 0 ] = 10 print ( f 'list after setting lst[0] to 10 : { lst } ' ) print () print ( 'Append And Insert:' ) # Append And Insert lst . append ( 'another string' ) lst . insert ( 1 , 0.0 ) print ( f 'list after appedning and inserting: { lst } ' ) print () print ( 'Pop and Remove' ) # Pop and Remove element = lst . pop ( 0 ) lst . remove ( 10.0 ) print ( f 'list after poping and removing : { lst } ' ) print ( f 'pop function also returns the element : { element } ' ) [1 -> 10 -> -3 -> 5] Elements of list: first element : 1 second element : 10 third element : -3 Length of list: size of the list : 4 Set item: list after setting lst[0] to 10 : [10 -> 10 -> -3 -> 5] Append And Insert: list after appedning and inserting: [10 -> 0.0 -> 10 -> -3 -> 5 -> another string] Pop and Remove list after poping and removing : [0.0 -> -3 -> 5 -> another string] pop function also returns the element : 10","title":"Using StructLinks package"},{"location":"DS/pyList/","text":"A list comprises a sequence of objects, usually represented using square brackets with commas between the items in the sequence as is done below: my_list = [ 'a' , 'b' , 'c' , 'd' ] print ( my_list ) ['a', 'b', 'c', 'd'] Above, my_list contains a sequence of character objects. Lists, however, accomodate items of varying types of objects: varied_list = [ 'a' , 1 , 'b' , 3.14159 ] # a list with elements of char, integer, and float types nested_list = [ 'hello' , 'governor' , [ 1.618 , 42 ]] # a list within a list! Lists allow for what is called indexing, in which a specified element of the list may be obtained. For instance, say you wanted to grab the second element of varied_list above. Then you could index the list as so: second_element = varied_list [ 1 ] # Grab second element of varied_list print ( second_element ) Now is a good time to mention that Python is what's called a zero-indexed programming language. This simply means that the \"first\" element in a list or other collection of data items is indexed using \"0\" (zero) rather than \"1\". This is why, above, we grab the second element of varied_list using the integer index \"1\" instead of \"2\" as some might expect from a one-indexed language (like MATLab). Another feature of python indexing that comes in handy is the use of negative indexing. As we discussed above, the \"first\" element of a python list is denoted by index \"0\"; thus, it is almost natural to consider the last element of the list as being indexed by \"-1\". Observe the following examples of negative indexing: last_element = my_list [ - 1 ] # the last element of my_list last_element_2 = my_list [ len ( my_list ) - 1 ] # also the last element of my_list, obtained differently second_to_last_element = my_list [ - 2 ] Similar to indexing is list slicing, in which a contiguous section of list may be accessed. The colon (:) is used to perform slicing, with integers denoting the positions at which to begin and end the slice. Below, we show that the beginning or ending integer for a slice may be omited when one is slicing from the beginning or to the end of the list. Also note below that the index for slice beginning is included in the slice, but the index for the slice end is not included. NFL_list = [ \"Chargers\" , \"Broncos\" , \"Raiders\" , \"Chiefs\" , \"Panthers\" , \"Falcons\" , \"Cowboys\" , \"Eagles\" ] AFC_west_list = NFL_list [: 4 ] # Slice to grab list indices 0, 1, 2, 3 -- \"Chargers\", \"Broncos\", \"Raiders\", \"Chiefs\" NFC_south_list = NFL_list [ 4 : 6 ] # Slice list indices 4, 5 -- \"Panthers\", \"Falcons\" NFC_east_list = NFL_list [ 6 :] # Slice list indices 6, 7 -- \"Cowboys\", \"Eagles\" List slices can also have a third number, representing the step, to include only alternate values in the slice. NFL_list = [ \"Chargers\" , \"Broncos\" , \"Raiders\" , \"Chiefs\" , \"Panthers\" , \"Falcons\" , \"Cowboys\" , \"Eagles\" ] list1 = NFL_list [ 3 :: 2 ] print ( list1 ) ['Chiefs', 'Falcons', 'Eagles'] Negative values can be used in list slicing (and normal list indexing). When negative values are used for the first and second values in a slice (or a normal index), they count from the end of the list. If a negative value is used for the step, the slice is done backwards. Using [::-1] as a slice is a common and idiomatic way to reverse a list. squares = [ 0 , 1 , 4 , 9 , 16 , 25 , 36 , 49 , 64 , 81 ] print ( squares [ 1 : - 3 ]) print ( squares [:: - 1 ]) print ( squares [: 4 : - 1 ]) [1, 4, 9, 16, 25, 36] [81, 64, 49, 36, 25, 16, 9, 4, 1, 0] [81, 64, 49, 36, 25] Sometimes you need to create an empty list and populate it later during the program. For example, if you are creating a queue management program, the queue is going to be empty in the beginning and get populated with people data later. An empty list is created with an empty pair of square brackets. Nested lists can be used to represent 2D grids, such as matrices. Indexing strings behaves as though you are indexing a list containing each character in the string. empty_list = [] print ( empty_list ) m = [ [ 1 , 2 , 3 ], [ 4 , 5 , 6 ] ] print ( m ) s = \"Hello world\" print ( s [ 6 ]) [] [[1, 2, 3], [4, 5, 6]] w List Operations The item at a certain index in a list can be reassigned. Lists can be added and multiplied in the same way as strings. To check if an item is in a list, the in operator can be used. It returns True if the item occurs one or more times in the list, and False if it doesn't. The in operator is also used to determine whether or not a string is a substring of another string. M = [ 1 , 1 , 1 ] M [ 1 ] = \"hello\" print ( M ) print ( M * 3 ) print ( M + [ 1 , 2 ]) print ( 1 in M ) print ( \"Spam\" in M ) print ( not \"hello\" in M ) [1, 'hello', 1] [1, 'hello', 1, 1, 'hello', 1, 1, 'hello', 1] [1, 'hello', 1, 1, 2] True False False List Functions len(list): to get the number of items in a list. max(list): Returns the list item with the maximum value min(list): Returns the list item with minimum value list.append(item): adds an item to the end of an existing list. list.insert(index, item): is similar to append, except that it allows you to insert a new item at any position in the list, as opposed to just at the end. list.index(item): finds the first occurrence of a list item and returns its index. If the item isn't in the list, it raises a ValueError. list.count(item): Returns a count of how many times an item occurs in a list list.remove(item): Removes an object from a list list.pop(index) removes the item at the given index. list.reverse(): Reverses items in a list. list.sort() sorts the list. By default, the list is sorted ascending. You can specify reverse=True as the parameter, to sort descending. nums = [ 1 , 2 , 3 ] nums . append ( 4 ) print ( nums ) nums . insert ( 2 , \"hello\" ) print ( nums ) print ( len ( nums )) print ( nums . index ( 3 )) nums += [ 1 , 2 , 1 ] print ( nums . count ( 1 )) nums . remove ( \"hello\" ) print ( nums . reverse ()) print ( max ( nums )) print ( min ( nums )) [1, 2, 3, 4] [1, 2, 'hello', 3, 4] 5 3 3 None 4 1 # use iterator functions like enumerate, zip, iter, next # define a list of days in English and French days = [ \"Sun\" , \"Mon\" , \"Tue\" , \"Wed\" , \"Thu\" , \"Fri\" , \"Sat\" ] daysFr = [ \"Dim\" , \"Lun\" , \"Mar\" , \"Mer\" , \"Jeu\" , \"Ven\" , \"Sam\" ] # use iter to create an iterator over a collection i = iter ( days ) print ( next ( i )) # Sun print ( next ( i )) # Mon print ( next ( i )) # Tue # iterate using a function and a sentinel with open ( \"game.txt\" , \"r\" ) as fp : for line in iter ( fp . readline , '' ): print ( line ) # use regular interation over the days for m in range ( len ( days )): print ( m + 1 , days [ m ]) 1 Sun 2 Mon 3 Tue 4 Wed 5 Thu 6 Fri 7 Sat # using enumerate reduces code and provides a counter for i , m in enumerate ( days , start = 1 ): print ( i , m ) 1 Sun 2 Mon 3 Tue 4 Wed 5 Thu 6 Fri 7 Sat # use zip to combine sequences for m in zip ( days , daysFr ): print ( m ) for i , m in enumerate ( zip ( days , daysFr ), start = 1 ): print ( i , m [ 0 ], \"=\" , m [ 1 ], \"in French\" ) ('Sun', 'Dim') ('Mon', 'Lun') ('Tue', 'Mar') ('Wed', 'Mer') ('Thu', 'Jeu') ('Fri', 'Ven') ('Sat', 'Sam') 1 Sun = Dim in French 2 Mon = Lun in French 3 Tue = Mar in French 4 Wed = Mer in French 5 Thu = Jeu in French 6 Fri = Ven in French 7 Sat = Sam in French","title":"Lists"},{"location":"DS/pyList/#list-operations","text":"The item at a certain index in a list can be reassigned. Lists can be added and multiplied in the same way as strings. To check if an item is in a list, the in operator can be used. It returns True if the item occurs one or more times in the list, and False if it doesn't. The in operator is also used to determine whether or not a string is a substring of another string. M = [ 1 , 1 , 1 ] M [ 1 ] = \"hello\" print ( M ) print ( M * 3 ) print ( M + [ 1 , 2 ]) print ( 1 in M ) print ( \"Spam\" in M ) print ( not \"hello\" in M ) [1, 'hello', 1] [1, 'hello', 1, 1, 'hello', 1, 1, 'hello', 1] [1, 'hello', 1, 1, 2] True False False","title":"List Operations"},{"location":"DS/pyList/#list-functions","text":"len(list): to get the number of items in a list. max(list): Returns the list item with the maximum value min(list): Returns the list item with minimum value list.append(item): adds an item to the end of an existing list. list.insert(index, item): is similar to append, except that it allows you to insert a new item at any position in the list, as opposed to just at the end. list.index(item): finds the first occurrence of a list item and returns its index. If the item isn't in the list, it raises a ValueError. list.count(item): Returns a count of how many times an item occurs in a list list.remove(item): Removes an object from a list list.pop(index) removes the item at the given index. list.reverse(): Reverses items in a list. list.sort() sorts the list. By default, the list is sorted ascending. You can specify reverse=True as the parameter, to sort descending. nums = [ 1 , 2 , 3 ] nums . append ( 4 ) print ( nums ) nums . insert ( 2 , \"hello\" ) print ( nums ) print ( len ( nums )) print ( nums . index ( 3 )) nums += [ 1 , 2 , 1 ] print ( nums . count ( 1 )) nums . remove ( \"hello\" ) print ( nums . reverse ()) print ( max ( nums )) print ( min ( nums )) [1, 2, 3, 4] [1, 2, 'hello', 3, 4] 5 3 3 None 4 1 # use iterator functions like enumerate, zip, iter, next # define a list of days in English and French days = [ \"Sun\" , \"Mon\" , \"Tue\" , \"Wed\" , \"Thu\" , \"Fri\" , \"Sat\" ] daysFr = [ \"Dim\" , \"Lun\" , \"Mar\" , \"Mer\" , \"Jeu\" , \"Ven\" , \"Sam\" ] # use iter to create an iterator over a collection i = iter ( days ) print ( next ( i )) # Sun print ( next ( i )) # Mon print ( next ( i )) # Tue # iterate using a function and a sentinel with open ( \"game.txt\" , \"r\" ) as fp : for line in iter ( fp . readline , '' ): print ( line ) # use regular interation over the days for m in range ( len ( days )): print ( m + 1 , days [ m ]) 1 Sun 2 Mon 3 Tue 4 Wed 5 Thu 6 Fri 7 Sat # using enumerate reduces code and provides a counter for i , m in enumerate ( days , start = 1 ): print ( i , m ) 1 Sun 2 Mon 3 Tue 4 Wed 5 Thu 6 Fri 7 Sat # use zip to combine sequences for m in zip ( days , daysFr ): print ( m ) for i , m in enumerate ( zip ( days , daysFr ), start = 1 ): print ( i , m [ 0 ], \"=\" , m [ 1 ], \"in French\" ) ('Sun', 'Dim') ('Mon', 'Lun') ('Tue', 'Mar') ('Wed', 'Mer') ('Thu', 'Jeu') ('Fri', 'Ven') ('Sat', 'Sam') 1 Sun = Dim in French 2 Mon = Lun in French 3 Tue = Mar in French 4 Wed = Mer in French 5 Thu = Jeu in French 6 Fri = Ven in French 7 Sat = Sam in French","title":"List Functions"},{"location":"DS/pyNamedTuple/","text":"Named tuples are basically easy-to-create, lightweight object types. Named tuple instances can be referenced using object-like variable dereferencing or the standard tuple syntax. They can be used similarly to struct or other common record types, except that they are immutable. It is common to represent a point as a tuple (x, y). This leads to code like the following: pt1 = ( 1.0 , 5.0 ) pt2 = ( 2.5 , 1.5 ) from math import sqrt line_length = sqrt (( pt1 [ 0 ] - pt2 [ 0 ]) ** 2 + ( pt1 [ 1 ] - pt2 [ 1 ]) ** 2 ) print ( line_length ) 3.8078865529319543 Using a named tuple it becomes more readable: from collections import namedtuple Point = namedtuple ( 'Point' , 'x y' ) pt1 = Point ( 1.0 , 5.0 ) pt2 = Point ( 2.5 , 1.5 ) from math import sqrt line_length = sqrt (( pt1 . x - pt2 . x ) ** 2 + ( pt1 . y - pt2 . y ) ** 2 ) print ( line_length ) 3.8078865529319543 However, named tuples are still backwards compatible with normal tuples, so the following will still work: Point = namedtuple ( 'Point' , 'x y' ) pt1 = Point ( 1.0 , 5.0 ) pt2 = Point ( 2.5 , 1.5 ) from math import sqrt # use index referencing line_length = sqrt (( pt1 [ 0 ] - pt2 [ 0 ]) ** 2 + ( pt1 [ 1 ] - pt2 [ 1 ]) ** 2 ) print ( line_length ) # use tuple unpacking x1 , y1 = pt1 print ( x1 ) print ( y1 ) 3.8078865529319543 1.0 5.0 Thus, you should use named tuples instead of tuples anywhere you think object notation will make your code more pythonic and more easily readable. Use them to represent very simple value types, particularly when passing them as parameters to functions. It makes the functions more readable, without seeing the context of the tuple packing. NamedTuples, like dictionaries, contain keys that are hashed to a particular value. But on contrary, it supports both access from key-value and iteration, the functionality that dictionaries lack. # Python code to demonstrate namedtuple() from collections import namedtuple # Declaring namedtuple() Student = namedtuple ( 'Student' , [ 'name' , 'age' , 'DOB' ]) # Adding values S = Student ( 'Harry' , '12' , '31071980' ) # Access by index: The attribute values of namedtuple() # are ordered and can be accessed using the index number unlike dictionaries # which are not accessible by index. print ( \"The Student age using index is : \" , end = \"\" ) print ( S [ 1 ]) # Access using name : Access by keyname is also allowed as in dictionaries. print ( \"The Student name using keyname is : \" , end = \"\" ) print ( S . name ) # Access using getattr(): This is yet another way to access the value by # giving namedtuple and key value as its argument. print ( \"The Student DOB using getattr() is : \" , end = \"\" ) print ( getattr ( S , 'DOB' )) The Student age using index is : 12 The Student name using keyname is : Harry The Student DOB using getattr() is : 31071980 Conversion Operations _make() : This function is used to return a namedtuple() from the iterable passed as argument. _asdict() : This function returns the OrderedDict() as constructed from the mapped values of namedtuple(). using \u201c**\u201d (double star) operator : This function is used to convert a dictionary into the namedtuple(). # Python code to demonstrate namedtuple() and # _make(), _asdict() and \"**\" operator # importing \"collections\" for namedtuple() import collections # Declaring namedtuple() Student = collections . namedtuple ( 'Student' , [ 'name' , 'age' , 'DOB' ]) # Adding values S = Student ( 'Harry' , '12' , '31071980' ) # initializing iterable li = [ 'Ron' , '12' , '01031980' ] # initializing dict di = { 'name' : \"Hermione\" , 'age' : 12 , 'DOB' : '19091979' } # using _make() to return namedtuple() print ( \"The namedtuple instance using iterable is : \" ) print ( Student . _make ( li )) # using _asdict() to return an OrderedDict() print ( \"The OrderedDict instance using namedtuple is : \" ) print ( S . _asdict ()) # using ** operator to return namedtuple from dictionary print ( \"The namedtuple instance from dict is : \" ) print ( Student ( ** di )) The namedtuple instance using iterable is : Student(name='Ron', age='12', DOB='01031980') The OrderedDict instance using namedtuple is : OrderedDict([('name', 'Harry'), ('age', '12'), ('DOB', '31071980')]) The namedtuple instance from dict is : Student(name='Hermione', age=12, DOB='19091979') Additional Operation _fields : This function is used to return all the keynames of the namespace declared. _replace() : _replace() is like str.replace() but targets named fields( does not modify the original values) # Python code to demonstrate namedtuple() and # _fields and _replace() # importing \"collections\" for namedtuple() import collections # Declaring namedtuple() Student = collections . namedtuple ( 'Student' , [ 'name' , 'age' , 'DOB' ]) # Adding values S = Student ( 'Harry' , '12' , '31071980' ) # using _fields to display all the keynames of namedtuple() print ( \"All the fields of students are : \" ) print ( S . _fields ) # ._replace returns a new namedtuple, it does not modify the original print ( \"returns a new namedtuple : \" ) print ( S . _replace ( name = 'Ron' )) # original namedtuple print ( S ) All the fields of students are : ('name', 'age', 'DOB') returns a new namedtuple : Student(name='Ron', age='12', DOB='31071980') Student(name='Harry', age='12', DOB='31071980')","title":"NamedTuple"},{"location":"DS/pyNamedTuple/#conversion-operations","text":"_make() : This function is used to return a namedtuple() from the iterable passed as argument. _asdict() : This function returns the OrderedDict() as constructed from the mapped values of namedtuple(). using \u201c**\u201d (double star) operator : This function is used to convert a dictionary into the namedtuple(). # Python code to demonstrate namedtuple() and # _make(), _asdict() and \"**\" operator # importing \"collections\" for namedtuple() import collections # Declaring namedtuple() Student = collections . namedtuple ( 'Student' , [ 'name' , 'age' , 'DOB' ]) # Adding values S = Student ( 'Harry' , '12' , '31071980' ) # initializing iterable li = [ 'Ron' , '12' , '01031980' ] # initializing dict di = { 'name' : \"Hermione\" , 'age' : 12 , 'DOB' : '19091979' } # using _make() to return namedtuple() print ( \"The namedtuple instance using iterable is : \" ) print ( Student . _make ( li )) # using _asdict() to return an OrderedDict() print ( \"The OrderedDict instance using namedtuple is : \" ) print ( S . _asdict ()) # using ** operator to return namedtuple from dictionary print ( \"The namedtuple instance from dict is : \" ) print ( Student ( ** di )) The namedtuple instance using iterable is : Student(name='Ron', age='12', DOB='01031980') The OrderedDict instance using namedtuple is : OrderedDict([('name', 'Harry'), ('age', '12'), ('DOB', '31071980')]) The namedtuple instance from dict is : Student(name='Hermione', age=12, DOB='19091979')","title":"Conversion Operations"},{"location":"DS/pyNamedTuple/#additional-operation","text":"_fields : This function is used to return all the keynames of the namespace declared. _replace() : _replace() is like str.replace() but targets named fields( does not modify the original values) # Python code to demonstrate namedtuple() and # _fields and _replace() # importing \"collections\" for namedtuple() import collections # Declaring namedtuple() Student = collections . namedtuple ( 'Student' , [ 'name' , 'age' , 'DOB' ]) # Adding values S = Student ( 'Harry' , '12' , '31071980' ) # using _fields to display all the keynames of namedtuple() print ( \"All the fields of students are : \" ) print ( S . _fields ) # ._replace returns a new namedtuple, it does not modify the original print ( \"returns a new namedtuple : \" ) print ( S . _replace ( name = 'Ron' )) # original namedtuple print ( S ) All the fields of students are : ('name', 'age', 'DOB') returns a new namedtuple : Student(name='Ron', age='12', DOB='31071980') Student(name='Harry', age='12', DOB='31071980')","title":"Additional Operation"},{"location":"DS/pyOrdereddict/","text":"An OrderedDict is a dictionary subclass that remembers the order that keys were first inserted. The only difference between dict() and OrderedDict() is that: OrderedDict preserves the order in which the keys are inserted. A regular dict doesn\u2019t track the insertion order, and iterating it gives the values in an arbitrary order. By contrast, the order the items are inserted is remembered by OrderedDict. # A Python program to demonstrate working # of OrderedDict from collections import OrderedDict print ( \"This is a Dict: \\n \" ) d = {} d [ 'a' ] = 1 d [ 'b' ] = 2 d [ 'c' ] = 3 d [ 'd' ] = 4 for key , value in d . items (): print ( key , value ) print ( \" \\n This is an Ordered Dict: \\n \" ) od = OrderedDict () od [ 'a' ] = 1 od [ 'b' ] = 2 od [ 'c' ] = 3 od [ 'd' ] = 4 for key , value in od . items (): print ( key , value ) This is a Dict: a 1 b 2 c 3 d 4 This is an Ordered Dict: a 1 b 2 c 3 d 4 Key value Change If the value of a certain key is changed, the position of the key remains unchanged in OrderedDict. # A Python program to demonstrate working of key # value change in OrderedDict from collections import OrderedDict print ( \"Before: \\n \" ) od = OrderedDict () od [ 'a' ] = 1 od [ 'b' ] = 2 od [ 'c' ] = 3 od [ 'd' ] = 4 for key , value in od . items (): print ( key , value ) print ( \" \\n After: \\n \" ) od [ 'c' ] = 5 for key , value in od . items (): print ( key , value ) Before: a 1 b 2 c 3 d 4 After: a 1 b 2 c 5 d 4 Deletion and Re-Inserting Deleting and re-inserting the same key will push it to the back as OrderedDict, however, maintains the order of insertion. # A Python program to demonstrate working of deletion # re-insertion in OrderedDict from collections import OrderedDict print ( \"Before deleting: \\n \" ) od = OrderedDict () od [ 'a' ] = 1 od [ 'b' ] = 2 od [ 'c' ] = 3 od [ 'd' ] = 4 for key , value in od . items (): print ( key , value ) print ( \" \\n After deleting: \\n \" ) od . pop ( 'c' ) for key , value in od . items (): print ( key , value ) print ( \" \\n After re-inserting: \\n \" ) od [ 'c' ] = 3 for key , value in od . items (): print ( key , value ) Before deleting: a 1 b 2 c 3 d 4 After deleting: a 1 b 2 d 4 After re-inserting: a 1 b 2 d 4 c 3 from collections import OrderedDict def main (): # list of sport teams with wins and losses sportTeams = [( \"Royals\" , ( 18 , 12 )), ( \"Rockets\" , ( 24 , 6 )), ( \"Cardinals\" , ( 20 , 10 )), ( \"Dragons\" , ( 22 , 8 )), ( \"Kings\" , ( 15 , 15 )), ( \"Chargers\" , ( 20 , 10 )), ( \"Jets\" , ( 16 , 14 )), ( \"Warriors\" , ( 25 , 5 ))] # sort the teams by number of wins sortedTeams = sorted ( sportTeams , key = lambda t : t [ 1 ][ 0 ], reverse = True ) # create an ordered dictionary of the teams teams = OrderedDict ( sortedTeams ) print ( teams ) # Use popitem to remove the top item tm , wl = teams . popitem ( False ) print ( \"Top team: \" , tm , wl ) # What are next the top 4 teams? for i , team in enumerate ( teams , start = 1 ): print ( i , team ) if i == 4 : break # test for equality a = OrderedDict ({ \"a\" : 1 , \"b\" : 2 , \"c\" : 3 }) b = OrderedDict ({ \"a\" : 1 , \"c\" : 3 , \"b\" : 2 }) print ( \"Equality test: \" , a == b ) if __name__ == \"__main__\" : main () OrderedDict([('Warriors', (25, 5)), ('Rockets', (24, 6)), ('Dragons', (22, 8)), ('Cardinals', (20, 10)), ('Chargers', (20, 10)), ('Royals', (18, 12)), ('Jets', (16, 14)), ('Kings', (15, 15))]) Top team: Warriors (25, 5) 1 Rockets 2 Dragons 3 Cardinals 4 Chargers Equality test: False","title":"Ordereddict"},{"location":"DS/pyOrdereddict/#key-value-change","text":"If the value of a certain key is changed, the position of the key remains unchanged in OrderedDict. # A Python program to demonstrate working of key # value change in OrderedDict from collections import OrderedDict print ( \"Before: \\n \" ) od = OrderedDict () od [ 'a' ] = 1 od [ 'b' ] = 2 od [ 'c' ] = 3 od [ 'd' ] = 4 for key , value in od . items (): print ( key , value ) print ( \" \\n After: \\n \" ) od [ 'c' ] = 5 for key , value in od . items (): print ( key , value ) Before: a 1 b 2 c 3 d 4 After: a 1 b 2 c 5 d 4","title":"Key value Change"},{"location":"DS/pyOrdereddict/#deletion-and-re-inserting","text":"Deleting and re-inserting the same key will push it to the back as OrderedDict, however, maintains the order of insertion. # A Python program to demonstrate working of deletion # re-insertion in OrderedDict from collections import OrderedDict print ( \"Before deleting: \\n \" ) od = OrderedDict () od [ 'a' ] = 1 od [ 'b' ] = 2 od [ 'c' ] = 3 od [ 'd' ] = 4 for key , value in od . items (): print ( key , value ) print ( \" \\n After deleting: \\n \" ) od . pop ( 'c' ) for key , value in od . items (): print ( key , value ) print ( \" \\n After re-inserting: \\n \" ) od [ 'c' ] = 3 for key , value in od . items (): print ( key , value ) Before deleting: a 1 b 2 c 3 d 4 After deleting: a 1 b 2 d 4 After re-inserting: a 1 b 2 d 4 c 3 from collections import OrderedDict def main (): # list of sport teams with wins and losses sportTeams = [( \"Royals\" , ( 18 , 12 )), ( \"Rockets\" , ( 24 , 6 )), ( \"Cardinals\" , ( 20 , 10 )), ( \"Dragons\" , ( 22 , 8 )), ( \"Kings\" , ( 15 , 15 )), ( \"Chargers\" , ( 20 , 10 )), ( \"Jets\" , ( 16 , 14 )), ( \"Warriors\" , ( 25 , 5 ))] # sort the teams by number of wins sortedTeams = sorted ( sportTeams , key = lambda t : t [ 1 ][ 0 ], reverse = True ) # create an ordered dictionary of the teams teams = OrderedDict ( sortedTeams ) print ( teams ) # Use popitem to remove the top item tm , wl = teams . popitem ( False ) print ( \"Top team: \" , tm , wl ) # What are next the top 4 teams? for i , team in enumerate ( teams , start = 1 ): print ( i , team ) if i == 4 : break # test for equality a = OrderedDict ({ \"a\" : 1 , \"b\" : 2 , \"c\" : 3 }) b = OrderedDict ({ \"a\" : 1 , \"c\" : 3 , \"b\" : 2 }) print ( \"Equality test: \" , a == b ) if __name__ == \"__main__\" : main () OrderedDict([('Warriors', (25, 5)), ('Rockets', (24, 6)), ('Dragons', (22, 8)), ('Cardinals', (20, 10)), ('Chargers', (20, 10)), ('Royals', (18, 12)), ('Jets', (16, 14)), ('Kings', (15, 15))]) Top team: Warriors (25, 5) 1 Rockets 2 Dragons 3 Cardinals 4 Chargers Equality test: False","title":"Deletion and Re-Inserting"},{"location":"DS/pyQueue/","text":"A queue is similar to a stack, but defines a different way to add and remove elements. The elements are inserted from one end, called the rear, and deleted from the other end, called the front. This behavior is called FIFO (First in First Out). Terminology The process of adding new elements into the queue is called enqueue. The process of removal of an element from the queue is called dequeue. Applications Queues are used whenever we need to manage objects in order starting with the first one in. Scenarios include printing documents on a printer, call center systems answering people on hold, and so on. Queue in Python can be implemented by the following ways: list collections.deque queue.Queue Using List Python lists are the easiest way to implement a queue functionality. List is a Python\u2019s built-in data structure that can be used as a queue. Instead of enqueue() and dequeue(), append() and pop() function is used. However, lists are quite slow for this purpose because inserting or deleting an element at the beginning requires shifting all of the other elements by one, requiring O(n) time. # Python program to # demonstrate queue implementation # using list # Initializing a queue queue = [] # Adding elements to the queue queue . append ( 'a' ) queue . append ( 'b' ) queue . append ( 'c' ) print ( \"Initial queue\" ) print ( queue ) # Removing elements from the queue print ( \" \\n Elements dequeued from queue\" ) print ( queue . pop ( 0 )) print ( queue . pop ( 0 )) print ( queue . pop ( 0 )) print ( \" \\n Queue after removing elements\" ) print ( queue ) # Uncommenting print(queue.pop(0)) # will raise and IndexError # as the queue is now empty Initial queue ['a', 'b', 'c'] Elements dequeued from queue a b c Queue after removing elements [] Using collections.deque Queue in Python can be implemented using deque class from the collections module. Deque is preferred over list in the cases where we need quicker append and pop operations from both the ends of container, as deque provides an O(1) time complexity for append and pop operations as compared to list which provides O(n) time complexity. Instead of enqueue and deque, append() and popleft() functions are used. # Python program to # demonstrate queue implementation # using collections.dequeue from collections import deque # Initializing a queue q = deque () # Adding elements to a queue q . append ( 'a' ) q . append ( 'b' ) q . append ( 'c' ) print ( \"Initial queue\" ) print ( q ) # Removing elements from a queue print ( \" \\n Elements dequeued from the queue\" ) print ( q . popleft ()) print ( q . popleft ()) print ( q . popleft ()) print ( \" \\n Queue after removing elements\" ) print ( q ) # Uncommenting q.popleft() # will raise an IndexError # as queue is now empty Initial queue deque(['a', 'b', 'c']) Elements dequeued from the queue a b c Queue after removing elements deque([]) Using queue.Queue Queue is built-in module of Python which is used to implement a queue. queue.Queue(maxsize) initializes a variable to a maximum size of maxsize. A maxsize of zero \u20180\u2019 means a infinite queue. This Queue follows FIFO rule. There are various functions available in this module: maxsize \u2013 Number of items allowed in the queue. empty() \u2013 Return True if the queue is empty, False otherwise. full() \u2013 Return True if there are maxsize items in the queue. If the queue was initialized with maxsize=0 (the default), then full() never returns True. get() \u2013 Remove and return an item from the queue. If queue is empty, wait until an item is available. get_nowait() \u2013 Return an item if one is immediately available, else raise QueueEmpty. put(item) \u2013 Put an item into the queue. If the queue is full, wait until a free slot is available before adding the item. put_nowait(item) \u2013 Put an item into the queue without blocking. If no free slot is immediately available, raise QueueFull. qsize() \u2013 Return the number of items in the queue. # Python program to # demonstrate implementation of # queue using queue module from queue import Queue # Initializing a queue q = Queue ( maxsize = 3 ) # qsize() give the maxsize # of the Queue print ( q . qsize ()) # Adding of element to queue q . put ( 'a' ) q . put ( 'b' ) q . put ( 'c' ) # Return Boolean for Full # Queue print ( \" \\n Full: \" , q . full ()) # Removing element from queue print ( \" \\n Elements dequeued from the queue\" ) print ( q . get ()) print ( q . get ()) print ( q . get ()) # Return Boolean for Empty # Queue print ( \" \\n Empty: \" , q . empty ()) q . put ( 1 ) print ( \" \\n Empty: \" , q . empty ()) print ( \"Full: \" , q . full ()) # This would result into Infinite # Loop as the Queue is empty. # print(q.get()) 0 Full: True Elements dequeued from the queue a b c Empty: True Empty: False Full: False","title":"Queue"},{"location":"DS/pyQueue/#using-list","text":"Python lists are the easiest way to implement a queue functionality. List is a Python\u2019s built-in data structure that can be used as a queue. Instead of enqueue() and dequeue(), append() and pop() function is used. However, lists are quite slow for this purpose because inserting or deleting an element at the beginning requires shifting all of the other elements by one, requiring O(n) time. # Python program to # demonstrate queue implementation # using list # Initializing a queue queue = [] # Adding elements to the queue queue . append ( 'a' ) queue . append ( 'b' ) queue . append ( 'c' ) print ( \"Initial queue\" ) print ( queue ) # Removing elements from the queue print ( \" \\n Elements dequeued from queue\" ) print ( queue . pop ( 0 )) print ( queue . pop ( 0 )) print ( queue . pop ( 0 )) print ( \" \\n Queue after removing elements\" ) print ( queue ) # Uncommenting print(queue.pop(0)) # will raise and IndexError # as the queue is now empty Initial queue ['a', 'b', 'c'] Elements dequeued from queue a b c Queue after removing elements []","title":"Using List"},{"location":"DS/pyQueue/#using-collectionsdeque","text":"Queue in Python can be implemented using deque class from the collections module. Deque is preferred over list in the cases where we need quicker append and pop operations from both the ends of container, as deque provides an O(1) time complexity for append and pop operations as compared to list which provides O(n) time complexity. Instead of enqueue and deque, append() and popleft() functions are used. # Python program to # demonstrate queue implementation # using collections.dequeue from collections import deque # Initializing a queue q = deque () # Adding elements to a queue q . append ( 'a' ) q . append ( 'b' ) q . append ( 'c' ) print ( \"Initial queue\" ) print ( q ) # Removing elements from a queue print ( \" \\n Elements dequeued from the queue\" ) print ( q . popleft ()) print ( q . popleft ()) print ( q . popleft ()) print ( \" \\n Queue after removing elements\" ) print ( q ) # Uncommenting q.popleft() # will raise an IndexError # as queue is now empty Initial queue deque(['a', 'b', 'c']) Elements dequeued from the queue a b c Queue after removing elements deque([])","title":"Using collections.deque"},{"location":"DS/pyQueue/#using-queuequeue","text":"Queue is built-in module of Python which is used to implement a queue. queue.Queue(maxsize) initializes a variable to a maximum size of maxsize. A maxsize of zero \u20180\u2019 means a infinite queue. This Queue follows FIFO rule. There are various functions available in this module: maxsize \u2013 Number of items allowed in the queue. empty() \u2013 Return True if the queue is empty, False otherwise. full() \u2013 Return True if there are maxsize items in the queue. If the queue was initialized with maxsize=0 (the default), then full() never returns True. get() \u2013 Remove and return an item from the queue. If queue is empty, wait until an item is available. get_nowait() \u2013 Return an item if one is immediately available, else raise QueueEmpty. put(item) \u2013 Put an item into the queue. If the queue is full, wait until a free slot is available before adding the item. put_nowait(item) \u2013 Put an item into the queue without blocking. If no free slot is immediately available, raise QueueFull. qsize() \u2013 Return the number of items in the queue. # Python program to # demonstrate implementation of # queue using queue module from queue import Queue # Initializing a queue q = Queue ( maxsize = 3 ) # qsize() give the maxsize # of the Queue print ( q . qsize ()) # Adding of element to queue q . put ( 'a' ) q . put ( 'b' ) q . put ( 'c' ) # Return Boolean for Full # Queue print ( \" \\n Full: \" , q . full ()) # Removing element from queue print ( \" \\n Elements dequeued from the queue\" ) print ( q . get ()) print ( q . get ()) print ( q . get ()) # Return Boolean for Empty # Queue print ( \" \\n Empty: \" , q . empty ()) q . put ( 1 ) print ( \" \\n Empty: \" , q . empty ()) print ( \"Full: \" , q . full ()) # This would result into Infinite # Loop as the Queue is empty. # print(q.get()) 0 Full: True Elements dequeued from the queue a b c Empty: True Empty: False Full: False","title":"Using queue.Queue"},{"location":"DS/pySet/","text":"Sets are data structures, similar to lists or dictionaries. They are created using curly braces, or the set function. They share some functionality with lists, such as the use of in to check whether they contain a particular item. To create an empty set, you must use set(), as {} creates an empty dictionary. One small syntax nuisance: {1, 2, 3} is a set, but {} is an empty dictionary. empty_set = set () num_set = { 1 , 2 , 3 , 4 , 5 } word_set = set ([ \"spam\" , \"eggs\" , \"ham\" ]) print ( 3 in num_set ) print ( \"spam\" not in word_set ) True False Sets differ from lists in several ways, but share several list operations such as len. They are unordered, which means that they can't be indexed. They cannot contain duplicate elements. Due to the way they're stored, it's faster to check whether an item is part of a set, rather than part of a list. Instead of using append to add to a set, use add. The method remove removes a specific element from a set; pop removes an arbitrary element. Basic uses of sets include membership testing and the elimination of duplicate entries. nums = { 1 , 1 , 2 , 3 , 1 , 2 , 1 , 1 } print ( nums ) nums . add ( - 7 ) nums . remove ( 3 ) print ( nums ) {1, 2, 3} {1, 2, -7} Set Operations Sets can be combined using mathematical operations. The union operator | combines two sets to form a new one containing items in either. OR The intersection operator & gets items only in both. AND The difference operator - gets items in the first set but not in the second. The symmetric difference operator ^ gets items in either set, but not both. XOR The comparison operators check for subset and superset relationships. >= and <= f = { 3 , 2 , 9 , 4 , 5 , 6 } s = { 7 , 8 , 9 , 1 , 4 , 6 , 6 , 8 } print ( f | s ) #Union print ( f & s ) #Intersection print ( f - s ) # Difference print ( f ^ s ) #Sym Difference print ( f >= s ) #f superset of s {1, 2, 3, 4, 5, 6, 7, 8, 9} {9, 4, 6} {2, 3, 5} {1, 2, 3, 5, 7, 8} False Sets provide methods as well as operators. The argument you pass to a method can be any iterable, not just a set. And accept more than one argument f . issuperset ([ 1 , 2 , 3 ]) False f . union ([ 1 , 2 , 3 ], ( 3 , 4 , 5 ), { 5 , 6 , 7 }, { 7 : 'a' , 8 : 'b' }) {1, 2, 3, 4, 5, 6, 7, 8, 9} Union # Python3 program for union() function set1 = { 2 , 4 , 5 , 6 } set2 = { 4 , 6 , 7 , 8 } set3 = { 7 , 8 , 9 , 10 } # union of two sets print ( \"set1 U set2 : \" , set1 . union ( set2 )) # union of three sets print ( \"set1 U set2 U set3 :\" , set1 . union ( set2 , set3 )) set1 U set2 : {2, 4, 5, 6, 7, 8} set1 U set2 U set3 : {2, 4, 5, 6, 7, 8, 9, 10} Intersection # Python3 program for intersection() function set1 = { 2 , 4 , 5 , 6 } set2 = { 4 , 6 , 7 , 8 } set3 = { 4 , 6 , 8 } # union of two sets print ( \"set1 intersection set2 : \" , set1 . intersection ( set2 )) # union of three sets print ( \"set1 intersection set2 intersection set3 :\" , set1 . intersection ( set2 , set3 )) set1 intersection set2 : {4, 6} set1 intersection set2 intersection set3 : {4, 6} # Python3 program for intersection() function set1 = { 2 , 4 , 5 , 6 } set2 = { 4 , 6 , 7 , 8 } set3 = { 1 , 0 , 12 } print ( set1 & set2 ) print ( set1 & set3 ) print ( set1 & set2 & set3 ) {4, 6} set() set() Difference # Python code to get the difference between two sets # using difference() between set A and set B # Driver Code A = { 10 , 20 , 30 , 40 , 80 } B = { 100 , 30 , 80 , 40 , 60 } print ( A . difference ( B )) print ( B . difference ( A )) {10, 20} {100, 60}","title":"Set"},{"location":"DS/pySet/#set-operations","text":"Sets can be combined using mathematical operations. The union operator | combines two sets to form a new one containing items in either. OR The intersection operator & gets items only in both. AND The difference operator - gets items in the first set but not in the second. The symmetric difference operator ^ gets items in either set, but not both. XOR The comparison operators check for subset and superset relationships. >= and <= f = { 3 , 2 , 9 , 4 , 5 , 6 } s = { 7 , 8 , 9 , 1 , 4 , 6 , 6 , 8 } print ( f | s ) #Union print ( f & s ) #Intersection print ( f - s ) # Difference print ( f ^ s ) #Sym Difference print ( f >= s ) #f superset of s {1, 2, 3, 4, 5, 6, 7, 8, 9} {9, 4, 6} {2, 3, 5} {1, 2, 3, 5, 7, 8} False Sets provide methods as well as operators. The argument you pass to a method can be any iterable, not just a set. And accept more than one argument f . issuperset ([ 1 , 2 , 3 ]) False f . union ([ 1 , 2 , 3 ], ( 3 , 4 , 5 ), { 5 , 6 , 7 }, { 7 : 'a' , 8 : 'b' }) {1, 2, 3, 4, 5, 6, 7, 8, 9}","title":"Set Operations"},{"location":"DS/pySet/#union","text":"# Python3 program for union() function set1 = { 2 , 4 , 5 , 6 } set2 = { 4 , 6 , 7 , 8 } set3 = { 7 , 8 , 9 , 10 } # union of two sets print ( \"set1 U set2 : \" , set1 . union ( set2 )) # union of three sets print ( \"set1 U set2 U set3 :\" , set1 . union ( set2 , set3 )) set1 U set2 : {2, 4, 5, 6, 7, 8} set1 U set2 U set3 : {2, 4, 5, 6, 7, 8, 9, 10}","title":"Union"},{"location":"DS/pySet/#intersection","text":"# Python3 program for intersection() function set1 = { 2 , 4 , 5 , 6 } set2 = { 4 , 6 , 7 , 8 } set3 = { 4 , 6 , 8 } # union of two sets print ( \"set1 intersection set2 : \" , set1 . intersection ( set2 )) # union of three sets print ( \"set1 intersection set2 intersection set3 :\" , set1 . intersection ( set2 , set3 )) set1 intersection set2 : {4, 6} set1 intersection set2 intersection set3 : {4, 6} # Python3 program for intersection() function set1 = { 2 , 4 , 5 , 6 } set2 = { 4 , 6 , 7 , 8 } set3 = { 1 , 0 , 12 } print ( set1 & set2 ) print ( set1 & set3 ) print ( set1 & set2 & set3 ) {4, 6} set() set()","title":"Intersection"},{"location":"DS/pySet/#difference","text":"# Python code to get the difference between two sets # using difference() between set A and set B # Driver Code A = { 10 , 20 , 30 , 40 , 80 } B = { 100 , 30 , 80 , 40 , 60 } print ( A . difference ( B )) print ( B . difference ( A )) {10, 20} {100, 60}","title":"Difference"},{"location":"DS/pyStack/","text":"A stack is a simple data structure that adds and removes elements in a particular order. Every time an element is added, it goes on the \"top\" of the stack. Only an element at the top of the stack can be removed, just like a stack of plates. This behavior is called LIFO (Last In, First Out). Terminology Adding a new element onto the stack is called push. Removing an element from the stack is called pop. Applications Stacks can be used to create undo-redo functionalities, parsing expressions (infix to postfix/prefix conversion), and much more. There are various ways from which a stack can be implemented in Python. This article covers the implementation of a stack using data structures and modules from the Python library. Stack in Python can be implemented using the following ways: list Collections.deque queue.LifoQueue singly linked list using List Python\u2019s built-in data structure list can be used as a stack. Instead of push(), append() is used to add elements to the top of the stack while pop() removes the element in LIFO order. Unfortunately, the list has a few shortcomings. The biggest issue is that it can run into speed issues as it grows. The items in the list are stored next to each other in memory, if the stack grows bigger than the block of memory that currently holds it, then Python needs to do some memory allocations. This can lead to some append() calls taking much longer than other ones. # Python program to # demonstrate stack implementation # using list stack = [] # append() function to push # element in the stack stack . append ( 'a' ) stack . append ( 'b' ) stack . append ( 'c' ) print ( 'Initial stack' ) print ( stack ) # pop() function to pop # element from stack in # LIFO order print ( ' \\n Elements popped from stack:' ) print ( stack . pop ()) print ( stack . pop ()) print ( stack . pop ()) print ( ' \\n Stack after elements are popped:' ) print ( stack ) # uncommenting print(stack.pop()) # will cause an IndexError # as the stack is now empty Initial stack ['a', 'b', 'c'] Elements popped from stack: c b a Stack after elements are popped: [] using deque Python stack can be implemented using the deque class from the collections module. Deque is preferred over the list in the cases where we need quicker append and pop operations from both the ends of the container, as deque provides an O(1) time complexity for append and pop operations as compared to list which provides O(n) time complexity. The same methods on deque as seen in the list are used, append() and pop(). # Python program to # demonstrate stack implementation # using collections.deque from collections import deque stack = deque () # append() function to push # element in the stack stack . append ( 'a' ) stack . append ( 'b' ) stack . append ( 'c' ) print ( 'Initial stack:' ) print ( stack ) # pop() function to pop # element from stack in # LIFO order print ( ' \\n Elements popped from stack:' ) print ( stack . pop ()) print ( stack . pop ()) print ( stack . pop ()) print ( ' \\n Stack after elements are popped:' ) print ( stack ) # uncommenting print(stack.pop()) # will cause an IndexError # as the stack is now empty Initial stack: deque(['a', 'b', 'c']) Elements popped from stack: c b a Stack after elements are popped: deque([]) using queue module Queue module also has a LIFO Queue, which is basically a Stack. Data is inserted into Queue using the put() function and get() takes data out from the Queue. There are various functions available in this module: maxsize \u2013 Number of items allowed in the queue. empty() \u2013 Return True if the queue is empty, False otherwise. full() \u2013 Return True if there are maxsize items in the queue. If the queue was initialized with maxsize=0 (the default), then full() never returns True. get() \u2013 Remove and return an item from the queue. If the queue is empty, wait until an item is available. get_nowait() \u2013 Return an item if one is immediately available, else raise QueueEmpty. put(item) \u2013 Put an item into the queue. If the queue is full, wait until a free slot is available before adding the item. put_nowait(item) \u2013 Put an item into the queue without blocking. qsize() \u2013 Return the number of items in the queue. If no free slot is immediately available, raise QueueFull. # Python program to # demonstrate stack implementation # using queue module from queue import LifoQueue # Initializing a stack stack = LifoQueue ( maxsize = 3 ) # qsize() show the number of elements # in the stack print ( stack . qsize ()) # put() function to push # element in the stack stack . put ( 'a' ) stack . put ( 'b' ) stack . put ( 'c' ) print ( \"Full: \" , stack . full ()) print ( \"Size: \" , stack . qsize ()) # get() function to pop # element from stack in # LIFO order print ( ' \\n Elements popped from the stack' ) print ( stack . get ()) print ( stack . get ()) print ( stack . get ()) print ( \" \\n Empty: \" , stack . empty ()) 0 Full: True Size: 3 Elements popped from the stack c b a Empty: True using singly linked list The linked list has two methods addHead(item) and removeHead() that run in constant time. These two methods are suitable to implement a stack. getSize()\u2013 Get the number of items in the stack. isEmpty() \u2013 Return True if the stack is empty, False otherwise. peek() \u2013 Return the top item in the stack. If the stack is empty, raise an exception. push(value) \u2013 Push a value into the head of the stack. pop() \u2013 Remove and return a value in the head of the stack. If the stack is empty, raise an exception. # Python program to demonstrate # stack implementation using a linked list. # node class class Node : def __init__ ( self , value ): self . value = value self . next = None class Stack : # Initializing a stack. # Use a dummy node, which is # easier for handling edge cases. def __init__ ( self ): self . head = Node ( \"head\" ) self . size = 0 # String representation of the stack def __str__ ( self ): cur = self . head . next out = \"\" while cur : out += str ( cur . value ) + \"->\" cur = cur . next return out [: - 3 ] # Get the current size of the stack def getSize ( self ): return self . size # Check if the stack is empty def isEmpty ( self ): return self . size == 0 # Get the top item of the stack def peek ( self ): # Sanitary check to see if we # are peeking an empty stack. if self . isEmpty (): raise Exception ( \"Peeking from an empty stack\" ) return self . head . next . value # Push a value into the stack. def push ( self , value ): node = Node ( value ) node . next = self . head . next self . head . next = node self . size += 1 # Remove a value from the stack and return. def pop ( self ): if self . isEmpty (): raise Exception ( \"Popping from an empty stack\" ) remove = self . head . next self . head . next = self . head . next . next self . size -= 1 return remove . value # Driver Code if __name__ == \"__main__\" : stack = Stack () for i in range ( 1 , 11 ): stack . push ( i ) print ( f \"Stack: { stack } \" ) for _ in range ( 1 , 6 ): remove = stack . pop () print ( f \"Pop: { remove } \" ) print ( f \"Stack: { stack } \" ) Stack: 10->9->8->7->6->5->4->3->2-> Pop: 10 Pop: 9 Pop: 8 Pop: 7 Pop: 6 Stack: 5->4->3->2->","title":"Stacks"},{"location":"DS/pyStack/#using-list","text":"Python\u2019s built-in data structure list can be used as a stack. Instead of push(), append() is used to add elements to the top of the stack while pop() removes the element in LIFO order. Unfortunately, the list has a few shortcomings. The biggest issue is that it can run into speed issues as it grows. The items in the list are stored next to each other in memory, if the stack grows bigger than the block of memory that currently holds it, then Python needs to do some memory allocations. This can lead to some append() calls taking much longer than other ones. # Python program to # demonstrate stack implementation # using list stack = [] # append() function to push # element in the stack stack . append ( 'a' ) stack . append ( 'b' ) stack . append ( 'c' ) print ( 'Initial stack' ) print ( stack ) # pop() function to pop # element from stack in # LIFO order print ( ' \\n Elements popped from stack:' ) print ( stack . pop ()) print ( stack . pop ()) print ( stack . pop ()) print ( ' \\n Stack after elements are popped:' ) print ( stack ) # uncommenting print(stack.pop()) # will cause an IndexError # as the stack is now empty Initial stack ['a', 'b', 'c'] Elements popped from stack: c b a Stack after elements are popped: []","title":"using List"},{"location":"DS/pyStack/#using-deque","text":"Python stack can be implemented using the deque class from the collections module. Deque is preferred over the list in the cases where we need quicker append and pop operations from both the ends of the container, as deque provides an O(1) time complexity for append and pop operations as compared to list which provides O(n) time complexity. The same methods on deque as seen in the list are used, append() and pop(). # Python program to # demonstrate stack implementation # using collections.deque from collections import deque stack = deque () # append() function to push # element in the stack stack . append ( 'a' ) stack . append ( 'b' ) stack . append ( 'c' ) print ( 'Initial stack:' ) print ( stack ) # pop() function to pop # element from stack in # LIFO order print ( ' \\n Elements popped from stack:' ) print ( stack . pop ()) print ( stack . pop ()) print ( stack . pop ()) print ( ' \\n Stack after elements are popped:' ) print ( stack ) # uncommenting print(stack.pop()) # will cause an IndexError # as the stack is now empty Initial stack: deque(['a', 'b', 'c']) Elements popped from stack: c b a Stack after elements are popped: deque([])","title":"using deque"},{"location":"DS/pyStack/#using-queue-module","text":"Queue module also has a LIFO Queue, which is basically a Stack. Data is inserted into Queue using the put() function and get() takes data out from the Queue. There are various functions available in this module: maxsize \u2013 Number of items allowed in the queue. empty() \u2013 Return True if the queue is empty, False otherwise. full() \u2013 Return True if there are maxsize items in the queue. If the queue was initialized with maxsize=0 (the default), then full() never returns True. get() \u2013 Remove and return an item from the queue. If the queue is empty, wait until an item is available. get_nowait() \u2013 Return an item if one is immediately available, else raise QueueEmpty. put(item) \u2013 Put an item into the queue. If the queue is full, wait until a free slot is available before adding the item. put_nowait(item) \u2013 Put an item into the queue without blocking. qsize() \u2013 Return the number of items in the queue. If no free slot is immediately available, raise QueueFull. # Python program to # demonstrate stack implementation # using queue module from queue import LifoQueue # Initializing a stack stack = LifoQueue ( maxsize = 3 ) # qsize() show the number of elements # in the stack print ( stack . qsize ()) # put() function to push # element in the stack stack . put ( 'a' ) stack . put ( 'b' ) stack . put ( 'c' ) print ( \"Full: \" , stack . full ()) print ( \"Size: \" , stack . qsize ()) # get() function to pop # element from stack in # LIFO order print ( ' \\n Elements popped from the stack' ) print ( stack . get ()) print ( stack . get ()) print ( stack . get ()) print ( \" \\n Empty: \" , stack . empty ()) 0 Full: True Size: 3 Elements popped from the stack c b a Empty: True","title":"using queue module"},{"location":"DS/pyStack/#using-singly-linked-list","text":"The linked list has two methods addHead(item) and removeHead() that run in constant time. These two methods are suitable to implement a stack. getSize()\u2013 Get the number of items in the stack. isEmpty() \u2013 Return True if the stack is empty, False otherwise. peek() \u2013 Return the top item in the stack. If the stack is empty, raise an exception. push(value) \u2013 Push a value into the head of the stack. pop() \u2013 Remove and return a value in the head of the stack. If the stack is empty, raise an exception. # Python program to demonstrate # stack implementation using a linked list. # node class class Node : def __init__ ( self , value ): self . value = value self . next = None class Stack : # Initializing a stack. # Use a dummy node, which is # easier for handling edge cases. def __init__ ( self ): self . head = Node ( \"head\" ) self . size = 0 # String representation of the stack def __str__ ( self ): cur = self . head . next out = \"\" while cur : out += str ( cur . value ) + \"->\" cur = cur . next return out [: - 3 ] # Get the current size of the stack def getSize ( self ): return self . size # Check if the stack is empty def isEmpty ( self ): return self . size == 0 # Get the top item of the stack def peek ( self ): # Sanitary check to see if we # are peeking an empty stack. if self . isEmpty (): raise Exception ( \"Peeking from an empty stack\" ) return self . head . next . value # Push a value into the stack. def push ( self , value ): node = Node ( value ) node . next = self . head . next self . head . next = node self . size += 1 # Remove a value from the stack and return. def pop ( self ): if self . isEmpty (): raise Exception ( \"Popping from an empty stack\" ) remove = self . head . next self . head . next = self . head . next . next self . size -= 1 return remove . value # Driver Code if __name__ == \"__main__\" : stack = Stack () for i in range ( 1 , 11 ): stack . push ( i ) print ( f \"Stack: { stack } \" ) for _ in range ( 1 , 6 ): remove = stack . pop () print ( f \"Pop: { remove } \" ) print ( f \"Stack: { stack } \" ) Stack: 10->9->8->7->6->5->4->3->2-> Pop: 10 Pop: 9 Pop: 8 Pop: 7 Pop: 6 Stack: 5->4->3->2->","title":"using singly linked list"},{"location":"DS/pyTrees/","text":"Unlike Arrays, Linked Lists, Stack and Queues, which are linear data structures, trees are hierarchical data structures. Tree Vocabulary: Root The topmost node is called root of the tree. Children The elements that are directly under an element are called its children. Parent The element directly above something is called its parent. For example, \u2018a\u2019 is a child of \u2018f\u2019, and \u2018f\u2019 is the parent of \u2018a\u2019. Leaf Finally, elements with no children are called leaves. Main applications of trees include: Manipulate hierarchical data. Make information easy to search (see tree traversal). Manipulate sorted lists of data. As a workflow for compositing digital images for visual effects. Router algorithms Form of a multi-stage decision-making # Python program to introduce Binary Tree # A class that represents an individual node in a # Binary Tree class Node : def __init__ ( self , key ): self . left = None self . right = None self . val = key # create root root = Node ( 1 ) ''' following is the tree after above statement 1 / \\ None None''' root . left = Node ( 2 ); root . right = Node ( 3 ); ''' 2 and 3 become left and right children of 1 1 / \\ 2 3 / \\ / \\ None None None None''' root . left . left = Node ( 4 ); '''4 becomes left child of 2 1 / \\ 2 3 / \\ / \\ 4 None None None / \\ None None'''","title":"Trees"},{"location":"DS/pyTrie/","text":"Trie is a tree-like data structure made up of nodes. Nodes can be used to store data. Each node may have none, one or more children. When used to store a vocabulary, each node is used to store a character, and consequently each \"branch\" of the trie represents a unique word. The following figure shows a trie with five words (was, wax, what, word, work) stored in it. There are two major operations that can be performed on a trie, namely: Inserting a word into the Trie Searching for words using a prefix Inserting Words into the Trie In order to insert a new word into the trie, we need to first check whether any prefix of the word is already in the trie. Therefore, we will start traverse the trie from the root node, and follow the algorithm below: Set the current node to be the root node Set the current character as the first character of the input word Check if the current character is a child of the current node If yes, set the current node to be this child node, set the current character to the next character in the input word, and perform this step again If no, it means from this character onwards, we will need to create new nodes and insert them into the trie Below is an illustration of what will happen when we want to add the word won into the trie above. Following the steps in the algorithm mentioned above, we will arrive at the node o under w, at which point we discover that n is not a child of o, and therefore we create a new node for the character n, and insert it under o. Searching in the Trie A common application scenario of the trie data structure is to search for words with a certain prefix, just like the auto-complete or query suggestion function in a search bar. When given a prefix, we can traverse the trie to check if any word in the trie starts with that prefix. If the prefix is found in the trie, we can then use depth-first traversal to retrieve all the words with that prefix. For example, given the trie illustrated above, which contains the words was, wax, what, word, work and won, let's see what will happen if we want to search for words with the prefix wa: Starting from the root node, we are able to find the node w and a From the node a, we can go on to traverse the trie to retrieve all words starting with the prefix wa When we arrive at the node s, we check whether it is the end of a word (yes), and the word was was output Similarity, when we arrive at the node x, the word wax is output Implementation class TrieNode : \"\"\"A node in the trie structure\"\"\" def __init__ ( self , char ): # the character stored in this node self . char = char # whether this can be the end of a word self . is_end = False # a counter indicating how many times a word is inserted # (if this node's is_end is True) self . counter = 0 # a dictionary of child nodes # keys are characters, values are nodes self . children = {} In this implementation, we want to store also the number of times a word has been inserted into the trie. This allows us to support additional features, such as ranking the words by their popularity. class Trie ( object ): \"\"\"The trie object\"\"\" def __init__ ( self ): \"\"\" The trie has at least the root node. The root node does not store any character \"\"\" self . root = TrieNode ( \"\" ) def insert ( self , word ): \"\"\"Insert a word into the trie\"\"\" node = self . root # Loop through each character in the word # Check if there is no child containing the character, create a new child for the current node for char in word : if char in node . children : node = node . children [ char ] else : # If a character is not found, # create a new node in the trie new_node = TrieNode ( char ) node . children [ char ] = new_node node = new_node # Mark the end of a word node . is_end = True # Increment the counter to indicate that we see this word once more node . counter += 1 def dfs ( self , node , prefix ): \"\"\"Depth-first traversal of the trie Args: - node: the node to start with - prefix: the current prefix, for tracing a word while traversing the trie \"\"\" if node . is_end : self . output . append (( prefix + node . char , node . counter )) for child in node . children . values (): self . dfs ( child , prefix + node . char ) def query ( self , x ): \"\"\"Given an input (a prefix), retrieve all words stored in the trie with that prefix, sort the words by the number of times they have been inserted \"\"\" # Use a variable within the class to keep all possible outputs # As there can be more than one word with such prefix self . output = [] node = self . root # Check if the prefix is in the trie for char in x : if char in node . children : node = node . children [ char ] else : # cannot found the prefix, return empty list return [] # Traverse the trie to get all candidates self . dfs ( node , x [: - 1 ]) # Sort the results in reverse order and return return sorted ( self . output , key = lambda x : x [ 1 ], reverse = True ) Below is an example of how this Trie class can be used: t = Trie () t . insert ( \"was\" ) t . insert ( \"word\" ) t . insert ( \"war\" ) t . insert ( \"what\" ) t . insert ( \"where\" ) t . query ( \"wh\" ) [('what', 1), ('where', 1)] using DefaultDict _end = '_end_' def make_trie ( * words ): root = dict () for word in words : current_dict = root for letter in word : current_dict = current_dict . setdefault ( letter , {}) current_dict [ _end ] = _end return root make_trie ( 'foo' , 'bar' , 'baz' , 'barz' ) {'b': {'a': {'r': {'_end_': '_end_', 'z': {'_end_': '_end_'}}, 'z': {'_end_': '_end_'}}}, 'f': {'o': {'o': {'_end_': '_end_'}}}} setdefault() simply looks up a key in the dictionary (here, letter or _end). If the key is present, it returns the associated value; if not, it assigns a default value to that key and returns the value ({} or _end). (It's like a version of get that also updates the dictionary.) def in_trie ( trie , word ): current_dict = trie for letter in word : if letter not in current_dict : return False current_dict = current_dict [ letter ] return _end in current_dict in_trie ( make_trie ( 'foo' , 'bar' , 'baz' , 'barz' ), 'baz' ) True in_trie ( make_trie ( 'foo' , 'bar' , 'baz' , 'barz' ), 'barzz' ) False","title":"Trie"},{"location":"DS/pyTrie/#inserting-words-into-the-trie","text":"In order to insert a new word into the trie, we need to first check whether any prefix of the word is already in the trie. Therefore, we will start traverse the trie from the root node, and follow the algorithm below: Set the current node to be the root node Set the current character as the first character of the input word Check if the current character is a child of the current node If yes, set the current node to be this child node, set the current character to the next character in the input word, and perform this step again If no, it means from this character onwards, we will need to create new nodes and insert them into the trie Below is an illustration of what will happen when we want to add the word won into the trie above. Following the steps in the algorithm mentioned above, we will arrive at the node o under w, at which point we discover that n is not a child of o, and therefore we create a new node for the character n, and insert it under o.","title":"Inserting Words into the Trie"},{"location":"DS/pyTrie/#searching-in-the-trie","text":"A common application scenario of the trie data structure is to search for words with a certain prefix, just like the auto-complete or query suggestion function in a search bar. When given a prefix, we can traverse the trie to check if any word in the trie starts with that prefix. If the prefix is found in the trie, we can then use depth-first traversal to retrieve all the words with that prefix. For example, given the trie illustrated above, which contains the words was, wax, what, word, work and won, let's see what will happen if we want to search for words with the prefix wa: Starting from the root node, we are able to find the node w and a From the node a, we can go on to traverse the trie to retrieve all words starting with the prefix wa When we arrive at the node s, we check whether it is the end of a word (yes), and the word was was output Similarity, when we arrive at the node x, the word wax is output","title":"Searching in the Trie"},{"location":"DS/pyTrie/#implementation","text":"class TrieNode : \"\"\"A node in the trie structure\"\"\" def __init__ ( self , char ): # the character stored in this node self . char = char # whether this can be the end of a word self . is_end = False # a counter indicating how many times a word is inserted # (if this node's is_end is True) self . counter = 0 # a dictionary of child nodes # keys are characters, values are nodes self . children = {} In this implementation, we want to store also the number of times a word has been inserted into the trie. This allows us to support additional features, such as ranking the words by their popularity. class Trie ( object ): \"\"\"The trie object\"\"\" def __init__ ( self ): \"\"\" The trie has at least the root node. The root node does not store any character \"\"\" self . root = TrieNode ( \"\" ) def insert ( self , word ): \"\"\"Insert a word into the trie\"\"\" node = self . root # Loop through each character in the word # Check if there is no child containing the character, create a new child for the current node for char in word : if char in node . children : node = node . children [ char ] else : # If a character is not found, # create a new node in the trie new_node = TrieNode ( char ) node . children [ char ] = new_node node = new_node # Mark the end of a word node . is_end = True # Increment the counter to indicate that we see this word once more node . counter += 1 def dfs ( self , node , prefix ): \"\"\"Depth-first traversal of the trie Args: - node: the node to start with - prefix: the current prefix, for tracing a word while traversing the trie \"\"\" if node . is_end : self . output . append (( prefix + node . char , node . counter )) for child in node . children . values (): self . dfs ( child , prefix + node . char ) def query ( self , x ): \"\"\"Given an input (a prefix), retrieve all words stored in the trie with that prefix, sort the words by the number of times they have been inserted \"\"\" # Use a variable within the class to keep all possible outputs # As there can be more than one word with such prefix self . output = [] node = self . root # Check if the prefix is in the trie for char in x : if char in node . children : node = node . children [ char ] else : # cannot found the prefix, return empty list return [] # Traverse the trie to get all candidates self . dfs ( node , x [: - 1 ]) # Sort the results in reverse order and return return sorted ( self . output , key = lambda x : x [ 1 ], reverse = True ) Below is an example of how this Trie class can be used: t = Trie () t . insert ( \"was\" ) t . insert ( \"word\" ) t . insert ( \"war\" ) t . insert ( \"what\" ) t . insert ( \"where\" ) t . query ( \"wh\" ) [('what', 1), ('where', 1)]","title":"Implementation"},{"location":"DS/pyTrie/#using-defaultdict","text":"_end = '_end_' def make_trie ( * words ): root = dict () for word in words : current_dict = root for letter in word : current_dict = current_dict . setdefault ( letter , {}) current_dict [ _end ] = _end return root make_trie ( 'foo' , 'bar' , 'baz' , 'barz' ) {'b': {'a': {'r': {'_end_': '_end_', 'z': {'_end_': '_end_'}}, 'z': {'_end_': '_end_'}}}, 'f': {'o': {'o': {'_end_': '_end_'}}}} setdefault() simply looks up a key in the dictionary (here, letter or _end). If the key is present, it returns the associated value; if not, it assigns a default value to that key and returns the value ({} or _end). (It's like a version of get that also updates the dictionary.) def in_trie ( trie , word ): current_dict = trie for letter in word : if letter not in current_dict : return False current_dict = current_dict [ letter ] return _end in current_dict in_trie ( make_trie ( 'foo' , 'bar' , 'baz' , 'barz' ), 'baz' ) True in_trie ( make_trie ( 'foo' , 'bar' , 'baz' , 'barz' ), 'barzz' ) False","title":"using DefaultDict"},{"location":"DS/pyTuple/","text":"A tuple is a Python collection that is extremely similar to a list, with some subtle differences. For starters, tuples are indicated using parentheses instead of square brackets. Like lists and dictionaries, tuples can be nested within each other. x = 1 y = 2 coordinates = ( x , y ) The variable coordinates above is a tuple containing the variables x and y. This example was chosen to also demonstrate a difference between the typical usage of tuples versus lists. Whereas lists are frequently used to contain objects whose values are similar in some sense, tuples are frequently used to contain attributes of a coherent unit. For instance, as above, it makes sense to treat the coordinates of a point as a single unit. As another example, consider the following tuple and list concerning dates: year1 = 2011 month1 = \"May\" day1 = 18 date1 = ( month1 , day1 , year1 ) year2 = 2017 month2 = \"June\" day2 = 13 date2 = ( month2 , day2 , year2 ) years_list = [ year1 , year2 ] Notice above that we have collected the attributes of a single date into one tuple: those pieces of information all describe a single \"unit\". By contrast, in the years list we have collected the different years. In the code-snippet: the values in the list have a commonality (they are both years), but they do not describe the same unit. The distinction drawn between tuples and lists is one that many Python programmers recognize in practice, but not one that is strictly enforced (i.e., you won't get any errors if you break this convention!). Another subtle way in which tuples and lists differ involves what is called mutability of Python variables. Mutability refers to the fact that a mutable object can be changed after it is created, and an immutable object can\u2019t. Tuples are not mutable, lists are mutable. Tuples are very similar to lists, except that they are immutable (they cannot be changed). Trying to reassign a value in a tuple causes a TypeError. Objects of built-in types like (int, float, bool, str, tuple, frozenset, unicode) are immutable. Objects of built-in types like (list, set, dict, byte array) are mutable. Custom classes are generally mutable. To simulate immutability in a class, one should override attribute setting and deletion to raise exceptions. To read further. words = ( \"spam\" , \"eggs\" , \"sausages\" ,) print ( words [ 0 ]) words [ 1 ] = \"cheese\" spam --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-85-a8af92c7d33f> in <module>() 1 words = (\"spam\", \"eggs\", \"sausages\",) 2 print(words[0]) ----> 3 words[1]=\"cheese\" TypeError: 'tuple' object does not support item assignment Tuples can be created without the parentheses, by just separating the values with commas. An empty tuple is created using an empty parenthesis pair. Tuples are faster than lists, but they cannot be changed. Slicing can also be done on tuples. my_tp = () tp = \"one\" , \"two\" , \"three\" print ( tp [ 0 ]) print ( len ( my_tp )) print ( tp [ 1 :]) one 0 ('two', 'three') Tuple unpacking Tuple unpacking allows you to assign each item in an iterable (often a tuple) to a variable. This can be also used to swap variables by doing a, b = b, a , since b, a on the right hand side forms the tuple (b, a) which is then unpacked. A variable that is prefaced with an asterisk (*) takes all values from the iterable that are left over from the other variables. numbers = ( 1 , 2 , 3 ) a , b , c = numbers #unpacking print ( a ) print ( b ) print ( c ) 1 2 3 a , b , * c , d = ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ) print ( a ) print ( b ) print ( c ) print ( d ) 1 2 [3, 4, 5, 6, 7, 8] 9","title":"Tuple"},{"location":"DS/pyTuple/#tuple-unpacking","text":"Tuple unpacking allows you to assign each item in an iterable (often a tuple) to a variable. This can be also used to swap variables by doing a, b = b, a , since b, a on the right hand side forms the tuple (b, a) which is then unpacked. A variable that is prefaced with an asterisk (*) takes all values from the iterable that are left over from the other variables. numbers = ( 1 , 2 , 3 ) a , b , c = numbers #unpacking print ( a ) print ( b ) print ( c ) 1 2 3 a , b , * c , d = ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ) print ( a ) print ( b ) print ( c ) print ( d ) 1 2 [3, 4, 5, 6, 7, 8] 9","title":"Tuple unpacking"},{"location":"DS/pyUserDefGen/","text":"Linear data structures Lists Stacks Queue and Deque LinkedLists Non-linear data structures Mapping data structures Set Counter Hashtables and Hashmaps Tree data structures Trees (BST) Priority Queue Trie Graph data structures Dictionary of dictionaries Adjacent matrix","title":"General"},{"location":"DS/pyUserDefGen/#linear-data-structures","text":"Lists Stacks Queue and Deque LinkedLists","title":"Linear data structures"},{"location":"DS/pyUserDefGen/#non-linear-data-structures","text":"","title":"Non-linear data structures"},{"location":"DS/pyUserDefGen/#mapping-data-structures","text":"Set Counter Hashtables and Hashmaps","title":"Mapping data structures"},{"location":"DS/pyUserDefGen/#tree-data-structures","text":"Trees (BST) Priority Queue Trie","title":"Tree data structures"},{"location":"DS/pyUserDefGen/#graph-data-structures","text":"Dictionary of dictionaries Adjacent matrix","title":"Graph data structures"},{"location":"DS/pydeque/","text":"The collection Module in Python provides different types of containers. A Container is an object that is used to store different objects and provide a way to access the contained objects and iterate over them. Some of the built-in containers are Tuple, List, Dictionary, etc. import collections Deque (Doubly Ended Queue) in Python is implemented using the module \u201ccollections\u201c. Deque is preferred over list in the cases where we need quicker append and pop operations from both the ends of container, as deque provides an O(1) time complexity for append and pop operations as compared to list which provides O(n) time complexity. With Python lists, we can add and remove elements from the end of the list in constant time, but adding and removing from the beginning takes linear time. That\u2019s because Python lists are implemented using arrays that grow dynamically. With linked lists, we can add and remove elements from the beginning of the list in constant time, but adding and removing from the end takes linear time. With either of these implementations, it is easy to make a stack, that is, a collection where the first element we add is the last element we remove. A stack is also called a \u201cfirst-in, last-out\u201d queue, abbreviated FILO. But it is not easy to implement a \u201cfirst-in, first-out\u201d queue, that is, a collection where the first element we add is the first element we remove. Fortunately, there are ways to implement lists that can add and remove elements from both ends in constant time. A collection that has this property is called a double-ended queue, abbreviated \u201cdeque\u201d and pronounced like \u201cdeck\u201d. One way to implement a deque is a doubly-linked list, also known as a \u201chead-tail linked list\u201d. Each node in a doubly-linked list has a reference to the previous node in the list as well as the next element, which I will call left and right. Constructor dq = collections . deque ( range ( 10 )) dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) append() & popleft() for i in range ( 10 , 15 ): dq . append ( i ) v = dq . popleft () print ( \"Inserted :\" , i , \"- popped: \" , v , \"-result:\" , dq ) Inserted : 10 - popped: 0 -result: deque([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) Inserted : 11 - popped: 1 -result: deque([2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) Inserted : 12 - popped: 2 -result: deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) Inserted : 13 - popped: 3 -result: deque([4, 5, 6, 7, 8, 9, 10, 11, 12, 13]) Inserted : 14 - popped: 4 -result: deque([5, 6, 7, 8, 9, 10, 11, 12, 13, 14]) appendleft() & pop() for i in reversed ( range ( 0 , 5 )): dq . appendleft ( i ) v = dq . pop () print ( \"Inserted :\" , i , \"- popped: \" , v , \"-result:\" , dq ) Inserted : 4 - popped: 14 -result: deque([4, 5, 6, 7, 8, 9, 10, 11, 12, 13]) Inserted : 3 - popped: 13 -result: deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) Inserted : 2 - popped: 12 -result: deque([2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) Inserted : 1 - popped: 11 -result: deque([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) Inserted : 0 - popped: 10 -result: deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) index(ele, beg, end) This function returns the first index of the value mentioned in arguments, starting searching from beg till end index. insert(i, a) This function inserts the value mentioned in arguments(a) at index(i) specified in arguments. remove() This function removes the first occurrence of value mentioned in arguments. count() This function counts the number of occurrences of value mentioned in arguments. # Python code to demonstrate working of # insert(), index(), remove(), count() # importing \"collections\" for deque operations import collections # initializing deque de = collections . deque ([ 1 , 2 , 3 , 3 , 4 , 2 , 4 ]) # using index() to print the first occurrence of 4 print ( \"The number 4 first occurs at a position : \" ) print ( de . index ( 4 , 2 , 5 )) # using insert() to insert the value 3 at 5th position de . insert ( 4 , 3 ) # printing modified deque print ( \"The deque after inserting 3 at 5th position is : \" ) print ( de ) # using count() to count the occurrences of 3 print ( \"The count of 3 in deque is : \" ) print ( de . count ( 3 )) # using remove() to remove the first occurrence of 3 de . remove ( 3 ) # printing modified deque print ( \"The deque after deleting first occurrence of 3 is : \" ) print ( de ) The number 4 first occurs at a position : 4 The deque after inserting 3 at 5th position is : deque([1, 2, 3, 3, 3, 4, 2, 4]) The count of 3 in deque is : 3 The deque after deleting first occurrence of 3 is : deque([1, 2, 3, 3, 4, 2, 4]) extend(iterable) This function is used to add multiple values at the right end of deque. The argument passed is an iterable. extendleft(iterable) This function is used to add multiple values at the left end of deque. The argument passed is an iterable. Order is reversed as a result of left appends. reverse() This function is used to reverse order of deque elements. rotate() This function rotates the deque by the number specified in arguments. If the number specified is negative, rotation occurs to left. Else rotation is to right. # Python code to demonstrate working of # extend(), extendleft(), rotate(), reverse() # importing \"collections\" for deque operations import collections # initializing deque de = collections . deque ([ 1 , 2 , 3 ,]) # using extend() to add numbers to right end # adds 4,5,6 to right end de . extend ([ 4 , 5 , 6 ]) # printing modified deque print ( \"The deque after extending deque at end is : \" ) print ( de ) # using extendleft() to add numbers to left end # adds 7,8,9 to right end de . extendleft ([ 7 , 8 , 9 ]) # printing modified deque print ( \"The deque after extending deque at beginning is : \" ) print ( de ) # using rotate() to rotate the deque # rotates by 3 to left de . rotate ( - 3 ) # printing modified deque print ( \"The deque after rotating deque is : \" ) print ( de ) # using reverse() to reverse the deque de . reverse () # printing modified deque print ( \"The deque after reversing deque is : \" ) print ( de ) The deque after extending deque at end is : deque([1, 2, 3, 4, 5, 6]) The deque after extending deque at beginning is : deque([9, 8, 7, 1, 2, 3, 4, 5, 6]) The deque after rotating deque is : deque([1, 2, 3, 4, 5, 6, 9, 8, 7]) The deque after reversing deque is : deque([7, 8, 9, 6, 5, 4, 3, 2, 1])","title":"Deque"},{"location":"DS/pydeque/#constructor","text":"dq = collections . deque ( range ( 10 )) dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])","title":"Constructor"},{"location":"DS/pydeque/#append-popleft","text":"for i in range ( 10 , 15 ): dq . append ( i ) v = dq . popleft () print ( \"Inserted :\" , i , \"- popped: \" , v , \"-result:\" , dq ) Inserted : 10 - popped: 0 -result: deque([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) Inserted : 11 - popped: 1 -result: deque([2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) Inserted : 12 - popped: 2 -result: deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) Inserted : 13 - popped: 3 -result: deque([4, 5, 6, 7, 8, 9, 10, 11, 12, 13]) Inserted : 14 - popped: 4 -result: deque([5, 6, 7, 8, 9, 10, 11, 12, 13, 14])","title":"append() &amp; popleft()"},{"location":"DS/pydeque/#appendleft-pop","text":"for i in reversed ( range ( 0 , 5 )): dq . appendleft ( i ) v = dq . pop () print ( \"Inserted :\" , i , \"- popped: \" , v , \"-result:\" , dq ) Inserted : 4 - popped: 14 -result: deque([4, 5, 6, 7, 8, 9, 10, 11, 12, 13]) Inserted : 3 - popped: 13 -result: deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) Inserted : 2 - popped: 12 -result: deque([2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) Inserted : 1 - popped: 11 -result: deque([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) Inserted : 0 - popped: 10 -result: deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])","title":"appendleft() &amp; pop()"},{"location":"DS/pydeque/#indexele-beg-end","text":"This function returns the first index of the value mentioned in arguments, starting searching from beg till end index.","title":"index(ele, beg, end)"},{"location":"DS/pydeque/#inserti-a","text":"This function inserts the value mentioned in arguments(a) at index(i) specified in arguments.","title":"insert(i, a)"},{"location":"DS/pydeque/#remove","text":"This function removes the first occurrence of value mentioned in arguments.","title":"remove()"},{"location":"DS/pydeque/#count","text":"This function counts the number of occurrences of value mentioned in arguments. # Python code to demonstrate working of # insert(), index(), remove(), count() # importing \"collections\" for deque operations import collections # initializing deque de = collections . deque ([ 1 , 2 , 3 , 3 , 4 , 2 , 4 ]) # using index() to print the first occurrence of 4 print ( \"The number 4 first occurs at a position : \" ) print ( de . index ( 4 , 2 , 5 )) # using insert() to insert the value 3 at 5th position de . insert ( 4 , 3 ) # printing modified deque print ( \"The deque after inserting 3 at 5th position is : \" ) print ( de ) # using count() to count the occurrences of 3 print ( \"The count of 3 in deque is : \" ) print ( de . count ( 3 )) # using remove() to remove the first occurrence of 3 de . remove ( 3 ) # printing modified deque print ( \"The deque after deleting first occurrence of 3 is : \" ) print ( de ) The number 4 first occurs at a position : 4 The deque after inserting 3 at 5th position is : deque([1, 2, 3, 3, 3, 4, 2, 4]) The count of 3 in deque is : 3 The deque after deleting first occurrence of 3 is : deque([1, 2, 3, 3, 4, 2, 4])","title":"count()"},{"location":"DS/pydeque/#extenditerable","text":"This function is used to add multiple values at the right end of deque. The argument passed is an iterable.","title":"extend(iterable)"},{"location":"DS/pydeque/#extendleftiterable","text":"This function is used to add multiple values at the left end of deque. The argument passed is an iterable. Order is reversed as a result of left appends.","title":"extendleft(iterable)"},{"location":"DS/pydeque/#reverse","text":"This function is used to reverse order of deque elements.","title":"reverse()"},{"location":"DS/pydeque/#rotate","text":"This function rotates the deque by the number specified in arguments. If the number specified is negative, rotation occurs to left. Else rotation is to right. # Python code to demonstrate working of # extend(), extendleft(), rotate(), reverse() # importing \"collections\" for deque operations import collections # initializing deque de = collections . deque ([ 1 , 2 , 3 ,]) # using extend() to add numbers to right end # adds 4,5,6 to right end de . extend ([ 4 , 5 , 6 ]) # printing modified deque print ( \"The deque after extending deque at end is : \" ) print ( de ) # using extendleft() to add numbers to left end # adds 7,8,9 to right end de . extendleft ([ 7 , 8 , 9 ]) # printing modified deque print ( \"The deque after extending deque at beginning is : \" ) print ( de ) # using rotate() to rotate the deque # rotates by 3 to left de . rotate ( - 3 ) # printing modified deque print ( \"The deque after rotating deque is : \" ) print ( de ) # using reverse() to reverse the deque de . reverse () # printing modified deque print ( \"The deque after reversing deque is : \" ) print ( de ) The deque after extending deque at end is : deque([1, 2, 3, 4, 5, 6]) The deque after extending deque at beginning is : deque([9, 8, 7, 1, 2, 3, 4, 5, 6]) The deque after rotating deque is : deque([1, 2, 3, 4, 5, 6, 9, 8, 7]) The deque after reversing deque is : deque([7, 8, 9, 6, 5, 4, 3, 2, 1])","title":"rotate()"},{"location":"Exe/pyGen/","text":"Record of Useful Exercises for Coding Interviews","title":"General"},{"location":"Func/pyAnn/","text":"PEP 3107 PEP stands for Python Enhancement Proposal. It is a design document that describes new features for Python or its processes or environment. It also provides information to the python community. PEP-3107 introduced the concept and syntax for adding arbitrary metadata annotations to Python. There's no preconceived use case, but the PEP suggests several. One very handy one is to allow you to annotate parameters with their expected types; it would then be easy to write a decorator that verifies the annotations or coerces the arguments to the right type. Another is to allow parameter-specific documentation instead of encoding it into the docstring. Function annotations are only supported in python 3x. Details here the -> marks the return function annotation. def kinetic_energy ( m : 'in KG' , v : 'in M/S' ) -> 'Joules' : return 1 / 2 * m * v ** 2 kinetic_energy . __annotations__ {'m': 'in KG', 'return': 'Joules', 'v': 'in M/S'} Annotations are dictionaries, so you can do this: ' {:,} {} ' . format ( kinetic_energy ( 12 , 30 ), kinetic_energy . __annotations__ [ 'return' ]) 5,400.0 Joules You can also have a python data structure rather than just a string: rd = { 'type' : float , 'units' : 'Joules' , 'docstring' : 'Given mass and velocity returns kinetic energy in Joules' } def f () -> rd : pass f . __annotations__ [ 'return' ][ 'type' ] float f . __annotations__ [ 'return' ][ 'units' ] Joules f . __annotations__ [ 'return' ][ 'docstring' ] Given mass and velocity returns kinetic energy in Joules Or, you can use function attributes to validate called values: def validate ( func , locals ): for var , test in func . __annotations__ . items (): value = locals [ var ] try : pr = test . __name__ + ': ' + test . __docstring__ except AttributeError : pr = test . __name__ msg = ' {} == {} ; Test: {} ' . format ( var , value , pr ) assert test ( value ), msg def between ( lo , hi ): def _between ( x ): return lo <= x <= hi _between . __docstring__ = 'must be between {} and {} ' . format ( lo , hi ) return _between def f ( x : between ( 3 , 10 ), y : lambda _y : isinstance ( _y , int )): validate ( f , locals ()) print ( x , y ) f ( 2 , 2 ) --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) <ipython-input-8-e43489394a12> in <module>() ----> 1 f(2,2) 1 frames <ipython-input-7-b73806aca747> in validate(func, locals) 7 pr=test.__name__ 8 msg = '{}=={}; Test: {}'.format(var, value, pr) ----> 9 assert test(value), msg 10 11 def between(lo, hi): AssertionError: x==2; Test: _between: must be between 3 and 10 f ( 3 , 2.1 ) --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) <ipython-input-9-d705e73c1fc6> in <module>() ----> 1 f(3,2.1) 1 frames <ipython-input-7-b73806aca747> in validate(func, locals) 7 pr=test.__name__ 8 msg = '{}=={}; Test: {}'.format(var, value, pr) ----> 9 assert test(value), msg 10 11 def between(lo, hi): AssertionError: y==2.1; Test: <lambda> f ( 3 , 4 ) 3 4","title":"Annotations"},{"location":"Func/pyCtxtMgr/","text":"The with Keyword Context managers are a really helpful structure in Python. Each context manager executes specific code before and after the statements you specify. To use one, you use the with keyword: with <context manager> as <var>: <statements> Using with gives you a way to define code to be executed within the context manager\u2019s scope. The most basic example of this is when you\u2019re working with file I/O in Python. If you wanted to open a file, do something with that file, and then make sure that the file was closed correctly, then you would use a context manager. Consider this example in which names.txt contains a list of names, one per line: with open ( \"names.txt\" ) as input_file : for name in input_file : print ( name . strip ()) The file I/O context manager provided by open() and initiated with the with keyword opens the file for reading, assigns the open file pointer to input_file, then executes whatever code you specify in the with block. Then, after the block is executed, the file pointer closes. Even if your code in the with block raises an exception, the file pointer would still close. The as Keyword If you want access to the results of the expression or context manager passed to with, you\u2019ll need to alias it using as. You may have also seen as used to alias imports and exceptions, and this is no different. The alias is available in the with block: with <expr> as <alias>: <statements> Most of the time, you\u2019ll see these two Python keywords, with and as, used together.","title":"Context Managers"},{"location":"Func/pyCtxtMgr/#the-with-keyword","text":"Context managers are a really helpful structure in Python. Each context manager executes specific code before and after the statements you specify. To use one, you use the with keyword: with <context manager> as <var>: <statements> Using with gives you a way to define code to be executed within the context manager\u2019s scope. The most basic example of this is when you\u2019re working with file I/O in Python. If you wanted to open a file, do something with that file, and then make sure that the file was closed correctly, then you would use a context manager. Consider this example in which names.txt contains a list of names, one per line: with open ( \"names.txt\" ) as input_file : for name in input_file : print ( name . strip ()) The file I/O context manager provided by open() and initiated with the with keyword opens the file for reading, assigns the open file pointer to input_file, then executes whatever code you specify in the with block. Then, after the block is executed, the file pointer closes. Even if your code in the with block raises an exception, the file pointer would still close.","title":"The with Keyword"},{"location":"Func/pyCtxtMgr/#the-as-keyword","text":"If you want access to the results of the expression or context manager passed to with, you\u2019ll need to alias it using as. You may have also seen as used to alias imports and exceptions, and this is no different. The alias is available in the with block: with <expr> as <alias>: <statements> Most of the time, you\u2019ll see these two Python keywords, with and as, used together.","title":"The as Keyword"},{"location":"Func/pyDecor/","text":"A Decorator is a callable that takes another function as an argument, extending the behavior of that function without explicitly modifying that function. Decorators provide a way to modify functions using other functions. This is ideal when you need to extend the functionality of functions that you don't want to modify. Functions within functions def fib_3 ( a , b , c ): def get_3 (): return a , b , c return get_3 fib_3 ( 1 , 1 , 2 ) <function __main__.fib_3.<locals>.get_3> f = fib_3 ( 1 , 1 , 2 ) f () (1, 1, 2) We defined a function named decor that has a single parameter func. Inside decor, we defined a nested function named wrap. The wrap function will print a string, then call func(), and print another string. The decor function returns the wrap function as its result. We could say that the variable decorated is a decorated version of print_text - it's print_text plus something. def decor ( func ): def wrap (): '''This is the wrapper''' #Do something before print ( \"***************\" ) func () #Do something after print ( \"***************\" ) return wrap def print_text (): '''Prints Hello''' print ( \"Hello\" ) decorated = decor ( print_text ) decorated () *************** Hello *************** print_text . __name__ print_text print_text . __doc__ Prints Hello Python provides support to wrap a function in a decorator by pre-pending the function definition with a decorator name and the @ symbol. If we are defining a function we can \"decorate\" it with the @ symbol like. A single function can have multiple decorators. def print_text (): print ( \"Hello\" ) print_text = decor ( print_text ) print_text () *************** Hello *************** Is equivalent to: @decor def print_text (): '''Prints Hello''' print ( \"Hello\" ) print_text () *************** Hello *************** print_text . __name__ wrap print_text . __doc__ This is the wrapper To avoid this problem use functools from functools import wraps def decor ( func ): @wraps ( func ) def wrap (): '''This is the wrapper''' #Do something before print ( \"***************\" ) func () #Do something after print ( \"***************\" ) return wrap @decor def print_text (): '''Prints Hello''' print ( \"Hello\" ) print_text () *************** Hello *************** print_text . __name__ print_text print_text . __doc__ Prints Hello Decorators with arguments def pfib ( a , b , c ): print ( a , b , c ) pfib ( 1 , 1 , 2 ) 1 1 2 If I dont want only 3 args but more def pfib ( a , * args ): print ( a ) print ( args ) pfib ( 1 , 1 , 2 , 3 ) 1 (1, 2, 3) def pfib ( a , ** kwargs ): print ( a ) print ( kwargs ) pfib ( 1 , se = 1 , th = 2 , fo = 3 , fi = 5 ) 1 {'se': 1, 'th': 2, 'fo': 3, 'fi': 5} def pfib ( * args , ** kwargs ): print ( args ) print ( kwargs ) pfib ( 1 , 2 , 2 , se = 1 , th = 2 , fo = 3 , fi = 5 ) (1, 2, 2) {'se': 1, 'th': 2, 'fo': 3, 'fi': 5} def wrapper ( * args , ** kwargs ): print ( * args ) print ( 'Leaving wrapper' ) pfib ( * args , ** kwargs ) print ( kwargs ) wrapper ( 1 , 1 , th = 2 ) 1 1 Leaving wrapper (1, 1) {'th': 2} {'th': 2} The template is: from functools import wraps def decorator ( func ): @wraps ( func ) def wrapper ( * args , ** kwargs ): #Do something before result = func ( * args , ** kwargs ) #Do something after return result return wrapper @decorator def func (): pass Decorators with classes We can define a decorator as a class in order to do that, we have to use a call method of classes. # Python program showing # use of __call__() method class MyDecorator : def __init__ ( self , function ): self . function = function def __call__ ( self ): # We can add some code # before function call self . function () # We can also add some code # after function call. # adding class decorator to the function @MyDecorator def function (): print ( \"Meps3\" ) function () Meps3 # Python program showing # class decorator with *args # and **kwargs class MyDecorator : def __init__ ( self , function ): self . function = function def __call__ ( self , * args , ** kwargs ): # We can add some code # before function call self . function ( * args , ** kwargs ) # We can also add some code # after function call. # adding class decorator to the function @MyDecorator def function ( name , message = 'Hello' ): print ( \" {} , {} \" . format ( message , name )) function ( \"gpes3\" , \"hello\" ) hello, gpes3 # Python program to execute # time of a program # importing time module from time import time class Timer : def __init__ ( self , func ): self . function = func def __call__ ( self , * args , ** kwargs ): start_time = time () result = self . function ( * args , ** kwargs ) end_time = time () print ( \"Execution took {} seconds\" . format ( end_time - start_time )) return result # adding a decorator to the function @Timer def some_function ( delay ): from time import sleep # Introducing some time delay to # simulate a time taking function. sleep ( delay ) some_function ( 3 ) Execution took 3.003098487854004 seconds Decorators as a cache: Memoization LRU is the cache replacement algorithm that removes the least recently used data and stores the new data. Suppose we have a cache space of 10 memory frames. And each frame is filled with a file. Now if we want to store the new file, we need to remove the oldest file in the cache and add the new file. This is how LRU works. LRU cache consists of Queue and Dictionary data structures. Queue: to store the most recently used to least recently used files Hash table: to store the file and its position in the cache lru_cache() is one such function in functools module which helps in reducing the execution time of the function by using memoization technique. from functools import lru_cache import time # Function that computes Fibonacci # numbers without lru_cache def fib_without_cache ( n ): if n < 2 : return n return fib_without_cache ( n - 1 ) + fib_without_cache ( n - 2 ) # Execution start time begin = time . time () fib_without_cache ( 30 ) # Execution end time end = time . time () print ( \"Time taken to execute the \\ function without lru_cache is\" , end - begin ) # Function that computes Fibonacci # numbers with lru_cache @lru_cache ( maxsize = 128 ) def fib_with_cache ( n ): if n < 2 : return n return fib_with_cache ( n - 1 ) + fib_with_cache ( n - 2 ) begin = time . time () fib_with_cache ( 30 ) end = time . time () print ( \"Time taken to execute the \\ function with lru_cache is\" , end - begin ) Time taken to execute the function without lru_cache is 0.3661181926727295 Time taken to execute the function with lru_cache is 7.653236389160156e-05","title":"Decorators"},{"location":"Func/pyDecor/#functions-within-functions","text":"def fib_3 ( a , b , c ): def get_3 (): return a , b , c return get_3 fib_3 ( 1 , 1 , 2 ) <function __main__.fib_3.<locals>.get_3> f = fib_3 ( 1 , 1 , 2 ) f () (1, 1, 2) We defined a function named decor that has a single parameter func. Inside decor, we defined a nested function named wrap. The wrap function will print a string, then call func(), and print another string. The decor function returns the wrap function as its result. We could say that the variable decorated is a decorated version of print_text - it's print_text plus something. def decor ( func ): def wrap (): '''This is the wrapper''' #Do something before print ( \"***************\" ) func () #Do something after print ( \"***************\" ) return wrap def print_text (): '''Prints Hello''' print ( \"Hello\" ) decorated = decor ( print_text ) decorated () *************** Hello *************** print_text . __name__ print_text print_text . __doc__ Prints Hello Python provides support to wrap a function in a decorator by pre-pending the function definition with a decorator name and the @ symbol. If we are defining a function we can \"decorate\" it with the @ symbol like. A single function can have multiple decorators. def print_text (): print ( \"Hello\" ) print_text = decor ( print_text ) print_text () *************** Hello *************** Is equivalent to: @decor def print_text (): '''Prints Hello''' print ( \"Hello\" ) print_text () *************** Hello *************** print_text . __name__ wrap print_text . __doc__ This is the wrapper To avoid this problem use functools from functools import wraps def decor ( func ): @wraps ( func ) def wrap (): '''This is the wrapper''' #Do something before print ( \"***************\" ) func () #Do something after print ( \"***************\" ) return wrap @decor def print_text (): '''Prints Hello''' print ( \"Hello\" ) print_text () *************** Hello *************** print_text . __name__ print_text print_text . __doc__ Prints Hello","title":"Functions within functions"},{"location":"Func/pyDecor/#decorators-with-arguments","text":"def pfib ( a , b , c ): print ( a , b , c ) pfib ( 1 , 1 , 2 ) 1 1 2 If I dont want only 3 args but more def pfib ( a , * args ): print ( a ) print ( args ) pfib ( 1 , 1 , 2 , 3 ) 1 (1, 2, 3) def pfib ( a , ** kwargs ): print ( a ) print ( kwargs ) pfib ( 1 , se = 1 , th = 2 , fo = 3 , fi = 5 ) 1 {'se': 1, 'th': 2, 'fo': 3, 'fi': 5} def pfib ( * args , ** kwargs ): print ( args ) print ( kwargs ) pfib ( 1 , 2 , 2 , se = 1 , th = 2 , fo = 3 , fi = 5 ) (1, 2, 2) {'se': 1, 'th': 2, 'fo': 3, 'fi': 5} def wrapper ( * args , ** kwargs ): print ( * args ) print ( 'Leaving wrapper' ) pfib ( * args , ** kwargs ) print ( kwargs ) wrapper ( 1 , 1 , th = 2 ) 1 1 Leaving wrapper (1, 1) {'th': 2} {'th': 2} The template is: from functools import wraps def decorator ( func ): @wraps ( func ) def wrapper ( * args , ** kwargs ): #Do something before result = func ( * args , ** kwargs ) #Do something after return result return wrapper @decorator def func (): pass","title":"Decorators with arguments"},{"location":"Func/pyDecor/#decorators-with-classes","text":"We can define a decorator as a class in order to do that, we have to use a call method of classes. # Python program showing # use of __call__() method class MyDecorator : def __init__ ( self , function ): self . function = function def __call__ ( self ): # We can add some code # before function call self . function () # We can also add some code # after function call. # adding class decorator to the function @MyDecorator def function (): print ( \"Meps3\" ) function () Meps3 # Python program showing # class decorator with *args # and **kwargs class MyDecorator : def __init__ ( self , function ): self . function = function def __call__ ( self , * args , ** kwargs ): # We can add some code # before function call self . function ( * args , ** kwargs ) # We can also add some code # after function call. # adding class decorator to the function @MyDecorator def function ( name , message = 'Hello' ): print ( \" {} , {} \" . format ( message , name )) function ( \"gpes3\" , \"hello\" ) hello, gpes3 # Python program to execute # time of a program # importing time module from time import time class Timer : def __init__ ( self , func ): self . function = func def __call__ ( self , * args , ** kwargs ): start_time = time () result = self . function ( * args , ** kwargs ) end_time = time () print ( \"Execution took {} seconds\" . format ( end_time - start_time )) return result # adding a decorator to the function @Timer def some_function ( delay ): from time import sleep # Introducing some time delay to # simulate a time taking function. sleep ( delay ) some_function ( 3 ) Execution took 3.003098487854004 seconds","title":"Decorators with classes"},{"location":"Func/pyDecor/#decorators-as-a-cache-memoization","text":"LRU is the cache replacement algorithm that removes the least recently used data and stores the new data. Suppose we have a cache space of 10 memory frames. And each frame is filled with a file. Now if we want to store the new file, we need to remove the oldest file in the cache and add the new file. This is how LRU works. LRU cache consists of Queue and Dictionary data structures. Queue: to store the most recently used to least recently used files Hash table: to store the file and its position in the cache lru_cache() is one such function in functools module which helps in reducing the execution time of the function by using memoization technique. from functools import lru_cache import time # Function that computes Fibonacci # numbers without lru_cache def fib_without_cache ( n ): if n < 2 : return n return fib_without_cache ( n - 1 ) + fib_without_cache ( n - 2 ) # Execution start time begin = time . time () fib_without_cache ( 30 ) # Execution end time end = time . time () print ( \"Time taken to execute the \\ function without lru_cache is\" , end - begin ) # Function that computes Fibonacci # numbers with lru_cache @lru_cache ( maxsize = 128 ) def fib_with_cache ( n ): if n < 2 : return n return fib_with_cache ( n - 1 ) + fib_with_cache ( n - 2 ) begin = time . time () fib_with_cache ( 30 ) end = time . time () print ( \"Time taken to execute the \\ function with lru_cache is\" , end - begin ) Time taken to execute the function without lru_cache is 0.3661181926727295 Time taken to execute the function with lru_cache is 7.653236389160156e-05","title":"Decorators as a cache: Memoization"},{"location":"Func/pyDoc/","text":"Docstrings (documentation strings) serve a similar purpose to comments, as they are designed to explain code. However, they are more specific and have a different syntax. They are created by putting a multiline string containing an explanation of the function below the function's first line. Unlike conventional comments, docstrings are retained throughout the runtime of the program. This allows the programmer to inspect these comments at run time. def sumt ( x , y ): \"\"\" Multiplies by two the sum of parameters Parameters ---------- x : int First Number. y : int Second Number. Returns ------- z : int Result of the operation Examples -------- >>> sumt(2, 3) 12 \"\"\" return ( x + y ) * 2 The docstring is a triple-quoted string (which may span multiple lines) that comes immediately after the header of a function. When we call help() or .doc on a function, it shows the docstring. help ( sumt ) Help on function sumt in module __main__: sumt(x, y) Multiplies by two the sum of parameters Parameters ---------- x : int First Number. y : int Second Number. Returns ------- z : int Result of the operation Examples -------- >>> sumt(2, 3) 12 print ( sumt . __doc__ ) Multiplies by two the sum of parameters Parameters ---------- x : int First Number. y : int Second Number. Returns ------- z : int Result of the operation Examples -------- >>> sumt(2, 3) 12","title":"Documentation"},{"location":"Func/pyFnArgs/","text":"Python allows to have function with varying number of arguments. Using args as a function parameter enables you to pass an arbitrary number of arguments to that function. The arguments are then accessible as the tuple args in the body of the function. The parameter args must come after the named parameters to a function. The name args is just a convention; you can choose to use another. *args is called an argument list. def function ( named_args , * args ): print ( named_args ) print ( args ) function ( 1 , 2 , 3 , 4 , 5 , 6 , 7 ) 1 (2, 3, 4, 5, 6, 7) Default Values Named parameters to a function can be made optional by giving them a default value. These must come after named parameters without a default value. In case the argument is passed in, the default value is ignored. If the argument is not passed in, the default value is used. def function ( x , y , food = \"spam\" ): print ( food ) function ( 1 , 2 ) function ( 2 , 3 , \"eggs\" ) spam eggs Keyword Arguments kwargs (standing for keyword arguments) allows you to handle named arguments that you have not defined in advance. The keyword arguments return a **dictionary in which the keys are the argument names, and the values are the argument values. The arguments returned by * kwargs are not included in args def my_func ( x , y = 7 , * args , ** kwargs ): print ( kwargs ) my_func ( 2 , 3 , 4 , 5 , 6 , a = 7 , b = 8 ) #a and b are the names of the arguments that we passed to the function call. {'a': 7, 'b': 8} Keyword-only Arguments These are only specifiable via the name of the argument, and cannot be specified as a positional argument. For example, the following function takes a positional argument and two keyword-only arguments def keyword_only_function ( parameter , * , option1 = False , option2 = '' ): pass In this example, option1, and option2 are only specifiable via the keyword argument syntax. The following is valid keyword_only_function ( 3 , option1 = True , option2 = 'Hello World!' ) But this example will raise an error keyword_only_function ( 3 , True , 'Hello World!' ) Passing Arguments By Value and By Reference Manipulating provided arguments inside the function will leave immutable arguments intact, but will update mutable arguments. Lists are mutable, int is inmutable. Passing List as arguments is similar to passing by reference. Passing int is similar to passing by value. def Func ( a , b ): a = 1 b [ 0 ] = 1 x = 0 y = [ 0 ] Func ( x , y ) print ( x , y ) 0 [1]","title":"Arguments"},{"location":"Func/pyFnArgs/#default-values","text":"Named parameters to a function can be made optional by giving them a default value. These must come after named parameters without a default value. In case the argument is passed in, the default value is ignored. If the argument is not passed in, the default value is used. def function ( x , y , food = \"spam\" ): print ( food ) function ( 1 , 2 ) function ( 2 , 3 , \"eggs\" ) spam eggs","title":"Default Values"},{"location":"Func/pyFnArgs/#keyword-arguments","text":"kwargs (standing for keyword arguments) allows you to handle named arguments that you have not defined in advance. The keyword arguments return a **dictionary in which the keys are the argument names, and the values are the argument values. The arguments returned by * kwargs are not included in args def my_func ( x , y = 7 , * args , ** kwargs ): print ( kwargs ) my_func ( 2 , 3 , 4 , 5 , 6 , a = 7 , b = 8 ) #a and b are the names of the arguments that we passed to the function call. {'a': 7, 'b': 8}","title":"Keyword Arguments"},{"location":"Func/pyFnArgs/#keyword-only-arguments","text":"These are only specifiable via the name of the argument, and cannot be specified as a positional argument. For example, the following function takes a positional argument and two keyword-only arguments def keyword_only_function ( parameter , * , option1 = False , option2 = '' ): pass In this example, option1, and option2 are only specifiable via the keyword argument syntax. The following is valid keyword_only_function ( 3 , option1 = True , option2 = 'Hello World!' ) But this example will raise an error keyword_only_function ( 3 , True , 'Hello World!' )","title":"Keyword-only Arguments"},{"location":"Func/pyFnArgs/#passing-arguments-by-value-and-by-reference","text":"Manipulating provided arguments inside the function will leave immutable arguments intact, but will update mutable arguments. Lists are mutable, int is inmutable. Passing List as arguments is similar to passing by reference. Passing int is similar to passing by value. def Func ( a , b ): a = 1 b [ 0 ] = 1 x = 0 y = [ 0 ] Func ( x , y ) print ( x , y ) 0 [1]","title":"Passing Arguments By Value and By Reference"},{"location":"Func/pyFnTools/","text":"Functools module is for higher-order functions that work on other functions. It provides functions for working with other functions and callable objects to use or extend them without completely rewriting them. Reduce functools.reduce(function, iterable[, initializer]) Apply function of two arguments cumulatively to the items of iterable, from left to right, so as to reduce the iterable to a single value. For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates ((((1+2)+3)+4)+5). If the optional initializer is present, it is placed before the items of the iterable in the calculation, and serves as a default when the iterable is empty. If initializer is not given and iterable contains only one item, the first item is returned. Roughly equivalent to: def reduce ( function , iterable , initializer = None ): it = iter ( iterable ) if initializer is None : value = next ( it ) else : value = initializer for element in it : value = function ( value , element ) return value See itertools.accumulate() for an iterator that yields all intermediate values.","title":"Functools"},{"location":"Func/pyFnTools/#reduce","text":"functools.reduce(function, iterable[, initializer]) Apply function of two arguments cumulatively to the items of iterable, from left to right, so as to reduce the iterable to a single value. For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates ((((1+2)+3)+4)+5). If the optional initializer is present, it is placed before the items of the iterable in the calculation, and serves as a default when the iterable is empty. If initializer is not given and iterable contains only one item, the first item is returned. Roughly equivalent to: def reduce ( function , iterable , initializer = None ): it = iter ( iterable ) if initializer is None : value = next ( it ) else : value = initializer for element in it : value = function ( value , element ) return value See itertools.accumulate() for an iterator that yields all intermediate values.","title":"Reduce"},{"location":"Func/pyFuncObj/","text":"Functions can also be used as arguments of other functions. def add ( x , y ): return x + y def twice ( func , x , y ): return func ( func ( x , y ), func ( x , y )) a = 2 b = 3 print ( twice ( add , a , b )) 10 Functions that operate on other functions are called \"higher-order functions.\" there are higher-order functions built into Python that you might find useful to call. Here's an interesting example using the max function. By default, max returns the largest of its arguments. But if we pass in a function using the optional key argument, it returns the argument x that maximizes key(x) (aka the 'argmax'). def mod_5 ( x ): \"\"\"Return the remainder of x after dividing by 5\"\"\" return x % 5 print ( 'Which number is biggest?' , max ( 100 , 51 , 14 ), 'Which number is the biggest modulo 5?' , max ( 100 , 51 , 14 , key = mod_5 ), sep = ' \\n ' , ) Which number is biggest? 100 Which number is the biggest modulo 5? 14","title":"Function As Objects"},{"location":"Func/pyGen/","text":"The help() function is possibly the most important Python function you can learn. If you can remember how to use help(), you hold the key to understanding most other functions. help ( round ) Help on built-in function round in module builtins: round(number, ndigits=None) Round a number to a given precision in decimal digits. The return value is an integer if ndigits is omitted or None. Otherwise the return value has the same type as the number. ndigits may be negative. You can create your own functions by using the def statement. The code block within every function starts with a colon (:) and is indented. You must define functions before they are called, in the same way that you must assign variables before using them. def my_func (): print ( \"spam \" ) print ( \"spam \" ) my_func () def excla ( word ): print ( \"Spam with \" + word + \"!\" ) excla ( \"eggs\" ) def sumtwice ( x , y ): return ( x + y ) * 2 print ( sumtwice ( 3 , 4 )) spam spam Spam with eggs! 14","title":"General"},{"location":"Func/pyLambdas/","text":"Creating a function normally (using def) assigns it to a variable automatically. This is different from the creation of other objects - such as strings and integers - which can be created on the fly, without assigning them to a variable. The same is possible with functions, provided that they are created using lambda syntax. Functions created this way are known as anonymous . This approach is most commonly used when passing a simple function as an argument to another function. The syntax is shown in the next example and consists of the lambda keyword followed by a list of arguments, a colon, and the expression to evaluate and return. def my_func ( f , arg ): return f ( arg ) my_func ( lambda x : 2 * x * x , 5 ) 50 Lambda functions aren't as powerful as named functions. They can only do things that require a single expression - usually equivalent to a single line of code. Lambda functions can be assigned to variables, and used like normal functions. #It is usually better to define a function with def instead. ec = lambda x : x * x * 2 + 4 * x + 3 print ( ec ( 8 )) 163","title":"Lambdas"},{"location":"Func/pyMain/","text":"Most Python code is either a module to be imported, or a script that does something. However, sometimes it is useful to make a file that can be both imported as a module and run as a script. To do this, place script code inside if name == \"main\". This ensures that it won't be run if the file is imported. When the Python interpreter reads a source file, it executes all of the code it finds in the file. Before executing the code, it defines a few special variables. For example, if the Python interpreter is running that module (the source file) as the main program, it sets the special name variable to have a value \"main\". If this file is being imported from another module, name will be set to the module's name. def function (): print ( \"This is a module function!\" ) if __name__ == \"__main__\" : print ( \"This is a script\" ) This is a script If we save the code from our previous example as a file called example.py, we can then import it to another script as a module, using the name example. import example example . function () And the result will be This is a module function Before executing code, Python interpreter reads source file and define few special variables/global variables. If the python interpreter is running that module (the source file) as the main program, it sets the special __name__ variable to have a value \u201c__main__\u201d. If this file is being imported from another module, __name__ will be set to the module\u2019s name. Module\u2019s name is available as value to __name__ global variable. A module is a file containing Python definitions and statements. The file name is the module name with the suffix .py appended. # Python program to execute # function directly def my_function (): print ( \"I am inside function\" ) # We can test function by calling it. my_function () Now if we want to use that module by importing we have to comment out our call. Rather than that approach best approach is to use following code: # Python program to use # main for function call. if __name__ == \"__main__\" : my_function () import myscript myscript . my_function () Advantages : Every Python module has it\u2019s __name__ defined and if this is \u2018__main__\u2019, it implies that the module is being run standalone by the user and we can do corresponding appropriate actions. If you import this script as a module in another script, the __name__ is set to the name of the script/module. Python files can act as either reusable modules, or as standalone programs. if __name__ == \u201cmain\u201d: is used to execute some code only if the file was run directly, and not imported.","title":"Main"},{"location":"Func/pyNumFunc/","text":"To find the maximum or minimum of some numbers or a list, you can use max or min. To find the distance of a number from zero (its absolute value), use abs. To round a number to a certain number of decimal places, use round. To find the total of a list, use sum. Numeric Functions x =- 47.3 y = abs ( x ) print ( f 'x is { type ( x ) } ' ) print ( f 'x is { x } ' ) print ( f 'x is { type ( y ) } ' ) print ( f 'x is { y } ' ) x is <class 'float'> x is -47.3 x is <class 'float'> x is 47.3 x = 47 y = divmod ( x , 3 ) print ( f 'x is { type ( x ) } ' ) print ( f 'x is { x } ' ) print ( f 'x is { type ( y ) } ' ) print ( f 'x is { y } ' ) x is <class 'int'> x is 47 x is <class 'tuple'> x is (15, 2) x = 47 y = x + 73 j #y=complex(x, 73) print ( f 'x is { type ( x ) } ' ) print ( f 'x is { x } ' ) print ( f 'x is { type ( y ) } ' ) print ( f 'x is { y } ' ) x is <class 'int'> x is 47 x is <class 'complex'> x is (47+73j) Mathematical Functions Mathematical functions import math Mathematical functions for complex numbers import cmath print ( min ( 0 , 1 , 2 , 3 , - 1 , 4 , 5 , 6 )) print ( min ([ 0 , 1 , 2 , 3 , - 1 , 4 , 5 , 6 ])) print ( abs ( - 54 )) print ( round ( 0.6464 , 2 )) print ( sum ([ 0 , 1 , 4 , 5 , - 3 , 9 ])) -1 -1 54 0.65 16 Statistics For more advanced function use numpy # using Python statistics functions import statistics # simple statistics operations sample_data1 = [ 1 , 3 , 5 , 7 ] sample_data2 = [ 2 , 3 , 5 , 4 , 3 , 5 , 3 , 2 , 5 , 6 , 4 , 3 ] # Use the mean function - calculates an average value print ( statistics . mean ( sample_data1 )) # Use the different median functions print ( statistics . median ( sample_data1 )) print ( statistics . median_low ( sample_data1 )) print ( statistics . median_high ( sample_data1 )) # The mode function indicates which data item occurs # most frequently print ( statistics . mode ( sample_data2 )) 4 4.0 3 5 3","title":"Numeric Functions"},{"location":"Func/pyNumFunc/#numeric-functions","text":"x =- 47.3 y = abs ( x ) print ( f 'x is { type ( x ) } ' ) print ( f 'x is { x } ' ) print ( f 'x is { type ( y ) } ' ) print ( f 'x is { y } ' ) x is <class 'float'> x is -47.3 x is <class 'float'> x is 47.3 x = 47 y = divmod ( x , 3 ) print ( f 'x is { type ( x ) } ' ) print ( f 'x is { x } ' ) print ( f 'x is { type ( y ) } ' ) print ( f 'x is { y } ' ) x is <class 'int'> x is 47 x is <class 'tuple'> x is (15, 2) x = 47 y = x + 73 j #y=complex(x, 73) print ( f 'x is { type ( x ) } ' ) print ( f 'x is { x } ' ) print ( f 'x is { type ( y ) } ' ) print ( f 'x is { y } ' ) x is <class 'int'> x is 47 x is <class 'complex'> x is (47+73j)","title":"Numeric Functions"},{"location":"Func/pyNumFunc/#mathematical-functions","text":"Mathematical functions import math Mathematical functions for complex numbers import cmath print ( min ( 0 , 1 , 2 , 3 , - 1 , 4 , 5 , 6 )) print ( min ([ 0 , 1 , 2 , 3 , - 1 , 4 , 5 , 6 ])) print ( abs ( - 54 )) print ( round ( 0.6464 , 2 )) print ( sum ([ 0 , 1 , 4 , 5 , - 3 , 9 ])) -1 -1 54 0.65 16","title":"Mathematical Functions"},{"location":"Func/pyNumFunc/#statistics","text":"For more advanced function use numpy # using Python statistics functions import statistics # simple statistics operations sample_data1 = [ 1 , 3 , 5 , 7 ] sample_data2 = [ 2 , 3 , 5 , 4 , 3 , 5 , 3 , 2 , 5 , 6 , 4 , 3 ] # Use the mean function - calculates an average value print ( statistics . mean ( sample_data1 )) # Use the different median functions print ( statistics . median ( sample_data1 )) print ( statistics . median_low ( sample_data1 )) print ( statistics . median_high ( sample_data1 )) # The mode function indicates which data item occurs # most frequently print ( statistics . mode ( sample_data2 )) 4 4.0 3 5 3","title":"Statistics"},{"location":"Func/pyRegex/","text":"Regular expressions are a powerful tool for various kinds of string manipulation. They are a domain specific language (DSL) that is present as a library in most modern programming languages, not just Python. Regex Site They are useful for two main tasks: - verifying that strings match a pattern (for instance, that a string has the format of an email address), - performing substitutions in a string (such as changing all American spellings to British ones). Domain specific languages are highly specialized mini programming languages. Regular expressions are a popular example, and SQL (for database manipulation) is another. Private domain-specific languages are often used for specific industrial purposes. Regular expressions in Python can be accessed using the re module, which is part of the standard library. After you've defined a regular expression, the re.match function can be used to determine whether it matches at the beginning of a string. If it does, match returns an object representing the match, if not, it returns None. To avoid any confusion while working with regular expressions, we would use raw strings as r\"expression\". Raw strings don't escape anything, which makes use of regular expressions easier. import re pattern = r \"spam\" if re . match ( pattern , \"spamspamspam\" ): print ( \"Match\" ) else : print ( \"No match\" ) Match The function re.search finds a match of a pattern anywhere in the string. The function re.findall returns a list of all substrings that match a pattern. The function re.finditer does the same thing as re.findall, except it returns an iterator, rather than a list. import re pattern = r \"spam\" if re . match ( pattern , \"eggspamsausagespam\" ): print ( \"Match\" ) else : print ( \"No match\" ) if re . search ( pattern , \"eggspamsausagespam\" ): print ( \"Match\" ) else : print ( \"No match\" ) print ( re . findall ( pattern , \"eggspamsausagespam\" )) No match Match ['spam', 'spam'] The regex search returns an object with several methods that give details about it. These methods include group which returns the string matched, start and end which return the start and ending positions of the first match, and span which returns the start and end positions of the first match as a tuple. import re pattern = r \"pam\" match = re . search ( pattern , \"eggspamsausage\" ) if match : print ( match . group ()) print ( match . start ()) print ( match . end ()) print ( match . span ()) pam 4 7 (4, 7) One of the most important re methods that use regular expressions is sub. re.sub(pattern, repl, string, count=0) This method replaces all occurrences of the pattern in string with repl, substituting all occurrences, unless count provided. This method returns the modified string. import re hello = \"My name is Carlos, Hi Carlos\" pattern = r \"Carlos\" newstr = re . sub ( pattern , \"Diana\" , hello , count = 1 ) print ( newstr ) My name is Diana, Hi Carlos Metacharacters Metacharacters are what make regular expressions more powerful than normal string methods. They allow you to create regular expressions to represent concepts like \"one or more repetitions of a vowel\". The existence of metacharacters poses a problem if you want to create a regular expression (or regex) that matches a literal metacharacter, such as \"$\". You can do this by escaping the metacharacters by putting a backslash in front of them. However, this can cause problems, since backslashes also have an escaping function in normal Python strings. This can mean putting three or four backslashes in a row to do all the escaping. To avoid this, you can use a raw string, which is a normal string with an \"r\" in front of it. . (dot) : This matches any character, other than a new line. ^ and $ : These match the start and end of a string, respectively. import re pattern = r \"gr.y\" pattern2 = r \"....\" #Any four character string with no newlines patt3 = r \"^gr.y$\" if re . match ( pattern , \"grey\" ): print ( \"Match 1\" ) if re . match ( pattern , \"gray\" ): print ( \"Match 2\" ) if re . match ( pattern , \"blue\" ): print ( \"Match 3\" ) if re . match ( patt3 , \"gray\" ): print ( \"Match 4\" ) if re . match ( patt3 , \"Stingray\" ): print ( \"Match 5\" ) Match 1 Match 2 Match 4 Character Classes Character classes provide a way to match only one of a specific set of characters. A character class is created by putting the characters it matches inside square brackets. The pattern [aeiou] in the search function matches all strings that contain any one of the characters defined. import re patt = r \"[aeiou]\" if re . search ( patt , \"grey\" ): print ( \"Match 1\" ) if re . search ( patt , \"qwertyuiop\" ): print ( \"Match 2\" ) if re . search ( patt , \"rhythm myths\" ): print ( \"Match 3\" ) Match 1 Match 2 Character classes can also match ranges of characters. Some examples: The class [a-z] matches any lowercase alphabetic character. The class [G-P] matches any uppercase character from G to P. The class [0-9] matches any digit. Multiple ranges can be included in one class. For example, [A-Za-z] matches a letter of any case. import re #strings that contain two alphabetic uppercase letters followed by a digit. patt = r \"[A-Z][A-Z][0-9]\" if re . search ( patt , \"LS8\" ): print ( \"Match 1\" ) if re . search ( patt , \"E3\" ): print ( \"Match 2\" ) if re . search ( patt , \"1ab\" ): print ( \"Match 3\" ) Match 1 Place a ^ at the start of a character class to invert it. This causes it to match any character other than the ones included. Other metacharacters such as $ and ., have no meaning within character classes. The metacharacter ^ has no meaning unless it is the first character in a class. The pattern [^A-Z] excludes uppercase strings. Note, that the ^ should be inside the brackets to invert the character class. import re patt = r \"[^A-Z]\" if re . search ( patt , \"this is all quiet\" ): print ( \"Match 1\" ) if re . search ( patt , \"E31hsDD\" ): print ( \"Match 2\" ) if re . search ( patt , \"SHOUT\" ): print ( \"Match 3\" ) Match 1 Match 2 Metacharacters for Repetition Some more metacharacters are * + ? { and }. These specify numbers of repetitions. * The metacharacter * means \"zero or more repetitions of the previous thing\". It tries to match as many repetitions as possible. The \"previous thing\" can be a single character, a class, or a group of characters in parentheses. * matches 0 or more occurrences of the preceding expression. * The metacharacter + is very similar to *, except it means \"one or more repetitions\", as opposed to \"zero or more repetitions\". + matches 1 or more occurrence of the preceding expression. * The metacharacter ? means \"zero or one repetitions\". * Curly braces can be used to represent the number of repetitions between two numbers. The regex {x,y} means \"between x and y repetitions of something\". Hence {0,1} is the same thing as ?. If the first number is missing, it is taken to be zero. If the second number is missing, it is taken to be infinity. import re # strings that start with \"egg\" and follow with zero or more \"spam\"s patt = r \"egg(spam)*\" patt1 = r \"[a^]*\" #Zero or more repetitions of \"a\" or \"^\" patt2 = r \"g+\" patt3 = r \"(42)+$\" #One or more 42s patt4 = r \"ice(-)?cream\" patt5 = r \"colo(u)?r\" #Matches both color and colour patt6 = r \"9{1,3}$\" # matches string that have 1 to 3 nines. if re . match ( patt , \"egg\" ): print ( \"Match 1\" ) if re . match ( patt , \"eggspamspamegg\" ): print ( \"Match 2\" ) if re . match ( patt , \"spam\" ): print ( \"Match 3\" ) if re . match ( patt2 , \"g\" ): print ( \"Match 4\" ) if re . match ( patt2 , \"gggggg\" ): print ( \"Match 5\" ) if re . match ( patt2 , \"abcde\" ): print ( \"Match 6\" ) if re . match ( patt4 , \"ice-cream\" ): print ( \"Match 7\" ) if re . match ( patt4 , \"icecream\" ): print ( \"Match 8\" ) if re . match ( patt4 , \"ice--cream\" ): print ( \"Match 9\" ) if re . match ( patt6 , \"9\" ): print ( \"Match 10\" ) if re . match ( patt6 , \"999\" ): print ( \"Match 11\" ) if re . match ( patt6 , \"9999\" ): print ( \"Match 12\" ) Match 1 Match 2 Match 4 Match 5 Match 7 Match 8 Match 10 Match 11 Groups A group can be created by surrounding part of a regular expression with parentheses. This means that a group can be given as an argument to metacharacters such as * and ?. (spam) represents a group in the example pattern shown below. The content of groups in a match can be accessed using the group function. A call of group(0) or group() returns the whole match. A call of group(n), where n is greater than 0, returns the nth group from the left. The method groups() returns all groups up from 1. Groups can be nested import re # strings that start with \"egg\" and follow with zero or more \"spam\"s patt = r \"egg(spam)*\" patt1 = r \"([^aeiou][aeiou][^aeiou])+\" #one or more repetitions of a nonvowel, a vowel and nonvowel patt2 = r \"a(bc)(de)(f(g)h)i\" if re . match ( patt , \"egg\" ): print ( \"Match 1\" ) if re . match ( patt , \"eggspamspamegg\" ): print ( \"Match 2\" ) if re . match ( patt , \"spam\" ): print ( \"Match 3\" ) match = re . match ( patt2 , \"abcdefghijklmnop\" ) if match : print ( match . group ()) print ( match . group ( 0 )) print ( match . group ( 1 )) print ( match . group ( 2 )) print ( match . groups ()) Match 1 Match 2 abcdefghi abcdefghi bc de ('bc', 'de', 'fgh', 'g') There are several kinds of special groups. Two useful ones are named groups and non-capturing groups. * Named groups have the format (?P ...), where name is the name of the group, and ... is the content. They behave exactly the same as normal groups, except they can be accessed by group(name) in addition to its number. * Non-capturing groups have the format (?:...). They are not accessible by the group method, so they can be added to an existing regular expression without breaking the numbering. import re patt = r \"(?P<first>abc)(?:def)(ghi)\" match = re . match ( patt , \"abcdefghijklmnop\" ) if match : print ( match . group ( \"first\" )) print ( match . groups ()) abc ('abc', 'ghi') Another important metacharacter is |. This means \"or\", so red|blue matches either \"red\" or \"blue\". import re patt = r \"gr(a|e)y\" match = re . match ( patt , \"gray\" ) if match : print ( \"Match 1\" ) match = re . match ( patt , \"grey\" ) if match : print ( \"Match 2\" ) match = re . match ( patt , \"griy\" ) if match : print ( \"Match 3\" ) Match 1 Match 2 Special Sequences There are various special sequences you can use in regular expressions. They are written as a backslash followed by another character. One useful special sequence is a backslash and a number between 1 and 99, e.g., \\1 or \\17. This matches the expression of the group of that number. Note, that \"(.+) \\1\" is not the same as \"(.+) (.+)\", because \\1 refers to the first group's subexpression, which is the matched expression itself, and not the regex pattern. More useful special sequences are \\d, \\s, and \\w. These match digits, whitespace, and word characters respectively. In ASCII mode they are equivalent to [0-9], [ \\t\\n\\r\\f\\v], and [a-zA-Z0-9_]. In Unicode mode they match certain other characters, as well. For instance, \\w matches letters with accents. Versions of these special sequences with upper case letters - \\D, \\S, and \\W - mean the opposite to the lower-case versions. For instance, \\D matches anything that isn't a digit. Additional special sequences are \\A, \\Z, and \\b. The sequences \\A and \\Z match the beginning and end of a string, respectively. The sequence \\b matches the empty string between \\w and \\W characters, or \\w characters and the beginning or end of the string. Informally, it represents the boundary between words. The sequence \\B matches the empty string anywhere else. import re #[\\w\\.-]+ matches one or more word character, dot or dash. emailpattern = r \"([\\w\\.-]+)@([\\w\\.-]+)(\\.[\\w\\.]+)\" patt = r \"(.+) \\1\" match = re . match ( patt , \"word word\" ) if match : print ( \"Match 1\" ) match = re . match ( patt , \"?! ?!\" ) if match : print ( \"Match 2\" ) match = re . match ( patt , \"abc def\" ) if match : print ( \"Match 3\" ) patt = r \"(\\D+\\d)\" # matches one or more non-digits followed by a digit. match = re . match ( patt , \"Hi 999!\" ) if match : print ( \"Match 4\" ) match = re . match ( patt , \"1, 23, 456!!\" ) if match : print ( \"Match 5\" ) match = re . match ( patt , \" ! $?\" ) if match : print ( \"Match 6\" ) patt = r \"\\b(cat)\\b\" # matches the word \"cat\" surrounded by word boundaries. match = re . search ( patt , \"The cat sat!\" ) #needs search not match if match : print ( \"Match 7\" ) match = re . search ( patt , \"we s>cat<tered?\" ) if match : print ( \"Match 8\" ) match = re . search ( patt , \"We scattered.\" ) if match : print ( \"Match 9\" ) patt = r \"\\B(cat)\\B\" match = re . search ( patt , \"We scattered.\" ) if match : print ( \"Match 10\" ) #[\\w\\.-]+ matches one or more word character, dot or dash. the dot is preceded by \\ to treat it as a character emailpattern = r \"([\\w\\.-]+)@([\\w\\.-]+)(\\.[\\w\\.]+)\" match = re . search ( emailpattern , \"Please contact car.ar@laposte.net for any assitance\" ) #needs search not match if match : print ( match . group ()) Match 1 Match 2 Match 4 Match 7 Match 8 Match 10 car.ar@laposte.net Regexes can be more readable with the verbose flag #The usual compact way: email_rx = r \"^[^@ ]+@[^@ ]+\\.[^@ ]+$\" import re #The verbose way: email_rx = r \"\"\"(?x) #verbose flag ^ #beginning of string [^@ ]+ #stuff without @ or space (name) @ #an @ sign [^@ ]+ #more stuff (domain) \\. #a dot [^@ ]+ #final stuff(com, org,..) $ #end of string \"\"\" print ( re . match ( email_rx , \"carlos@pollo.com\" )) <re.Match object; span=(0, 16), match='carlos@pollo.com'>","title":"Regular Expressions"},{"location":"Func/pyRegex/#metacharacters","text":"Metacharacters are what make regular expressions more powerful than normal string methods. They allow you to create regular expressions to represent concepts like \"one or more repetitions of a vowel\". The existence of metacharacters poses a problem if you want to create a regular expression (or regex) that matches a literal metacharacter, such as \"$\". You can do this by escaping the metacharacters by putting a backslash in front of them. However, this can cause problems, since backslashes also have an escaping function in normal Python strings. This can mean putting three or four backslashes in a row to do all the escaping. To avoid this, you can use a raw string, which is a normal string with an \"r\" in front of it. . (dot) : This matches any character, other than a new line. ^ and $ : These match the start and end of a string, respectively. import re pattern = r \"gr.y\" pattern2 = r \"....\" #Any four character string with no newlines patt3 = r \"^gr.y$\" if re . match ( pattern , \"grey\" ): print ( \"Match 1\" ) if re . match ( pattern , \"gray\" ): print ( \"Match 2\" ) if re . match ( pattern , \"blue\" ): print ( \"Match 3\" ) if re . match ( patt3 , \"gray\" ): print ( \"Match 4\" ) if re . match ( patt3 , \"Stingray\" ): print ( \"Match 5\" ) Match 1 Match 2 Match 4","title":"Metacharacters"},{"location":"Func/pyRegex/#character-classes","text":"Character classes provide a way to match only one of a specific set of characters. A character class is created by putting the characters it matches inside square brackets. The pattern [aeiou] in the search function matches all strings that contain any one of the characters defined. import re patt = r \"[aeiou]\" if re . search ( patt , \"grey\" ): print ( \"Match 1\" ) if re . search ( patt , \"qwertyuiop\" ): print ( \"Match 2\" ) if re . search ( patt , \"rhythm myths\" ): print ( \"Match 3\" ) Match 1 Match 2 Character classes can also match ranges of characters. Some examples: The class [a-z] matches any lowercase alphabetic character. The class [G-P] matches any uppercase character from G to P. The class [0-9] matches any digit. Multiple ranges can be included in one class. For example, [A-Za-z] matches a letter of any case. import re #strings that contain two alphabetic uppercase letters followed by a digit. patt = r \"[A-Z][A-Z][0-9]\" if re . search ( patt , \"LS8\" ): print ( \"Match 1\" ) if re . search ( patt , \"E3\" ): print ( \"Match 2\" ) if re . search ( patt , \"1ab\" ): print ( \"Match 3\" ) Match 1 Place a ^ at the start of a character class to invert it. This causes it to match any character other than the ones included. Other metacharacters such as $ and ., have no meaning within character classes. The metacharacter ^ has no meaning unless it is the first character in a class. The pattern [^A-Z] excludes uppercase strings. Note, that the ^ should be inside the brackets to invert the character class. import re patt = r \"[^A-Z]\" if re . search ( patt , \"this is all quiet\" ): print ( \"Match 1\" ) if re . search ( patt , \"E31hsDD\" ): print ( \"Match 2\" ) if re . search ( patt , \"SHOUT\" ): print ( \"Match 3\" ) Match 1 Match 2","title":"Character Classes"},{"location":"Func/pyRegex/#metacharacters-for-repetition","text":"Some more metacharacters are * + ? { and }. These specify numbers of repetitions. * The metacharacter * means \"zero or more repetitions of the previous thing\". It tries to match as many repetitions as possible. The \"previous thing\" can be a single character, a class, or a group of characters in parentheses. * matches 0 or more occurrences of the preceding expression. * The metacharacter + is very similar to *, except it means \"one or more repetitions\", as opposed to \"zero or more repetitions\". + matches 1 or more occurrence of the preceding expression. * The metacharacter ? means \"zero or one repetitions\". * Curly braces can be used to represent the number of repetitions between two numbers. The regex {x,y} means \"between x and y repetitions of something\". Hence {0,1} is the same thing as ?. If the first number is missing, it is taken to be zero. If the second number is missing, it is taken to be infinity. import re # strings that start with \"egg\" and follow with zero or more \"spam\"s patt = r \"egg(spam)*\" patt1 = r \"[a^]*\" #Zero or more repetitions of \"a\" or \"^\" patt2 = r \"g+\" patt3 = r \"(42)+$\" #One or more 42s patt4 = r \"ice(-)?cream\" patt5 = r \"colo(u)?r\" #Matches both color and colour patt6 = r \"9{1,3}$\" # matches string that have 1 to 3 nines. if re . match ( patt , \"egg\" ): print ( \"Match 1\" ) if re . match ( patt , \"eggspamspamegg\" ): print ( \"Match 2\" ) if re . match ( patt , \"spam\" ): print ( \"Match 3\" ) if re . match ( patt2 , \"g\" ): print ( \"Match 4\" ) if re . match ( patt2 , \"gggggg\" ): print ( \"Match 5\" ) if re . match ( patt2 , \"abcde\" ): print ( \"Match 6\" ) if re . match ( patt4 , \"ice-cream\" ): print ( \"Match 7\" ) if re . match ( patt4 , \"icecream\" ): print ( \"Match 8\" ) if re . match ( patt4 , \"ice--cream\" ): print ( \"Match 9\" ) if re . match ( patt6 , \"9\" ): print ( \"Match 10\" ) if re . match ( patt6 , \"999\" ): print ( \"Match 11\" ) if re . match ( patt6 , \"9999\" ): print ( \"Match 12\" ) Match 1 Match 2 Match 4 Match 5 Match 7 Match 8 Match 10 Match 11","title":"Metacharacters for Repetition"},{"location":"Func/pyRegex/#groups","text":"A group can be created by surrounding part of a regular expression with parentheses. This means that a group can be given as an argument to metacharacters such as * and ?. (spam) represents a group in the example pattern shown below. The content of groups in a match can be accessed using the group function. A call of group(0) or group() returns the whole match. A call of group(n), where n is greater than 0, returns the nth group from the left. The method groups() returns all groups up from 1. Groups can be nested import re # strings that start with \"egg\" and follow with zero or more \"spam\"s patt = r \"egg(spam)*\" patt1 = r \"([^aeiou][aeiou][^aeiou])+\" #one or more repetitions of a nonvowel, a vowel and nonvowel patt2 = r \"a(bc)(de)(f(g)h)i\" if re . match ( patt , \"egg\" ): print ( \"Match 1\" ) if re . match ( patt , \"eggspamspamegg\" ): print ( \"Match 2\" ) if re . match ( patt , \"spam\" ): print ( \"Match 3\" ) match = re . match ( patt2 , \"abcdefghijklmnop\" ) if match : print ( match . group ()) print ( match . group ( 0 )) print ( match . group ( 1 )) print ( match . group ( 2 )) print ( match . groups ()) Match 1 Match 2 abcdefghi abcdefghi bc de ('bc', 'de', 'fgh', 'g') There are several kinds of special groups. Two useful ones are named groups and non-capturing groups. * Named groups have the format (?P ...), where name is the name of the group, and ... is the content. They behave exactly the same as normal groups, except they can be accessed by group(name) in addition to its number. * Non-capturing groups have the format (?:...). They are not accessible by the group method, so they can be added to an existing regular expression without breaking the numbering. import re patt = r \"(?P<first>abc)(?:def)(ghi)\" match = re . match ( patt , \"abcdefghijklmnop\" ) if match : print ( match . group ( \"first\" )) print ( match . groups ()) abc ('abc', 'ghi') Another important metacharacter is |. This means \"or\", so red|blue matches either \"red\" or \"blue\". import re patt = r \"gr(a|e)y\" match = re . match ( patt , \"gray\" ) if match : print ( \"Match 1\" ) match = re . match ( patt , \"grey\" ) if match : print ( \"Match 2\" ) match = re . match ( patt , \"griy\" ) if match : print ( \"Match 3\" ) Match 1 Match 2","title":"Groups"},{"location":"Func/pyRegex/#special-sequences","text":"There are various special sequences you can use in regular expressions. They are written as a backslash followed by another character. One useful special sequence is a backslash and a number between 1 and 99, e.g., \\1 or \\17. This matches the expression of the group of that number. Note, that \"(.+) \\1\" is not the same as \"(.+) (.+)\", because \\1 refers to the first group's subexpression, which is the matched expression itself, and not the regex pattern. More useful special sequences are \\d, \\s, and \\w. These match digits, whitespace, and word characters respectively. In ASCII mode they are equivalent to [0-9], [ \\t\\n\\r\\f\\v], and [a-zA-Z0-9_]. In Unicode mode they match certain other characters, as well. For instance, \\w matches letters with accents. Versions of these special sequences with upper case letters - \\D, \\S, and \\W - mean the opposite to the lower-case versions. For instance, \\D matches anything that isn't a digit. Additional special sequences are \\A, \\Z, and \\b. The sequences \\A and \\Z match the beginning and end of a string, respectively. The sequence \\b matches the empty string between \\w and \\W characters, or \\w characters and the beginning or end of the string. Informally, it represents the boundary between words. The sequence \\B matches the empty string anywhere else. import re #[\\w\\.-]+ matches one or more word character, dot or dash. emailpattern = r \"([\\w\\.-]+)@([\\w\\.-]+)(\\.[\\w\\.]+)\" patt = r \"(.+) \\1\" match = re . match ( patt , \"word word\" ) if match : print ( \"Match 1\" ) match = re . match ( patt , \"?! ?!\" ) if match : print ( \"Match 2\" ) match = re . match ( patt , \"abc def\" ) if match : print ( \"Match 3\" ) patt = r \"(\\D+\\d)\" # matches one or more non-digits followed by a digit. match = re . match ( patt , \"Hi 999!\" ) if match : print ( \"Match 4\" ) match = re . match ( patt , \"1, 23, 456!!\" ) if match : print ( \"Match 5\" ) match = re . match ( patt , \" ! $?\" ) if match : print ( \"Match 6\" ) patt = r \"\\b(cat)\\b\" # matches the word \"cat\" surrounded by word boundaries. match = re . search ( patt , \"The cat sat!\" ) #needs search not match if match : print ( \"Match 7\" ) match = re . search ( patt , \"we s>cat<tered?\" ) if match : print ( \"Match 8\" ) match = re . search ( patt , \"We scattered.\" ) if match : print ( \"Match 9\" ) patt = r \"\\B(cat)\\B\" match = re . search ( patt , \"We scattered.\" ) if match : print ( \"Match 10\" ) #[\\w\\.-]+ matches one or more word character, dot or dash. the dot is preceded by \\ to treat it as a character emailpattern = r \"([\\w\\.-]+)@([\\w\\.-]+)(\\.[\\w\\.]+)\" match = re . search ( emailpattern , \"Please contact car.ar@laposte.net for any assitance\" ) #needs search not match if match : print ( match . group ()) Match 1 Match 2 Match 4 Match 7 Match 8 Match 10 car.ar@laposte.net Regexes can be more readable with the verbose flag #The usual compact way: email_rx = r \"^[^@ ]+@[^@ ]+\\.[^@ ]+$\" import re #The verbose way: email_rx = r \"\"\"(?x) #verbose flag ^ #beginning of string [^@ ]+ #stuff without @ or space (name) @ #an @ sign [^@ ]+ #more stuff (domain) \\. #a dot [^@ ]+ #final stuff(com, org,..) $ #end of string \"\"\" print ( re . match ( email_rx , \"carlos@pollo.com\" )) <re.Match object; span=(0, 16), match='carlos@pollo.com'>","title":"Special Sequences"},{"location":"ML/pyEda/","text":"Basic Functions Example of exploratory data analysis using the Boston Housing Dataset Shape and Columns from sklearn.datasets import load_boston boston_dataset = load_boston () import pandas as pd boston = pd . DataFrame ( boston_dataset . data , columns = boston_dataset . feature_names ) boston [ 'MEDV' ] = boston_dataset . target print ( boston . shape ) #There are 506 records, and 14 columns including 13 features and the target. print ( boston . columns ) (506, 14) Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'], dtype='object') Head and Tail boston [[ 'CHAS' , 'RM' , 'AGE' , 'RAD' , 'MEDV' ]] . head () CHAS RM AGE RAD MEDV 0 0.0 6.575 65.2 1.0 24.0 1 0.0 6.421 78.9 2.0 21.6 2 0.0 7.185 61.1 2.0 34.7 3 0.0 6.998 45.8 3.0 33.4 4 0.0 7.147 54.2 3.0 36.2 Often datasets are loaded from other file formats (e.g., csv, text), it is a good practice to check the first and last few rows of the dataframe and make sure the data is in a consistent format using head and tail, respectively. Describe #To check the summary statistics of the dataset (round to the second decimal place for better display) boston . describe () . round ( 2 ) CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV count 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 mean 3.61 11.36 11.14 0.07 0.55 6.28 68.57 3.80 9.55 408.24 18.46 356.67 12.65 22.53 std 8.60 23.32 6.86 0.25 0.12 0.70 28.15 2.11 8.71 168.54 2.16 91.29 7.14 9.20 min 0.01 0.00 0.46 0.00 0.38 3.56 2.90 1.13 1.00 187.00 12.60 0.32 1.73 5.00 25% 0.08 0.00 5.19 0.00 0.45 5.89 45.02 2.10 4.00 279.00 17.40 375.38 6.95 17.02 50% 0.26 0.00 9.69 0.00 0.54 6.21 77.50 3.21 5.00 330.00 19.05 391.44 11.36 21.20 75% 3.68 12.50 18.10 0.00 0.62 6.62 94.07 5.19 24.00 666.00 20.20 396.22 16.96 25.00 max 88.98 100.00 27.74 1.00 0.87 8.78 100.00 12.13 24.00 711.00 22.00 396.90 37.97 50.00 Plot Hist import matplotlib.pyplot as plt boston . hist ( column = 'CHAS' ) plt . show () boston . hist ( column = 'RM' , bins = 20 ) plt . show () The distribution of RM appears normal and symmetric. The symmetry aligns with what we observed from the output of describe(), as the mean of RM 6.28 is close to its median 6.21. Scatter We specify the type of the plot by passing a string \u2018scatter\u2019 to the argument kind, identify the labels for x and y respectively, and set the size of the figure via a tuple (width, height) in inches. boston . plot ( kind = 'scatter' , x = 'RM' , y = 'MEDV' , figsize = ( 8 , 6 )); boston . plot ( kind = 'scatter' , x = 'LSTAT' , y = 'MEDV' , figsize = ( 8 , 6 )); Correlation Matrix To understand the relationship among features (columns), a correlation matrix is very useful in the exploratory data analysis. Correlation measures linear relationships between variables. corr_matrix = boston . corr () . round ( 2 ) print ( corr_matrix ) CRIM ZN INDUS CHAS NOX ... TAX PTRATIO B LSTAT MEDV CRIM 1.00 -0.20 0.41 -0.06 0.42 ... 0.58 0.29 -0.39 0.46 -0.39 ZN -0.20 1.00 -0.53 -0.04 -0.52 ... -0.31 -0.39 0.18 -0.41 0.36 INDUS 0.41 -0.53 1.00 0.06 0.76 ... 0.72 0.38 -0.36 0.60 -0.48 CHAS -0.06 -0.04 0.06 1.00 0.09 ... -0.04 -0.12 0.05 -0.05 0.18 NOX 0.42 -0.52 0.76 0.09 1.00 ... 0.67 0.19 -0.38 0.59 -0.43 RM -0.22 0.31 -0.39 0.09 -0.30 ... -0.29 -0.36 0.13 -0.61 0.70 AGE 0.35 -0.57 0.64 0.09 0.73 ... 0.51 0.26 -0.27 0.60 -0.38 DIS -0.38 0.66 -0.71 -0.10 -0.77 ... -0.53 -0.23 0.29 -0.50 0.25 RAD 0.63 -0.31 0.60 -0.01 0.61 ... 0.91 0.46 -0.44 0.49 -0.38 TAX 0.58 -0.31 0.72 -0.04 0.67 ... 1.00 0.46 -0.44 0.54 -0.47 PTRATIO 0.29 -0.39 0.38 -0.12 0.19 ... 0.46 1.00 -0.18 0.37 -0.51 B -0.39 0.18 -0.36 0.05 -0.38 ... -0.44 -0.18 1.00 -0.37 0.33 LSTAT 0.46 -0.41 0.60 -0.05 0.59 ... 0.54 0.37 -0.37 1.00 -0.74 MEDV -0.39 0.36 -0.48 0.18 -0.43 ... -0.47 -0.51 0.33 -0.74 1.00 [14 rows x 14 columns]","title":"EDA"},{"location":"ML/pyEda/#basic-functions","text":"Example of exploratory data analysis using the Boston Housing Dataset","title":"Basic Functions"},{"location":"ML/pyEda/#shape-and-columns","text":"from sklearn.datasets import load_boston boston_dataset = load_boston () import pandas as pd boston = pd . DataFrame ( boston_dataset . data , columns = boston_dataset . feature_names ) boston [ 'MEDV' ] = boston_dataset . target print ( boston . shape ) #There are 506 records, and 14 columns including 13 features and the target. print ( boston . columns ) (506, 14) Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'], dtype='object')","title":"Shape and Columns"},{"location":"ML/pyEda/#head-and-tail","text":"boston [[ 'CHAS' , 'RM' , 'AGE' , 'RAD' , 'MEDV' ]] . head () CHAS RM AGE RAD MEDV 0 0.0 6.575 65.2 1.0 24.0 1 0.0 6.421 78.9 2.0 21.6 2 0.0 7.185 61.1 2.0 34.7 3 0.0 6.998 45.8 3.0 33.4 4 0.0 7.147 54.2 3.0 36.2 Often datasets are loaded from other file formats (e.g., csv, text), it is a good practice to check the first and last few rows of the dataframe and make sure the data is in a consistent format using head and tail, respectively.","title":"Head and Tail"},{"location":"ML/pyEda/#describe","text":"#To check the summary statistics of the dataset (round to the second decimal place for better display) boston . describe () . round ( 2 ) CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV count 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 mean 3.61 11.36 11.14 0.07 0.55 6.28 68.57 3.80 9.55 408.24 18.46 356.67 12.65 22.53 std 8.60 23.32 6.86 0.25 0.12 0.70 28.15 2.11 8.71 168.54 2.16 91.29 7.14 9.20 min 0.01 0.00 0.46 0.00 0.38 3.56 2.90 1.13 1.00 187.00 12.60 0.32 1.73 5.00 25% 0.08 0.00 5.19 0.00 0.45 5.89 45.02 2.10 4.00 279.00 17.40 375.38 6.95 17.02 50% 0.26 0.00 9.69 0.00 0.54 6.21 77.50 3.21 5.00 330.00 19.05 391.44 11.36 21.20 75% 3.68 12.50 18.10 0.00 0.62 6.62 94.07 5.19 24.00 666.00 20.20 396.22 16.96 25.00 max 88.98 100.00 27.74 1.00 0.87 8.78 100.00 12.13 24.00 711.00 22.00 396.90 37.97 50.00","title":"Describe"},{"location":"ML/pyEda/#plot","text":"","title":"Plot"},{"location":"ML/pyEda/#hist","text":"import matplotlib.pyplot as plt boston . hist ( column = 'CHAS' ) plt . show () boston . hist ( column = 'RM' , bins = 20 ) plt . show () The distribution of RM appears normal and symmetric. The symmetry aligns with what we observed from the output of describe(), as the mean of RM 6.28 is close to its median 6.21.","title":"Hist"},{"location":"ML/pyEda/#scatter","text":"We specify the type of the plot by passing a string \u2018scatter\u2019 to the argument kind, identify the labels for x and y respectively, and set the size of the figure via a tuple (width, height) in inches. boston . plot ( kind = 'scatter' , x = 'RM' , y = 'MEDV' , figsize = ( 8 , 6 )); boston . plot ( kind = 'scatter' , x = 'LSTAT' , y = 'MEDV' , figsize = ( 8 , 6 ));","title":"Scatter"},{"location":"ML/pyEda/#correlation-matrix","text":"To understand the relationship among features (columns), a correlation matrix is very useful in the exploratory data analysis. Correlation measures linear relationships between variables. corr_matrix = boston . corr () . round ( 2 ) print ( corr_matrix ) CRIM ZN INDUS CHAS NOX ... TAX PTRATIO B LSTAT MEDV CRIM 1.00 -0.20 0.41 -0.06 0.42 ... 0.58 0.29 -0.39 0.46 -0.39 ZN -0.20 1.00 -0.53 -0.04 -0.52 ... -0.31 -0.39 0.18 -0.41 0.36 INDUS 0.41 -0.53 1.00 0.06 0.76 ... 0.72 0.38 -0.36 0.60 -0.48 CHAS -0.06 -0.04 0.06 1.00 0.09 ... -0.04 -0.12 0.05 -0.05 0.18 NOX 0.42 -0.52 0.76 0.09 1.00 ... 0.67 0.19 -0.38 0.59 -0.43 RM -0.22 0.31 -0.39 0.09 -0.30 ... -0.29 -0.36 0.13 -0.61 0.70 AGE 0.35 -0.57 0.64 0.09 0.73 ... 0.51 0.26 -0.27 0.60 -0.38 DIS -0.38 0.66 -0.71 -0.10 -0.77 ... -0.53 -0.23 0.29 -0.50 0.25 RAD 0.63 -0.31 0.60 -0.01 0.61 ... 0.91 0.46 -0.44 0.49 -0.38 TAX 0.58 -0.31 0.72 -0.04 0.67 ... 1.00 0.46 -0.44 0.54 -0.47 PTRATIO 0.29 -0.39 0.38 -0.12 0.19 ... 0.46 1.00 -0.18 0.37 -0.51 B -0.39 0.18 -0.36 0.05 -0.38 ... -0.44 -0.18 1.00 -0.37 0.33 LSTAT 0.46 -0.41 0.60 -0.05 0.59 ... 0.54 0.37 -0.37 1.00 -0.74 MEDV -0.39 0.36 -0.48 0.18 -0.43 ... -0.47 -0.51 0.33 -0.74 1.00 [14 rows x 14 columns]","title":"Correlation Matrix"},{"location":"ML/pyGen/","text":"Useful modules for ML and Data Science Pandas - read and manipulate data Numpy - manipulating lists and tables of numerical data Numba - makes Python code fast Matplotlib - for creating static, animated, and interactive visualizations in Python Scikit-learn - machine learning in Python EDA - exploratory data analysis Linear Regression","title":"General"},{"location":"ML/pyNumba/","text":"Numba is a just-in-time compiler for Python that works best on code that uses NumPy arrays and functions, and loops. The most common way to use Numba is through its collection of decorators that can be applied to your functions to instruct Numba to compile them. When a call is made to a Numba decorated function it is compiled to machine code \u201cjust-in-time\u201d for execution and all or part of your code can subsequently run at native machine code speed! GPU\u2019s have more cores than CPU and hence when it comes to parallel computing of data, GPUs perform exceptionally better than CPU even though GPU has lower clock speed and it lacks several core managements features as compared to the CPU. Thus, running a python script on GPU can prove out to be comparatively faster than CPU, however, it must be noted that for processing a data set with GPU, the data will first be transferred to the GPU\u2019s memory which may require additional time so if data set is small then GPU may perform better than GPU. from numba import jit , cuda import numpy as np # to measure exec time from timeit import default_timer as timer # normal function to run on cpu def func ( a ): for i in range ( 10000000 ): a [ i ] += 1 # function optimized to run on gpu @jit ( target = \"cuda\" ) def func2 ( a ): for i in range ( 10000000 ): a [ i ] += 1 if __name__ == \"__main__\" : n = 10000000 a = np . ones ( n , dtype = np . float64 ) b = np . ones ( n , dtype = np . float32 ) start = timer () func ( a ) print ( \"without GPU:\" , timer () - start ) start = timer () func2 ( a ) print ( \"with GPU:\" , timer () - start )","title":"Numba"},{"location":"ML/pyNumpy/","text":"Numpy (Numerical Python) is a python library that allows fast and easy mathematical operations to be performed on arrays. Numpy is a Python package for manipulating lists and tables of numerical data. We can use it to do a lot of statistical calculations. We call the list or table of data a numpy array. We often will take the data from our pandas DataFrame and put it in numpy arrays. Pandas DataFrames are great because we have the column names and other text data that makes it human readable. A DataFrame, while easy for a human to read, is not the ideal format for doing calculations. The numpy arrays are generally less human readable, but are in a format that enables the necessary computation. Numpy is a Python module for doing calculations on tables of data. Pandas was actually built using Numpy as it\u2019s foundation. import numpy as np data = [ 15 , 16 , 18 , 19 , 22 , 24 , 29 , 30 , 34 ] print ( \"Mean: \" , np . mean ( data )) print ( \"Median: \" , np . median ( data )) print ( \"50th percentile : \" , np . percentile ( data , 50 )) print ( \"75th percentile : \" , np . percentile ( data , 75 )) print ( \"Standard Deviation: \" , np . std ( data )) print ( \"Variance: \" , np . var ( data )) Mean: 23.0 Median: 22.0 50th percentile : 22.0 75th percentile : 29.0 Standard Deviation: 6.342099196813483 Variance: 40.22222222222222 Numpy Array In Python, lists are used to store data. NumPy provides an array structure for performing operations with data. NumPy arrays are faster and more compact than lists. NumPy arrays are homogeneous, meaning they can contain only a single data type, while lists can contain multiple different types of data. To check the data type, use numpy.ndarray.dtype NumPy arrays are often called ndarrays, which stands for \"N-dimensional array\", because they can have multiple dimensions. A NumPy array can be created using the np.array() function, providing it a list as the argument import numpy as np xo = np . array ([ 1 , 2 , 3 , 4 ]) print ( xo [ 0 ]) x = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]) print ( x [ 1 ][ 2 ]) 1 6 Pandas Series to Numpy Array We often start with our data in a Pandas DataFrame, but then want to convert it to a numpy array. The values attribute does this for us. Let's convert the Fare column to a numpy array. First we recall that we can use the single bracket notation to get a pandas Series of the Fare column as follows. print ( df [ 'Fare' ] . values ) #The values attribute of a Pandas Series give the data as a numpy array. If we have a pandas DataFrame (instead of a Series as in the last part), we can still use the values attribute, but it returns a 2-dimensional numpy array. This is a 2-dimensional numpy array. You can tell because there\u2019s two sets of brackets, and it expands both across the page and down. The values attribute of a Pandas DataFrame give the data as a 2d numpy array. df [[ 'Pclass' , 'Fare' , 'Age' ]] . values array([[ 3. , 7.25 , 22. ], [ 1. , 71.2833, 38. ], [ 3. , 7.925 , 26. ], ..., [ 3. , 23.45 , 7. ], [ 1. , 30. , 26. ], [ 3. , 7.75 , 32. ]]) Array Properties Can be accessed using a dot. ndim returns the number of dimensions of the array. size returns the total number of elements of the array. shape returns a tuple of integers that indicate the number of elements stored along each dimension of the array. Note that once an array is created in numpy, its size cannot be changed. Size tells us how big the array is, shape tells us the dimension. Numpy Shape Attribute We use the numpy shape attribute to determine the size of our numpy array. The size tells us how many rows and columns are in our data. This result means we have 887 rows and 3 columns. Use the shape attribute to find the number of rows and number columns for a Numpy array. You can also use the shape attribute on a pandas DataFrame (df.shape). x = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]) print ( x . ndim ) # 2 print ( x . size ) # 9 print ( x . shape ) # (3, 3) 2 9 (3, 3) arr = df [[ 'Pclass' , 'Fare' , 'Age' ]] . values print ( arr . shape ) #(887, 3) (887, 3) Select from a Numpy Array We can select a single element, a row or a column from a numpy array. print ( arr [ 0 , 1 ]) ##Select single element data print ( arr [ 0 ]) ##Select row print ( arr [:, 2 ]) #Select column Mask & Subsetting A mask is a boolean array (True/False values) that tells us which values from the array we\u2019re interested in. Masking is used to extract, modify, count, or otherwise manipulate values in an array based on some criterion. We can create a mask satisfying more than one criteria. We use & to separate the conditions and each condition is encapsulated with parentheses \"()\" mask = arr [:, 2 ] < 18 #all children passengers print ( arr [ mask ]) # or arr[arr[:, 2] < 18] Summing and Counting Let\u2019s say we want to know how many of our passengers are children. We still have the same array definition and can take our mask or boolean values from the previous part. Recall that True values are interpreted as 1 and False values are interpreted as 0. So we can just sum up the array and that\u2019s equivalent to counting the number of true values. print ( mask . sum ()) print (( arr [:, 2 ] < 18 ) . sum ()) 130 130 Matrix The NumPy library endows Python with a host of scientific computing capabilities. Chief among these is the Array object, which provides a multidimensional way to organize values of the same type. Numpy arrays allow slicing and indexing similar to lists. Most importantly, Numpy has a formidable number of mathematical operations that can be used to transform arrays and perform computations between arrays. For those familiar with MATLab, these operations should be reminiscent of many matrix operations. import numpy as np x = np . array ([ 2 , 4 , 6 ]) # create a rank 1 array A = np . array ([[ 1 , 3 , 5 ], [ 2 , 4 , 6 ]]) # create a rank 2 array B = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) print ( \"Matrix A: \\n \" ) print ( A ) print ( \" \\n Matrix B: \\n \" ) print ( B ) Matrix A: [[1 3 5] [2 4 6]] Matrix B: [[1 2 3] [4 5 6]] Indexing and Slicing Negative indexes count from the end of the array, so, [-3:] will result in the last 3 elements. Numpy slicing syntax follows that of a python list: arr[start:stop:step]. When any of these are unspecified, they default to the values start=0, stop=size of dimension, step=1. # Indexing/Slicing examples print ( A [ 0 , :]) # index the first \"row\" and all columns print ( A [ 1 , 2 ]) # index the second row, third column entry print ( A [:, 1 ]) # index entire second column [1 3 5] 6 [3 4] You can provide a condition as the index to select the elements that fulfill the given condition. Conditions can be combined using the & (and) and | (or) operators. x = np . arange ( 1 , 10 ) print ( x [ x < 4 ]) [1 2 3] The condition can also be assigned to a variable, which will be an array of boolean values showing whether or not the values in the array fulfill the condition: y = (x>5) & (x%2==0) print ( x [( x > 5 ) & ( x % 2 == 0 )]) y = ( x > 5 ) & ( x % 2 == 0 ) print ( x [ y ]) [6 8] [6 8] # Arithmetic Examples C = A * 2 # multiplies every elemnt of A by two D = A * B # elementwise multiplication rather than matrix multiplication E = np . transpose ( B ) F = np . matmul ( A , E ) # performs matrix multiplication -- could also use np.dot() G = np . matmul ( A , x ) # performs matrix-vector multiplication -- again could also use np.dot() print ( \" \\n Matrix E (the transpose of B): \\n \" ) print ( E ) print ( \" \\n Matrix F (result of matrix multiplication A x E): \\n \" ) print ( F ) print ( \" \\n Matrix G (result of matrix-vector multiplication A*x): \\n \" ) print ( G ) Matrix E (the transpose of B): [[1 4] [2 5] [3 6]] Matrix F (result of matrix multiplication A x E): [[22 49] [28 64]] Matrix G (result of matrix-vector multiplication A*x): [44 56] Assigning Values We can use slicing for multiple elements. For example, to replace the first row by 10. arr [ 0 ,:] = 10 We can also combine slicing to change any subset of the array. For example, to reassign 0 to the left upper corner. More on slicing with numpy. arr [: 2 ,: 2 ] = 0 Assigning an Array to an Array n addition, a 1darray or a 2darry can be assigned to a subset of another 2darray, as long as their shapes match. arr [:, 0 ] = [ 10 , 1 ] Combining Two Arrays Oftentime we obtain data stored in different arrays and we need to combine them into one to keep it in one place. We can stack them horizontally (by column) to get a 2darray using 'hstack'. if we want to combine the arrays vertically (by row), we can use 'vstack'. To combine more than two arrays horizontally, simply add the additional arrays into the tuple. arr3 = np . vstack (( arr1 , arr2 )) Concatenate More generally, we can use the function numpy.concatenate. If we want to concatenate, link together, two arrays along rows, then pass 'axis = 1' to achieve the same result as using numpy.hstack; and pass 'axis = 0' if you want to combine arrays vertically. You can use np.hstack to concatenate arrays ONLY if they have the same number of rows. np . concatenate (( arr1 , arr2 ), axis = 1 ) Broadcasting Operations between the array and a single number. NumPy understands that the given operation should be performed with each element. This is called broadcasting. # Broadcasting Examples x = np . array ([ 2 , 4 , 6 ]) # create a rank 1 array A = np . array ([[ 1 , 3 , 5 ], [ 2 , 4 , 6 ]]) # create a rank 2 array B = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) H = A * x # \"broadcasts\" x for element-wise multiplication with the rows of A print ( H ) print ( 'xxxxxx' ) J = B + x # broadcasts for addition, again across rows print ( J ) [[ 2 12 30] [ 4 16 36]] xxxxxx [[ 3 6 9] [ 6 9 12]] np.min() and np.max() min() and max() can be used to get the smallest and largest elements. # max operation examples X = np . array ([[ 3 , 9 , 4 ], [ 10 , 2 , 7 ], [ 5 , 11 , 8 ]]) all_max = np . max ( X ) # gets the maximum value of matrix X column_max = np . max ( X , axis = 0 ) # gets the maximum in each column -- returns a rank-1 array [10, 11, 8] row_max = np . max ( X , axis = 1 ) # gets the maximum in each row -- returns a rank-1 array [9, 10, 11] # In addition to max, can similarly do min. Numpy also has argmax to return indices of maximal values column_argmax = np . argmax ( X , axis = 0 ) # note that the \"index\" here is actually the row the maximum occurs for each column print ( \"Matrix X: \\n \" ) print ( X ) print ( \" \\n Maximum value in X: \\n \" ) print ( all_max ) print ( \" \\n Column-wise max of X: \\n \" ) print ( column_max ) print ( \" \\n Indices of column max: \\n \" ) print ( column_argmax ) print ( \" \\n Row-wise max of X: \\n \" ) print ( row_max ) Matrix X: [[ 3 9 4] [10 2 7] [ 5 11 8]] Maximum value in X: 11 Column-wise max of X: [10 11 8] Indices of column max: [1 2 2] Row-wise max of X: [ 9 10 11] np.sum() & np.mean() These work similarly to the max operations -- use the axis argument to denote if summing over rows or columns # Sum operation examples total_sum = np . sum ( X ) column_sum = np . sum ( X , axis = 0 ) row_sum = np . sum ( X , axis = 1 ) print ( \"Matrix X: \\n \" ) print ( X ) print ( \" \\n Sum over all elements of X: \\n \" ) print ( total_sum ) print ( \" \\n Column-wise sum of X: \\n \" ) print ( column_sum ) print ( \" \\n Row-wise sum of X: \\n \" ) print ( row_sum ) Matrix X: [[ 3 9 4] [10 2 7] [ 5 11 8]] Sum over all elements of X: 59 Column-wise sum of X: [18 22 19] Row-wise sum of X: [16 19 24] np.arange() & np.reshape() np.arange() allows you to create an array that contains a range of evenly spaced intervals (similar to a Python range). When you use the reshape method, the array you want to produce needs to have the same number of elements as the original array. Reshape can also do the opposite: take a 2-dimensional array and make a 1-dimensional array from it. The same result can be achieved using the flatten() function. Numpy can calculate the shape (dimension) for us if we indicate the unknown dimension as -1. For example, given a 2darray arr of shape (3,4), arr.reshape(-1) would output a 1darray of shape (12,), while arr.reshape((-1,2)) would generate a 2darray of shape (6,2). # Matrix reshaping X = np . arange ( 16 ) # makes a rank-1 array of integers from 0 to 15 X_square = np . reshape ( X , ( 4 , 4 )) # reshape X into a 4 x 4 matrix X_rank_3 = np . reshape ( X , ( 2 , 2 , 4 )) # reshape X to be 2 x 2 x 4 --a rank-3 array # consider as two rank-2 arrays with 2 rows and 4 columns print ( \"Rank-1 array X: \\n \" ) print ( X ) print ( \" \\n Reshaped into a square matrix: \\n \" ) print ( X_square ) print ( \" \\n Reshaped into a rank-3 array with dimensions 2 x 2 x 4: \\n \" ) print ( X_rank_3 ) print ( \" \\n Reshaped into Rank 1\" ) print ( X_square . reshape ( 16 )) print ( \"Using Flatten\" ) print ( X_rank_3 . flatten ()) Rank-1 array X: [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] Reshaped into a square matrix: [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11] [12 13 14 15]] Reshaped into a rank-3 array with dimensions 2 x 2 x 4: [[[ 0 1 2 3] [ 4 5 6 7]] [[ 8 9 10 11] [12 13 14 15]]] Reshaped into Rank 1 [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] Using Flatten [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] Other Functions We can add, remove and sort an array using the np.append(), np.delete() and np.sort() functions. x = np . array ([ 2 , 1 , 3 ]) #add an element x = np . append ( x , 4 ) #delete an element x = np . delete ( x , 0 ) #sort array x = np . sort ( x ) x = np . arange ( 2 , 8 , 2 ) print ( x ) x = np . append ( x , x . size ) x = np . sort ( x ) print ( x [ 1 ]) [2 4 6] 3 Comparisons We can use operations including \"<\", \">\", \">=\", \"<=\", and \"==\" . To find out how many rows satisfy the condition, use .sum() on the resultant 1d boolean array, e.g., (arr[:, 1] == 10).sum(). True is treated as 1 and False as 0 in the sum.","title":"Numpy"},{"location":"ML/pyNumpy/#numpy-array","text":"In Python, lists are used to store data. NumPy provides an array structure for performing operations with data. NumPy arrays are faster and more compact than lists. NumPy arrays are homogeneous, meaning they can contain only a single data type, while lists can contain multiple different types of data. To check the data type, use numpy.ndarray.dtype NumPy arrays are often called ndarrays, which stands for \"N-dimensional array\", because they can have multiple dimensions. A NumPy array can be created using the np.array() function, providing it a list as the argument import numpy as np xo = np . array ([ 1 , 2 , 3 , 4 ]) print ( xo [ 0 ]) x = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]) print ( x [ 1 ][ 2 ]) 1 6","title":"Numpy Array"},{"location":"ML/pyNumpy/#pandas-series-to-numpy-array","text":"We often start with our data in a Pandas DataFrame, but then want to convert it to a numpy array. The values attribute does this for us. Let's convert the Fare column to a numpy array. First we recall that we can use the single bracket notation to get a pandas Series of the Fare column as follows. print ( df [ 'Fare' ] . values ) #The values attribute of a Pandas Series give the data as a numpy array. If we have a pandas DataFrame (instead of a Series as in the last part), we can still use the values attribute, but it returns a 2-dimensional numpy array. This is a 2-dimensional numpy array. You can tell because there\u2019s two sets of brackets, and it expands both across the page and down. The values attribute of a Pandas DataFrame give the data as a 2d numpy array. df [[ 'Pclass' , 'Fare' , 'Age' ]] . values array([[ 3. , 7.25 , 22. ], [ 1. , 71.2833, 38. ], [ 3. , 7.925 , 26. ], ..., [ 3. , 23.45 , 7. ], [ 1. , 30. , 26. ], [ 3. , 7.75 , 32. ]])","title":"Pandas Series to Numpy Array"},{"location":"ML/pyNumpy/#array-properties","text":"Can be accessed using a dot. ndim returns the number of dimensions of the array. size returns the total number of elements of the array. shape returns a tuple of integers that indicate the number of elements stored along each dimension of the array. Note that once an array is created in numpy, its size cannot be changed. Size tells us how big the array is, shape tells us the dimension. Numpy Shape Attribute We use the numpy shape attribute to determine the size of our numpy array. The size tells us how many rows and columns are in our data. This result means we have 887 rows and 3 columns. Use the shape attribute to find the number of rows and number columns for a Numpy array. You can also use the shape attribute on a pandas DataFrame (df.shape). x = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]) print ( x . ndim ) # 2 print ( x . size ) # 9 print ( x . shape ) # (3, 3) 2 9 (3, 3) arr = df [[ 'Pclass' , 'Fare' , 'Age' ]] . values print ( arr . shape ) #(887, 3) (887, 3)","title":"Array Properties"},{"location":"ML/pyNumpy/#select-from-a-numpy-array","text":"We can select a single element, a row or a column from a numpy array. print ( arr [ 0 , 1 ]) ##Select single element data print ( arr [ 0 ]) ##Select row print ( arr [:, 2 ]) #Select column","title":"Select from a Numpy Array"},{"location":"ML/pyNumpy/#mask-subsetting","text":"A mask is a boolean array (True/False values) that tells us which values from the array we\u2019re interested in. Masking is used to extract, modify, count, or otherwise manipulate values in an array based on some criterion. We can create a mask satisfying more than one criteria. We use & to separate the conditions and each condition is encapsulated with parentheses \"()\" mask = arr [:, 2 ] < 18 #all children passengers print ( arr [ mask ]) # or arr[arr[:, 2] < 18]","title":"Mask &amp; Subsetting"},{"location":"ML/pyNumpy/#summing-and-counting","text":"Let\u2019s say we want to know how many of our passengers are children. We still have the same array definition and can take our mask or boolean values from the previous part. Recall that True values are interpreted as 1 and False values are interpreted as 0. So we can just sum up the array and that\u2019s equivalent to counting the number of true values. print ( mask . sum ()) print (( arr [:, 2 ] < 18 ) . sum ()) 130 130","title":"Summing and Counting"},{"location":"ML/pyNumpy/#matrix","text":"The NumPy library endows Python with a host of scientific computing capabilities. Chief among these is the Array object, which provides a multidimensional way to organize values of the same type. Numpy arrays allow slicing and indexing similar to lists. Most importantly, Numpy has a formidable number of mathematical operations that can be used to transform arrays and perform computations between arrays. For those familiar with MATLab, these operations should be reminiscent of many matrix operations. import numpy as np x = np . array ([ 2 , 4 , 6 ]) # create a rank 1 array A = np . array ([[ 1 , 3 , 5 ], [ 2 , 4 , 6 ]]) # create a rank 2 array B = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) print ( \"Matrix A: \\n \" ) print ( A ) print ( \" \\n Matrix B: \\n \" ) print ( B ) Matrix A: [[1 3 5] [2 4 6]] Matrix B: [[1 2 3] [4 5 6]]","title":"Matrix"},{"location":"ML/pyNumpy/#indexing-and-slicing","text":"Negative indexes count from the end of the array, so, [-3:] will result in the last 3 elements. Numpy slicing syntax follows that of a python list: arr[start:stop:step]. When any of these are unspecified, they default to the values start=0, stop=size of dimension, step=1. # Indexing/Slicing examples print ( A [ 0 , :]) # index the first \"row\" and all columns print ( A [ 1 , 2 ]) # index the second row, third column entry print ( A [:, 1 ]) # index entire second column [1 3 5] 6 [3 4] You can provide a condition as the index to select the elements that fulfill the given condition. Conditions can be combined using the & (and) and | (or) operators. x = np . arange ( 1 , 10 ) print ( x [ x < 4 ]) [1 2 3] The condition can also be assigned to a variable, which will be an array of boolean values showing whether or not the values in the array fulfill the condition: y = (x>5) & (x%2==0) print ( x [( x > 5 ) & ( x % 2 == 0 )]) y = ( x > 5 ) & ( x % 2 == 0 ) print ( x [ y ]) [6 8] [6 8] # Arithmetic Examples C = A * 2 # multiplies every elemnt of A by two D = A * B # elementwise multiplication rather than matrix multiplication E = np . transpose ( B ) F = np . matmul ( A , E ) # performs matrix multiplication -- could also use np.dot() G = np . matmul ( A , x ) # performs matrix-vector multiplication -- again could also use np.dot() print ( \" \\n Matrix E (the transpose of B): \\n \" ) print ( E ) print ( \" \\n Matrix F (result of matrix multiplication A x E): \\n \" ) print ( F ) print ( \" \\n Matrix G (result of matrix-vector multiplication A*x): \\n \" ) print ( G ) Matrix E (the transpose of B): [[1 4] [2 5] [3 6]] Matrix F (result of matrix multiplication A x E): [[22 49] [28 64]] Matrix G (result of matrix-vector multiplication A*x): [44 56]","title":"Indexing and Slicing"},{"location":"ML/pyNumpy/#assigning-values","text":"We can use slicing for multiple elements. For example, to replace the first row by 10. arr [ 0 ,:] = 10 We can also combine slicing to change any subset of the array. For example, to reassign 0 to the left upper corner. More on slicing with numpy. arr [: 2 ,: 2 ] = 0","title":"Assigning Values"},{"location":"ML/pyNumpy/#assigning-an-array-to-an-array","text":"n addition, a 1darray or a 2darry can be assigned to a subset of another 2darray, as long as their shapes match. arr [:, 0 ] = [ 10 , 1 ]","title":"Assigning an Array to an Array"},{"location":"ML/pyNumpy/#combining-two-arrays","text":"Oftentime we obtain data stored in different arrays and we need to combine them into one to keep it in one place. We can stack them horizontally (by column) to get a 2darray using 'hstack'. if we want to combine the arrays vertically (by row), we can use 'vstack'. To combine more than two arrays horizontally, simply add the additional arrays into the tuple. arr3 = np . vstack (( arr1 , arr2 ))","title":"Combining Two Arrays"},{"location":"ML/pyNumpy/#concatenate","text":"More generally, we can use the function numpy.concatenate. If we want to concatenate, link together, two arrays along rows, then pass 'axis = 1' to achieve the same result as using numpy.hstack; and pass 'axis = 0' if you want to combine arrays vertically. You can use np.hstack to concatenate arrays ONLY if they have the same number of rows. np . concatenate (( arr1 , arr2 ), axis = 1 )","title":"Concatenate"},{"location":"ML/pyNumpy/#broadcasting","text":"Operations between the array and a single number. NumPy understands that the given operation should be performed with each element. This is called broadcasting. # Broadcasting Examples x = np . array ([ 2 , 4 , 6 ]) # create a rank 1 array A = np . array ([[ 1 , 3 , 5 ], [ 2 , 4 , 6 ]]) # create a rank 2 array B = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) H = A * x # \"broadcasts\" x for element-wise multiplication with the rows of A print ( H ) print ( 'xxxxxx' ) J = B + x # broadcasts for addition, again across rows print ( J ) [[ 2 12 30] [ 4 16 36]] xxxxxx [[ 3 6 9] [ 6 9 12]]","title":"Broadcasting"},{"location":"ML/pyNumpy/#npmin-and-npmax","text":"min() and max() can be used to get the smallest and largest elements. # max operation examples X = np . array ([[ 3 , 9 , 4 ], [ 10 , 2 , 7 ], [ 5 , 11 , 8 ]]) all_max = np . max ( X ) # gets the maximum value of matrix X column_max = np . max ( X , axis = 0 ) # gets the maximum in each column -- returns a rank-1 array [10, 11, 8] row_max = np . max ( X , axis = 1 ) # gets the maximum in each row -- returns a rank-1 array [9, 10, 11] # In addition to max, can similarly do min. Numpy also has argmax to return indices of maximal values column_argmax = np . argmax ( X , axis = 0 ) # note that the \"index\" here is actually the row the maximum occurs for each column print ( \"Matrix X: \\n \" ) print ( X ) print ( \" \\n Maximum value in X: \\n \" ) print ( all_max ) print ( \" \\n Column-wise max of X: \\n \" ) print ( column_max ) print ( \" \\n Indices of column max: \\n \" ) print ( column_argmax ) print ( \" \\n Row-wise max of X: \\n \" ) print ( row_max ) Matrix X: [[ 3 9 4] [10 2 7] [ 5 11 8]] Maximum value in X: 11 Column-wise max of X: [10 11 8] Indices of column max: [1 2 2] Row-wise max of X: [ 9 10 11]","title":"np.min() and np.max()"},{"location":"ML/pyNumpy/#npsum-npmean","text":"These work similarly to the max operations -- use the axis argument to denote if summing over rows or columns # Sum operation examples total_sum = np . sum ( X ) column_sum = np . sum ( X , axis = 0 ) row_sum = np . sum ( X , axis = 1 ) print ( \"Matrix X: \\n \" ) print ( X ) print ( \" \\n Sum over all elements of X: \\n \" ) print ( total_sum ) print ( \" \\n Column-wise sum of X: \\n \" ) print ( column_sum ) print ( \" \\n Row-wise sum of X: \\n \" ) print ( row_sum ) Matrix X: [[ 3 9 4] [10 2 7] [ 5 11 8]] Sum over all elements of X: 59 Column-wise sum of X: [18 22 19] Row-wise sum of X: [16 19 24]","title":"np.sum() &amp; np.mean()"},{"location":"ML/pyNumpy/#nparange-npreshape","text":"np.arange() allows you to create an array that contains a range of evenly spaced intervals (similar to a Python range). When you use the reshape method, the array you want to produce needs to have the same number of elements as the original array. Reshape can also do the opposite: take a 2-dimensional array and make a 1-dimensional array from it. The same result can be achieved using the flatten() function. Numpy can calculate the shape (dimension) for us if we indicate the unknown dimension as -1. For example, given a 2darray arr of shape (3,4), arr.reshape(-1) would output a 1darray of shape (12,), while arr.reshape((-1,2)) would generate a 2darray of shape (6,2). # Matrix reshaping X = np . arange ( 16 ) # makes a rank-1 array of integers from 0 to 15 X_square = np . reshape ( X , ( 4 , 4 )) # reshape X into a 4 x 4 matrix X_rank_3 = np . reshape ( X , ( 2 , 2 , 4 )) # reshape X to be 2 x 2 x 4 --a rank-3 array # consider as two rank-2 arrays with 2 rows and 4 columns print ( \"Rank-1 array X: \\n \" ) print ( X ) print ( \" \\n Reshaped into a square matrix: \\n \" ) print ( X_square ) print ( \" \\n Reshaped into a rank-3 array with dimensions 2 x 2 x 4: \\n \" ) print ( X_rank_3 ) print ( \" \\n Reshaped into Rank 1\" ) print ( X_square . reshape ( 16 )) print ( \"Using Flatten\" ) print ( X_rank_3 . flatten ()) Rank-1 array X: [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] Reshaped into a square matrix: [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11] [12 13 14 15]] Reshaped into a rank-3 array with dimensions 2 x 2 x 4: [[[ 0 1 2 3] [ 4 5 6 7]] [[ 8 9 10 11] [12 13 14 15]]] Reshaped into Rank 1 [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] Using Flatten [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]","title":"np.arange() &amp; np.reshape()"},{"location":"ML/pyNumpy/#other-functions","text":"We can add, remove and sort an array using the np.append(), np.delete() and np.sort() functions. x = np . array ([ 2 , 1 , 3 ]) #add an element x = np . append ( x , 4 ) #delete an element x = np . delete ( x , 0 ) #sort array x = np . sort ( x ) x = np . arange ( 2 , 8 , 2 ) print ( x ) x = np . append ( x , x . size ) x = np . sort ( x ) print ( x [ 1 ]) [2 4 6] 3","title":"Other Functions"},{"location":"ML/pyNumpy/#comparisons","text":"We can use operations including \"<\", \">\", \">=\", \"<=\", and \"==\" . To find out how many rows satisfy the condition, use .sum() on the resultant 1d boolean array, e.g., (arr[:, 1] == 10).sum(). True is treated as 1 and False as 0 in the sum.","title":"Comparisons"},{"location":"ML/pyPandas/","text":"Pandas is a Python module that helps us read and manipulate data. What's cool about pandas is that you can take in data and view it as a table that's human readable, but it can also be interpreted numerically so that you can do lots of computations with it. Pandas is derived from the term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for the same individuals. We call the table of data a DataFrame. A Series is essentially a column, and a DataFrame is a multi-dimensional table made up of a collection of Series. As numpy ndarrays are homogeneous, pandas relaxes this requirement and allows for various dtypes in its data structures. Asking for Help help(pd.Series.loc) Series The Series is one building block in pandas. Pandas Series is a one-dimensional labeled array that can hold data of any type (integer, string, float, python objects, etc.), similar to a column in an excel spreadsheet. The axis labels are collectively called index. If we are given a bag of letters a, b, and c, and count how many of each we have, we find that there are 1 a, 2 b\u2019s, and 3 c\u2019s. We could create a Series by supplying a list of counts and their corresponding labels. If we don\u2019t specify the index, by default, the index would be the integer positions starting from 0. Accessing the value by its index, rather than the integer position comes in handy when the dataset is of thousands, if not millions, of rows. Series is the building block for the DataFrame we will introduce next. Think of Series as numpy 1d array with index or row names. import pandas as pd import numpy as np s1 = pd . Series ([ 1 , 2 , 3 ], index = [ 'a' , 'b' , 'c' ]) #Alternatively, the values can be a numpy array: s2 = pd . Series ( np . array ([ 1 , 2 , 3 ]), index = [ 'a' , 'b' , 'c' ]) #Or, we could use a dictionary to specify the index with keys s3 = pd . Series ({ 'a' : 1 , 'b' : 2 , 'c' : 3 }) #In a Series, we can access the value by its index directly s3 [ 'a' ] 1 DataFrames In data science, data is usually more than one-dimensional, and of different data types; thus Series is not sufficient. DataFrames are 2darrays with both row and column labels. The easiest way to create a DataFrame is using a dictionary. Each key is a column, while the value is an array representing the data for that column.And then, we can pass this dictionary to the DataFrame constructor. The DataFrame automatically creates a numeric index for each row. We can specify a custom index, when creating the DataFrame. We can access a row using its index and the loc[] function. loc uses square brackets to specify the index. import pandas as pd data = { 'ages' : [ 14 , 18 , 24 , 42 ], 'heights' : [ 165 , 180 , 176 , 184 ] } df = pd . DataFrame ( data ) df = pd . DataFrame ( data , index = [ 'James' , 'Bob' , 'Ana' , 'Susan' ]) print ( df . loc [ \"Bob\" ]) ages 18 heights 180 Name: Bob, dtype: int64 Similar to numpy, to get the dimensions of a DataFrame, use .shape Size also works on DataFrame to return an integer representing the number of elements in this object. Importing and Exporting Data Generally data is stored in CSV (comma-separated values) files, which we can easily read in with panda\u2019s read_csv function. Pandas also supports reading from JSON files, as well as SQL databases. The head method returns the first 5 rows. You can instruct it to return the number of rows you would like as an argument (for example, df.head(10) will return the first 10 rows). Similarly, you can get the last rows using the tail() function. The info() function is used to get essential information about your dataset, such as number of rows, columns, data types, etc. Pandas automatically generates an index for the DataFrame, if none is specified. We can set our own index column by using the set_index() function. df.setIndex(\"Sex\", inplace=True) The inplace=True argument specifies that the change will be applied to our DataFrame, without the need to assign it to a new DataFrame variable. The describe method returns a table of statistics about the columns. We add a line in the code below to force python to display all 6 columns. Without the line, it will abbreviate the results. We can also get the summary stats for a single column. Count: This is the number of rows that have a value. In our case, every passenger has a value for each of the columns, so the value is 887 (the total number of passengers). Mean: Recall that the mean is the standard average. Std: This is short for standard deviation. This is a measure of how dispersed the data is. Min: The smallest value 25%: The 25th percentile 50%: The 50th percentile, also known as the median. 75%: The 75th percentile Max: The largest value .describe() ignores the null values, such as NaN (Not a Number) and generates the descriptive statistics that summarize the central tendency (i.e., mean), dispersion (i.e., standard deviation), and shape (i.e., min, max, and quantiles) of a dataset\u2019s distribution. df.shape df.index : Describe index df.columns df.count() : Number of non-NA values CSV import pandas as pd #read csv df = pd . read_csv ( 'titanic.csv' ) #write csv df . to_csv ( 'titanic.csv' ) print ( df . head ()) pd . options . display . max_columns = 6 Unnamed: 0 Survived Pclass ... Siblings/Spouses Parents/Children \\ 0 0 0 3 ... 1 0 1 1 1 1 ... 1 0 2 2 1 3 ... 0 0 3 3 1 1 ... 1 0 4 4 0 3 ... 0 0 Fare 0 7.2500 1 71.2833 2 7.9250 3 53.1000 4 8.0500 [5 rows x 8 columns] df . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 887 entries, 0 to 886 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Survived 887 non-null int64 1 Pclass 887 non-null int64 2 Sex 887 non-null object 3 Age 887 non-null float64 4 Siblings/Spouses 887 non-null int64 5 Parents/Children 887 non-null int64 6 Fare 887 non-null float64 dtypes: float64(2), int64(4), object(1) memory usage: 48.6+ KB print ( df . describe ()) *****Describe**** Survived Pclass Age Siblings/Spouses Parents/Children \\ count 887.000000 887.000000 887.000000 887.000000 887.000000 mean 0.385569 2.305524 29.471443 0.525366 0.383315 std 0.487004 0.836662 14.121908 1.104669 0.807466 min 0.000000 1.000000 0.420000 0.000000 0.000000 25% 0.000000 2.000000 20.250000 0.000000 0.000000 50% 0.000000 3.000000 28.000000 0.000000 0.000000 75% 1.000000 3.000000 38.000000 1.000000 0.000000 max 1.000000 3.000000 80.000000 8.000000 6.000000 Fare count 887.00000 mean 32.30542 std 49.78204 min 0.00000 25% 7.92500 50% 14.45420 75% 31.13750 max 512.32920 print ( df [ 'Survived' ] . describe ()) count 887.000000 mean 0.385569 std 0.487004 min 0.000000 25% 0.000000 50% 0.000000 75% 1.000000 max 1.000000 Name: Survived, dtype: float64 Excel #Read xlsx = pd . ExcelFile ( 'file.xls' ) df = pd . read_excel ( xlsx , 'Sheet1' ) #Write df . to_excel ( 'dir/myDataFrame.xlsx' , sheet_name = 'Sheet1' ) SQL (read_sql()is a convenience wrapper around read_sql_table() and read_sql_query()) from sqlalchemy import create_engine engine = create_engine ( 'sqlite:///:memory:' ) pd . read_sql ( SELECT * FROM my_table ;, engine ) pd . read_sql_table ( 'my_table' , engine ) pd . read_sql_query ( SELECT * FROM my_table ; ', engine) df . to_sql ( 'myDf' , engine ) Selecting Columns We often will only want to deal with some of the columns that we have in our dataset. To select a single column, we use the square brackets and the column name. The result is what we call a Pandas Series. A series is like a DataFrame, but it's just a single column. Selecting Multiple Columns We can also select multiple columns from our original DataFrame, creating a smaller DataFrame. We're going to select just the Age, Sex, and Survived columns from our original DataFrame. When selecting a single column from a Pandas DataFrame, we use single square brackets. When selecting multiple columns, we use double square brackets. col = df [ 'Fare' ] print ( col ) 0 7.2500 1 71.2833 2 7.9250 3 53.1000 4 8.0500 ... 882 13.0000 883 30.0000 884 23.4500 885 30.0000 886 7.7500 Name: Fare, Length: 887, dtype: float64 small_df = df [[ 'Age' , 'Sex' , 'Survived' ]] print ( small_df . head ()) Age Sex Survived 0 22.0 male 0 1 38.0 female 1 2 26.0 female 1 3 35.0 female 1 4 35.0 male 0 Creating a Column We can easily create a new column in our DataFrame that is True if the passenger is male and False if they\u2019re female. To create a new column, we use the same bracket syntax (df['male']) and then assign this new value to it. df [ 'male' ] = df [ 'Sex' ] == 'male' print ( df . head ()) Survived Pclass Sex ... Parents/Children Fare male 0 0 3 male ... 0 7.2500 True 1 1 1 female ... 0 71.2833 False 2 1 3 female ... 0 7.9250 False 3 1 1 female ... 0 53.1000 False 4 0 3 male ... 0 8.0500 True [5 rows x 8 columns] Slicing Pandas uses the iloc function to select data based on its numeric index. It works the same way indexing lists does in Python. iloc follows the same rules as slicing does with Python lists. We can also select the data based on a condition. .loc[ ] allows us to select data by label or by a conditional statement. .loc allows us to access any of the columns. Both .loc[ ] and .iloc[ ] may be used with a boolean array to subset the data. #Third row print ( df . iloc [ 2 ]) #First three rows print ( df . iloc [: 3 ]) #rows 2 to 3 print ( df . iloc [ 1 : 3 ]) #Conditionals print ( df [ df [ 'ages' ] > 18 ]) #Conditionals print ( df [( df [ 'ages' ] > 18 ) & ( df [ 'heights' ] < 180 )]) ages 24 heights 176 Name: Ana, dtype: int64 ages heights James 14 165 Bob 18 180 Ana 24 176 ages heights Bob 18 180 Ana 24 176 ages heights Ana 24 176 Susan 42 184 ages heights Ana 24 176 Droping a Column drop() deletes rows and columns. axis=1 specifies that we want to drop a column. axis=0 will drop a row. df . drop ( 'Sex' , axis = 1 , inplace = True ) Other Functions Value_counts value_counts() returns how many times a value appears in the dataset, also called the frequency of the values. df [ 'Survived' ] . value_counts () 0 545 1 342 Name: Survived, dtype: int64 Groupby The groupby() function is used to group our dataset by the given column. Similarly, we can use min(), max(), mean(), etc. to find the corresponding values for each group. df . groupby ( 'Survived' )[ 'Age' ] . value_counts () Survived Age 0 21.0 28 28.0 27 22.0 24 18.0 23 30.0 23 .. 1 32.5 1 43.0 1 53.0 1 55.0 1 80.0 1 Name: Age, Length: 146, dtype: int64 Aggregation We can also perform multiple operations on the groupby object using .agg() method. It takes a string, a function, or a list thereof. Using groupby and agg provides us the flexibility and therefore the power to look into various perspectives of a variable or column conditioned on categories. df . groupby ( 'Survived' ) . agg ({ 'Age' :[ np . median , np . mean ], 'Fare' :[ min , max ]}) Age Fare median mean min max Survived 0 28.0 30.138532 0.0 263.0000 1 28.0 28.408392 0.0 512.3292 Sort and Rank #Sort by labels along an axis df . sort_index () #Sort by the values along an axis df . sort_values ( by = 'Fare' ) #Assign ranks to entries df . rank () Dealing with Missing Values Three approaches to dealing with missing values. 1) A Simple Option: Drop Columns with Missing Values The simplest option is to drop columns with missing values. Unless most values in the dropped columns are missing, the model loses access to a lot of (potentially useful!) information with this approach. 2) A Better Option: Imputation Imputation fills in the missing values with some number. For instance, we can fill in the mean value along each column. The imputed value won't be exactly right in most cases, but it usually leads to more accurate models than you would get from dropping the column entirely. 3) An Extension To Imputation Imputation is the standard approach, and it usually works well. However, imputed values may be systematically above or below their actual values (which weren't collected in the dataset). Or rows with missing values may be unique in some other way. In that case, your model would make better predictions by considering which values were originally missing. In this approach, we impute the missing values, as before. And, additionally, for each column with missing entries in the original dataset, we add a new column that shows the location of the imputed entries. In some cases, this will meaningfully improve results. In other cases, it doesn't help at all. import pandas as pd from sklearn.model_selection import train_test_split # Load the data data = pd . read_csv ( 'https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv' ) #print(data.head()) # Select target y = data . Price # To keep things simple, we'll use only numerical predictors melb_predictors = data . drop ([ 'Price' ], axis = 1 ) X = melb_predictors . select_dtypes ( exclude = [ 'object' ]) # Divide data into training and validation subsets X_train , X_valid , y_train , y_valid = train_test_split ( X , y , train_size = 0.8 , test_size = 0.2 , random_state = 0 ) Defining Scoring from sklearn.ensemble import RandomForestRegressor from sklearn.metrics import mean_absolute_error # Function for comparing different approaches def score_dataset ( X_train , X_valid , y_train , y_valid ): model = RandomForestRegressor ( n_estimators = 10 , random_state = 0 ) model . fit ( X_train , y_train ) preds = model . predict ( X_valid ) return mean_absolute_error ( y_valid , preds ) Drop columns with missing values # Get names of columns with missing values cols_with_missing = [ col for col in X_train . columns if X_train [ col ] . isnull () . any ()] # Drop columns in training and validation data reduced_X_train = X_train . drop ( cols_with_missing , axis = 1 ) reduced_X_valid = X_valid . drop ( cols_with_missing , axis = 1 ) print ( \"MAE from Approach 1 (Drop columns with missing values):\" ) print ( score_dataset ( reduced_X_train , reduced_X_valid , y_train , y_valid )) MAE from Approach 1 (Drop columns with missing values): 354257.66157608695 Imputation Next, we use SimpleImputer to replace missing values with the mean value along each column. Although it's simple, filling in the mean value generally performs quite well (but this varies by dataset). While statisticians have experimented with more complex ways to determine imputed values (such as regression imputation, for instance), the complex strategies typically give no additional benefit once you plug the results into sophisticated machine learning models. from sklearn.impute import SimpleImputer # Imputation my_imputer = SimpleImputer () imputed_X_train = pd . DataFrame ( my_imputer . fit_transform ( X_train )) imputed_X_valid = pd . DataFrame ( my_imputer . transform ( X_valid )) # Imputation removed column names; put them back imputed_X_train . columns = X_train . columns imputed_X_valid . columns = X_valid . columns print ( \"MAE from Approach 2 (Imputation):\" ) print ( score_dataset ( imputed_X_train , imputed_X_valid , y_train , y_valid )) MAE from Approach 2 (Imputation): 203078.71828804348 An Extension to Imputation Next, we impute the missing values, while also keeping track of which values were imputed. # Make copy to avoid changing original data (when imputing) X_train_plus = X_train . copy () X_valid_plus = X_valid . copy () # Make new columns indicating what will be imputed for col in cols_with_missing : X_train_plus [ col + '_was_missing' ] = X_train_plus [ col ] . isnull () X_valid_plus [ col + '_was_missing' ] = X_valid_plus [ col ] . isnull () # Imputation my_imputer = SimpleImputer () imputed_X_train_plus = pd . DataFrame ( my_imputer . fit_transform ( X_train_plus )) imputed_X_valid_plus = pd . DataFrame ( my_imputer . transform ( X_valid_plus )) # Imputation removed column names; put them back imputed_X_train_plus . columns = X_train_plus . columns imputed_X_valid_plus . columns = X_valid_plus . columns print ( \"MAE from Approach 3 (An Extension to Imputation):\" ) print ( score_dataset ( imputed_X_train_plus , imputed_X_valid_plus , y_train , y_valid )) MAE from Approach 3 (An Extension to Imputation): 202839.1169021739 Best result is Approach 3, lowest MAE. Categorical Variables A categorical variable takes only a limited number of values. Consider a survey that asks how often you eat breakfast and provides four options: \"Never\", \"Rarely\", \"Most days\", or \"Every day\". In this case, the data is categorical, because responses fall into a fixed set of categories. If people responded to a survey about which what brand of car they owned, the responses would fall into categories like \"Honda\", \"Toyota\", and \"Ford\". In this case, the data is also categorical. You will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first. 1) Drop Categorical Variables The easiest approach to dealing with categorical variables is to simply remove them from the dataset. This approach will only work well if the columns did not contain useful information. 2) Ordinal Encoding Ordinal encoding assigns each unique value to a different integer. This approach assumes an ordering of the categories: \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3). This assumption makes sense in this example, because there is an indisputable ranking to the categories. Not all categorical variables have a clear ordering in the values, but we refer to those that do as ordinal variables. For tree-based models (like decision trees and random forests), you can expect ordinal encoding to work well with ordinal variables. 3) One-Hot Encoding One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data. To understand this, we'll work through an example. In contrast to ordinal encoding, one-hot encoding does not assume an ordering of the categories. Thus, you can expect this approach to work particularly well if there is no clear ordering in the categorical data (e.g., \"Red\" is neither more nor less than \"Yellow\"). We refer to categorical variables without an intrinsic ranking as nominal variables. One-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally won't use it for variables taking more than 15 different values). import pandas as pd from sklearn.model_selection import train_test_split # Read the data data = pd . read_csv ( 'https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv' ) # Separate target from predictors y = data . Price X = data . drop ([ 'Price' ], axis = 1 ) # Divide data into training and validation subsets X_train_full , X_valid_full , y_train , y_valid = train_test_split ( X , y , train_size = 0.8 , test_size = 0.2 , random_state = 0 ) # Drop columns with missing values (simplest approach) cols_with_missing = [ col for col in X_train_full . columns if X_train_full [ col ] . isnull () . any ()] X_train_full . drop ( cols_with_missing , axis = 1 , inplace = True ) X_valid_full . drop ( cols_with_missing , axis = 1 , inplace = True ) # \"Cardinality\" means the number of unique values in a column # Select categorical columns with relatively low cardinality (convenient but arbitrary) low_cardinality_cols = [ cname for cname in X_train_full . columns if X_train_full [ cname ] . nunique () < 10 and X_train_full [ cname ] . dtype == \"object\" ] # Select numerical columns numerical_cols = [ cname for cname in X_train_full . columns if X_train_full [ cname ] . dtype in [ 'int64' , 'float64' ]] # Keep selected columns only my_cols = low_cardinality_cols + numerical_cols X_train = X_train_full [ my_cols ] . copy () X_valid = X_valid_full [ my_cols ] . copy () X_train . head () Type Method Unnamed: 0 Rooms 2573 h SP 3349 4 2091 h SP 2686 3 4683 u S 6065 2 8832 h VB 11346 3 10469 u S 13474 2 Next, we obtain a list of all of the categorical variables in the training data. We do this by checking the data type (or dtype) of each column. The object dtype indicates a column has text (there are other things it could theoretically be, but that's unimportant for our purposes). For this dataset, the columns with text indicate categorical variables. # Get list of categorical variables s = ( X_train . dtypes == 'object' ) object_cols = list ( s [ s ] . index ) print ( \"Categorical variables:\" ) print ( object_cols ) Categorical variables: ['Type', 'Method'] Define Function to Measure Quality of Each Approach We define a function score_dataset() to compare the three different approaches to dealing with categorical variables. This function reports the mean absolute error (MAE) from a random forest model. In general, we want the MAE to be as low as possible! from sklearn.ensemble import RandomForestRegressor from sklearn.metrics import mean_absolute_error # Function for comparing different approaches def score_dataset ( X_train , X_valid , y_train , y_valid ): model = RandomForestRegressor ( n_estimators = 100 , random_state = 0 ) model . fit ( X_train , y_train ) preds = model . predict ( X_valid ) return mean_absolute_error ( y_valid , preds ) Score from Approach 1 (Drop Categorical Variables) We drop the object columns with the select_dtypes() method. drop_X_train = X_train . select_dtypes ( exclude = [ 'object' ]) drop_X_valid = X_valid . select_dtypes ( exclude = [ 'object' ]) print ( \"MAE from Approach 1 (Drop categorical variables):\" ) print ( score_dataset ( drop_X_train , drop_X_valid , y_train , y_valid )) MAE from Approach 1 (Drop categorical variables): 345278.21768750006 Score from Approach 2 (Ordinal Encoding) Scikit-learn has a OrdinalEncoder class that can be used to get ordinal encodings. We loop over the categorical variables and apply the ordinal encoder separately to each column. In the code cell below, for each column, we randomly assign each unique value to a different integer. This is a common approach that is simpler than providing custom labels; however, we can expect an additional boost in performance if we provide better-informed labels for all ordinal variables. from sklearn.preprocessing import OrdinalEncoder # Make copy to avoid changing original data label_X_train = X_train . copy () label_X_valid = X_valid . copy () # Apply ordinal encoder to each column with categorical data ordinal_encoder = OrdinalEncoder () label_X_train [ object_cols ] = ordinal_encoder . fit_transform ( X_train [ object_cols ]) label_X_valid [ object_cols ] = ordinal_encoder . transform ( X_valid [ object_cols ]) print ( \"MAE from Approach 2 (Ordinal Encoding):\" ) print ( score_dataset ( label_X_train , label_X_valid , y_train , y_valid )) MAE from Approach 2 (Ordinal Encoding): 314139.64080978255 Fitting an ordinal encoder to a column in the training data creates a corresponding integer-valued label for each unique value that appears in the training data. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them. This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue. For instance, you can write a custom ordinal encoder to deal with new categories. The simplest approach, however, is to drop the problematic categorical columns. The code cell below save the problematic columns to a Python list bad_label_cols. Likewise, columns that can be safely ordinal encoded are stored in good_label_cols. # Categorical columns in the training data object_cols = [ col for col in X_train . columns if X_train [ col ] . dtype == \"object\" ] # Columns that can be safely ordinal encoded good_label_cols = [ col for col in object_cols if set ( X_valid [ col ]) . issubset ( set ( X_train [ col ]))] # Problematic columns that will be dropped from the dataset bad_label_cols = list ( set ( object_cols ) - set ( good_label_cols )) print ( 'Categorical columns that will be ordinal encoded:' , good_label_cols ) print ( ' \\n Categorical columns that will be dropped from the dataset:' , bad_label_cols ) Score from Approach 3 (One-Hot Encoding) We use the OneHotEncoder class from scikit-learn to get one-hot encodings. There are a number of parameters that can be used to customize its behavior. We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix). To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. For instance, to encode the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.) from sklearn.preprocessing import OneHotEncoder # Apply one-hot encoder to each column with categorical data OH_encoder = OneHotEncoder ( handle_unknown = 'ignore' , sparse = False ) OH_cols_train = pd . DataFrame ( OH_encoder . fit_transform ( X_train [ object_cols ])) OH_cols_valid = pd . DataFrame ( OH_encoder . transform ( X_valid [ object_cols ])) # One-hot encoding removed index; put it back OH_cols_train . index = X_train . index OH_cols_valid . index = X_valid . index # Remove categorical columns (will replace with one-hot encoding) num_X_train = X_train . drop ( object_cols , axis = 1 ) num_X_valid = X_valid . drop ( object_cols , axis = 1 ) # Add one-hot encoded columns to numerical features OH_X_train = pd . concat ([ num_X_train , OH_cols_train ], axis = 1 ) OH_X_valid = pd . concat ([ num_X_valid , OH_cols_valid ], axis = 1 ) print ( \"MAE from Approach 3 (One-Hot Encoding):\" ) print ( score_dataset ( OH_X_train , OH_X_valid , y_train , y_valid )) MAE from Approach 3 (One-Hot Encoding): 314342.2874402174 We refer to the number of unique entries of a categorical variable as the cardinality of that categorical variable. For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset. For this reason, we typically will only one-hot encode columns with relatively low cardinality. Then, high cardinality columns can either be dropped from the dataset, or we can use ordinal encoding. # Get number of unique entries in each column with categorical data object_nunique = list ( map ( lambda col : X_train [ col ] . nunique (), object_cols )) d = dict ( zip ( object_cols , object_nunique )) # Print number of unique entries by column, in ascending order sorted ( d . items (), key = lambda x : x [ 1 ]) to set low_cardinality_cols to a Python list containing the columns that will be one-hot encoded. Likewise, high_cardinality_cols contains a list of categorical columns that will be dropped from the dataset. # Columns that will be one-hot encoded low_cardinality_cols = [ col for col in object_cols if X_train [ col ] . nunique () < 10 ] # Columns that will be dropped from the dataset high_cardinality_cols = list ( set ( object_cols ) - set ( low_cardinality_cols )) print ( 'Categorical columns that will be one-hot encoded:' , low_cardinality_cols ) print ( ' \\n Categorical columns that will be dropped from the dataset:' , high_cardinality_cols ) Which approach is best? In this case, dropping the categorical columns (Approach 1) performed worst, since it had the highest MAE score. As for the other two approaches, since the returned MAE scores are so close in value, there doesn't appear to be any meaningful benefit to one over the other. In general, one-hot encoding (Approach 3) will typically perform best, and dropping the categorical columns (Approach 1) typically performs worst, but it varies on a case-by-case basis.","title":"Pandas"},{"location":"ML/pyPandas/#series","text":"The Series is one building block in pandas. Pandas Series is a one-dimensional labeled array that can hold data of any type (integer, string, float, python objects, etc.), similar to a column in an excel spreadsheet. The axis labels are collectively called index. If we are given a bag of letters a, b, and c, and count how many of each we have, we find that there are 1 a, 2 b\u2019s, and 3 c\u2019s. We could create a Series by supplying a list of counts and their corresponding labels. If we don\u2019t specify the index, by default, the index would be the integer positions starting from 0. Accessing the value by its index, rather than the integer position comes in handy when the dataset is of thousands, if not millions, of rows. Series is the building block for the DataFrame we will introduce next. Think of Series as numpy 1d array with index or row names. import pandas as pd import numpy as np s1 = pd . Series ([ 1 , 2 , 3 ], index = [ 'a' , 'b' , 'c' ]) #Alternatively, the values can be a numpy array: s2 = pd . Series ( np . array ([ 1 , 2 , 3 ]), index = [ 'a' , 'b' , 'c' ]) #Or, we could use a dictionary to specify the index with keys s3 = pd . Series ({ 'a' : 1 , 'b' : 2 , 'c' : 3 }) #In a Series, we can access the value by its index directly s3 [ 'a' ] 1","title":"Series"},{"location":"ML/pyPandas/#dataframes","text":"In data science, data is usually more than one-dimensional, and of different data types; thus Series is not sufficient. DataFrames are 2darrays with both row and column labels. The easiest way to create a DataFrame is using a dictionary. Each key is a column, while the value is an array representing the data for that column.And then, we can pass this dictionary to the DataFrame constructor. The DataFrame automatically creates a numeric index for each row. We can specify a custom index, when creating the DataFrame. We can access a row using its index and the loc[] function. loc uses square brackets to specify the index. import pandas as pd data = { 'ages' : [ 14 , 18 , 24 , 42 ], 'heights' : [ 165 , 180 , 176 , 184 ] } df = pd . DataFrame ( data ) df = pd . DataFrame ( data , index = [ 'James' , 'Bob' , 'Ana' , 'Susan' ]) print ( df . loc [ \"Bob\" ]) ages 18 heights 180 Name: Bob, dtype: int64 Similar to numpy, to get the dimensions of a DataFrame, use .shape Size also works on DataFrame to return an integer representing the number of elements in this object.","title":"DataFrames"},{"location":"ML/pyPandas/#importing-and-exporting-data","text":"Generally data is stored in CSV (comma-separated values) files, which we can easily read in with panda\u2019s read_csv function. Pandas also supports reading from JSON files, as well as SQL databases. The head method returns the first 5 rows. You can instruct it to return the number of rows you would like as an argument (for example, df.head(10) will return the first 10 rows). Similarly, you can get the last rows using the tail() function. The info() function is used to get essential information about your dataset, such as number of rows, columns, data types, etc. Pandas automatically generates an index for the DataFrame, if none is specified. We can set our own index column by using the set_index() function. df.setIndex(\"Sex\", inplace=True) The inplace=True argument specifies that the change will be applied to our DataFrame, without the need to assign it to a new DataFrame variable. The describe method returns a table of statistics about the columns. We add a line in the code below to force python to display all 6 columns. Without the line, it will abbreviate the results. We can also get the summary stats for a single column. Count: This is the number of rows that have a value. In our case, every passenger has a value for each of the columns, so the value is 887 (the total number of passengers). Mean: Recall that the mean is the standard average. Std: This is short for standard deviation. This is a measure of how dispersed the data is. Min: The smallest value 25%: The 25th percentile 50%: The 50th percentile, also known as the median. 75%: The 75th percentile Max: The largest value .describe() ignores the null values, such as NaN (Not a Number) and generates the descriptive statistics that summarize the central tendency (i.e., mean), dispersion (i.e., standard deviation), and shape (i.e., min, max, and quantiles) of a dataset\u2019s distribution. df.shape df.index : Describe index df.columns df.count() : Number of non-NA values","title":"Importing and Exporting Data"},{"location":"ML/pyPandas/#csv","text":"import pandas as pd #read csv df = pd . read_csv ( 'titanic.csv' ) #write csv df . to_csv ( 'titanic.csv' ) print ( df . head ()) pd . options . display . max_columns = 6 Unnamed: 0 Survived Pclass ... Siblings/Spouses Parents/Children \\ 0 0 0 3 ... 1 0 1 1 1 1 ... 1 0 2 2 1 3 ... 0 0 3 3 1 1 ... 1 0 4 4 0 3 ... 0 0 Fare 0 7.2500 1 71.2833 2 7.9250 3 53.1000 4 8.0500 [5 rows x 8 columns] df . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 887 entries, 0 to 886 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Survived 887 non-null int64 1 Pclass 887 non-null int64 2 Sex 887 non-null object 3 Age 887 non-null float64 4 Siblings/Spouses 887 non-null int64 5 Parents/Children 887 non-null int64 6 Fare 887 non-null float64 dtypes: float64(2), int64(4), object(1) memory usage: 48.6+ KB print ( df . describe ()) *****Describe**** Survived Pclass Age Siblings/Spouses Parents/Children \\ count 887.000000 887.000000 887.000000 887.000000 887.000000 mean 0.385569 2.305524 29.471443 0.525366 0.383315 std 0.487004 0.836662 14.121908 1.104669 0.807466 min 0.000000 1.000000 0.420000 0.000000 0.000000 25% 0.000000 2.000000 20.250000 0.000000 0.000000 50% 0.000000 3.000000 28.000000 0.000000 0.000000 75% 1.000000 3.000000 38.000000 1.000000 0.000000 max 1.000000 3.000000 80.000000 8.000000 6.000000 Fare count 887.00000 mean 32.30542 std 49.78204 min 0.00000 25% 7.92500 50% 14.45420 75% 31.13750 max 512.32920 print ( df [ 'Survived' ] . describe ()) count 887.000000 mean 0.385569 std 0.487004 min 0.000000 25% 0.000000 50% 0.000000 75% 1.000000 max 1.000000 Name: Survived, dtype: float64","title":"CSV"},{"location":"ML/pyPandas/#excel","text":"#Read xlsx = pd . ExcelFile ( 'file.xls' ) df = pd . read_excel ( xlsx , 'Sheet1' ) #Write df . to_excel ( 'dir/myDataFrame.xlsx' , sheet_name = 'Sheet1' )","title":"Excel"},{"location":"ML/pyPandas/#sql","text":"(read_sql()is a convenience wrapper around read_sql_table() and read_sql_query()) from sqlalchemy import create_engine engine = create_engine ( 'sqlite:///:memory:' ) pd . read_sql ( SELECT * FROM my_table ;, engine ) pd . read_sql_table ( 'my_table' , engine ) pd . read_sql_query ( SELECT * FROM my_table ; ', engine) df . to_sql ( 'myDf' , engine )","title":"SQL"},{"location":"ML/pyPandas/#selecting-columns","text":"We often will only want to deal with some of the columns that we have in our dataset. To select a single column, we use the square brackets and the column name. The result is what we call a Pandas Series. A series is like a DataFrame, but it's just a single column. Selecting Multiple Columns We can also select multiple columns from our original DataFrame, creating a smaller DataFrame. We're going to select just the Age, Sex, and Survived columns from our original DataFrame. When selecting a single column from a Pandas DataFrame, we use single square brackets. When selecting multiple columns, we use double square brackets. col = df [ 'Fare' ] print ( col ) 0 7.2500 1 71.2833 2 7.9250 3 53.1000 4 8.0500 ... 882 13.0000 883 30.0000 884 23.4500 885 30.0000 886 7.7500 Name: Fare, Length: 887, dtype: float64 small_df = df [[ 'Age' , 'Sex' , 'Survived' ]] print ( small_df . head ()) Age Sex Survived 0 22.0 male 0 1 38.0 female 1 2 26.0 female 1 3 35.0 female 1 4 35.0 male 0","title":"Selecting Columns"},{"location":"ML/pyPandas/#creating-a-column","text":"We can easily create a new column in our DataFrame that is True if the passenger is male and False if they\u2019re female. To create a new column, we use the same bracket syntax (df['male']) and then assign this new value to it. df [ 'male' ] = df [ 'Sex' ] == 'male' print ( df . head ()) Survived Pclass Sex ... Parents/Children Fare male 0 0 3 male ... 0 7.2500 True 1 1 1 female ... 0 71.2833 False 2 1 3 female ... 0 7.9250 False 3 1 1 female ... 0 53.1000 False 4 0 3 male ... 0 8.0500 True [5 rows x 8 columns]","title":"Creating a Column"},{"location":"ML/pyPandas/#slicing","text":"Pandas uses the iloc function to select data based on its numeric index. It works the same way indexing lists does in Python. iloc follows the same rules as slicing does with Python lists. We can also select the data based on a condition. .loc[ ] allows us to select data by label or by a conditional statement. .loc allows us to access any of the columns. Both .loc[ ] and .iloc[ ] may be used with a boolean array to subset the data. #Third row print ( df . iloc [ 2 ]) #First three rows print ( df . iloc [: 3 ]) #rows 2 to 3 print ( df . iloc [ 1 : 3 ]) #Conditionals print ( df [ df [ 'ages' ] > 18 ]) #Conditionals print ( df [( df [ 'ages' ] > 18 ) & ( df [ 'heights' ] < 180 )]) ages 24 heights 176 Name: Ana, dtype: int64 ages heights James 14 165 Bob 18 180 Ana 24 176 ages heights Bob 18 180 Ana 24 176 ages heights Ana 24 176 Susan 42 184 ages heights Ana 24 176","title":"Slicing"},{"location":"ML/pyPandas/#droping-a-column","text":"drop() deletes rows and columns. axis=1 specifies that we want to drop a column. axis=0 will drop a row. df . drop ( 'Sex' , axis = 1 , inplace = True )","title":"Droping a Column"},{"location":"ML/pyPandas/#other-functions","text":"","title":"Other Functions"},{"location":"ML/pyPandas/#value_counts","text":"value_counts() returns how many times a value appears in the dataset, also called the frequency of the values. df [ 'Survived' ] . value_counts () 0 545 1 342 Name: Survived, dtype: int64","title":"Value_counts"},{"location":"ML/pyPandas/#groupby","text":"The groupby() function is used to group our dataset by the given column. Similarly, we can use min(), max(), mean(), etc. to find the corresponding values for each group. df . groupby ( 'Survived' )[ 'Age' ] . value_counts () Survived Age 0 21.0 28 28.0 27 22.0 24 18.0 23 30.0 23 .. 1 32.5 1 43.0 1 53.0 1 55.0 1 80.0 1 Name: Age, Length: 146, dtype: int64","title":"Groupby"},{"location":"ML/pyPandas/#aggregation","text":"We can also perform multiple operations on the groupby object using .agg() method. It takes a string, a function, or a list thereof. Using groupby and agg provides us the flexibility and therefore the power to look into various perspectives of a variable or column conditioned on categories. df . groupby ( 'Survived' ) . agg ({ 'Age' :[ np . median , np . mean ], 'Fare' :[ min , max ]}) Age Fare median mean min max Survived 0 28.0 30.138532 0.0 263.0000 1 28.0 28.408392 0.0 512.3292","title":"Aggregation"},{"location":"ML/pyPandas/#sort-and-rank","text":"#Sort by labels along an axis df . sort_index () #Sort by the values along an axis df . sort_values ( by = 'Fare' ) #Assign ranks to entries df . rank ()","title":"Sort and Rank"},{"location":"ML/pyPandas/#dealing-with-missing-values","text":"Three approaches to dealing with missing values. 1) A Simple Option: Drop Columns with Missing Values The simplest option is to drop columns with missing values. Unless most values in the dropped columns are missing, the model loses access to a lot of (potentially useful!) information with this approach. 2) A Better Option: Imputation Imputation fills in the missing values with some number. For instance, we can fill in the mean value along each column. The imputed value won't be exactly right in most cases, but it usually leads to more accurate models than you would get from dropping the column entirely. 3) An Extension To Imputation Imputation is the standard approach, and it usually works well. However, imputed values may be systematically above or below their actual values (which weren't collected in the dataset). Or rows with missing values may be unique in some other way. In that case, your model would make better predictions by considering which values were originally missing. In this approach, we impute the missing values, as before. And, additionally, for each column with missing entries in the original dataset, we add a new column that shows the location of the imputed entries. In some cases, this will meaningfully improve results. In other cases, it doesn't help at all. import pandas as pd from sklearn.model_selection import train_test_split # Load the data data = pd . read_csv ( 'https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv' ) #print(data.head()) # Select target y = data . Price # To keep things simple, we'll use only numerical predictors melb_predictors = data . drop ([ 'Price' ], axis = 1 ) X = melb_predictors . select_dtypes ( exclude = [ 'object' ]) # Divide data into training and validation subsets X_train , X_valid , y_train , y_valid = train_test_split ( X , y , train_size = 0.8 , test_size = 0.2 , random_state = 0 ) Defining Scoring from sklearn.ensemble import RandomForestRegressor from sklearn.metrics import mean_absolute_error # Function for comparing different approaches def score_dataset ( X_train , X_valid , y_train , y_valid ): model = RandomForestRegressor ( n_estimators = 10 , random_state = 0 ) model . fit ( X_train , y_train ) preds = model . predict ( X_valid ) return mean_absolute_error ( y_valid , preds ) Drop columns with missing values # Get names of columns with missing values cols_with_missing = [ col for col in X_train . columns if X_train [ col ] . isnull () . any ()] # Drop columns in training and validation data reduced_X_train = X_train . drop ( cols_with_missing , axis = 1 ) reduced_X_valid = X_valid . drop ( cols_with_missing , axis = 1 ) print ( \"MAE from Approach 1 (Drop columns with missing values):\" ) print ( score_dataset ( reduced_X_train , reduced_X_valid , y_train , y_valid )) MAE from Approach 1 (Drop columns with missing values): 354257.66157608695 Imputation Next, we use SimpleImputer to replace missing values with the mean value along each column. Although it's simple, filling in the mean value generally performs quite well (but this varies by dataset). While statisticians have experimented with more complex ways to determine imputed values (such as regression imputation, for instance), the complex strategies typically give no additional benefit once you plug the results into sophisticated machine learning models. from sklearn.impute import SimpleImputer # Imputation my_imputer = SimpleImputer () imputed_X_train = pd . DataFrame ( my_imputer . fit_transform ( X_train )) imputed_X_valid = pd . DataFrame ( my_imputer . transform ( X_valid )) # Imputation removed column names; put them back imputed_X_train . columns = X_train . columns imputed_X_valid . columns = X_valid . columns print ( \"MAE from Approach 2 (Imputation):\" ) print ( score_dataset ( imputed_X_train , imputed_X_valid , y_train , y_valid )) MAE from Approach 2 (Imputation): 203078.71828804348 An Extension to Imputation Next, we impute the missing values, while also keeping track of which values were imputed. # Make copy to avoid changing original data (when imputing) X_train_plus = X_train . copy () X_valid_plus = X_valid . copy () # Make new columns indicating what will be imputed for col in cols_with_missing : X_train_plus [ col + '_was_missing' ] = X_train_plus [ col ] . isnull () X_valid_plus [ col + '_was_missing' ] = X_valid_plus [ col ] . isnull () # Imputation my_imputer = SimpleImputer () imputed_X_train_plus = pd . DataFrame ( my_imputer . fit_transform ( X_train_plus )) imputed_X_valid_plus = pd . DataFrame ( my_imputer . transform ( X_valid_plus )) # Imputation removed column names; put them back imputed_X_train_plus . columns = X_train_plus . columns imputed_X_valid_plus . columns = X_valid_plus . columns print ( \"MAE from Approach 3 (An Extension to Imputation):\" ) print ( score_dataset ( imputed_X_train_plus , imputed_X_valid_plus , y_train , y_valid )) MAE from Approach 3 (An Extension to Imputation): 202839.1169021739 Best result is Approach 3, lowest MAE.","title":"Dealing with Missing Values"},{"location":"ML/pyPandas/#categorical-variables","text":"A categorical variable takes only a limited number of values. Consider a survey that asks how often you eat breakfast and provides four options: \"Never\", \"Rarely\", \"Most days\", or \"Every day\". In this case, the data is categorical, because responses fall into a fixed set of categories. If people responded to a survey about which what brand of car they owned, the responses would fall into categories like \"Honda\", \"Toyota\", and \"Ford\". In this case, the data is also categorical. You will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first. 1) Drop Categorical Variables The easiest approach to dealing with categorical variables is to simply remove them from the dataset. This approach will only work well if the columns did not contain useful information. 2) Ordinal Encoding Ordinal encoding assigns each unique value to a different integer. This approach assumes an ordering of the categories: \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3). This assumption makes sense in this example, because there is an indisputable ranking to the categories. Not all categorical variables have a clear ordering in the values, but we refer to those that do as ordinal variables. For tree-based models (like decision trees and random forests), you can expect ordinal encoding to work well with ordinal variables. 3) One-Hot Encoding One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data. To understand this, we'll work through an example. In contrast to ordinal encoding, one-hot encoding does not assume an ordering of the categories. Thus, you can expect this approach to work particularly well if there is no clear ordering in the categorical data (e.g., \"Red\" is neither more nor less than \"Yellow\"). We refer to categorical variables without an intrinsic ranking as nominal variables. One-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally won't use it for variables taking more than 15 different values). import pandas as pd from sklearn.model_selection import train_test_split # Read the data data = pd . read_csv ( 'https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv' ) # Separate target from predictors y = data . Price X = data . drop ([ 'Price' ], axis = 1 ) # Divide data into training and validation subsets X_train_full , X_valid_full , y_train , y_valid = train_test_split ( X , y , train_size = 0.8 , test_size = 0.2 , random_state = 0 ) # Drop columns with missing values (simplest approach) cols_with_missing = [ col for col in X_train_full . columns if X_train_full [ col ] . isnull () . any ()] X_train_full . drop ( cols_with_missing , axis = 1 , inplace = True ) X_valid_full . drop ( cols_with_missing , axis = 1 , inplace = True ) # \"Cardinality\" means the number of unique values in a column # Select categorical columns with relatively low cardinality (convenient but arbitrary) low_cardinality_cols = [ cname for cname in X_train_full . columns if X_train_full [ cname ] . nunique () < 10 and X_train_full [ cname ] . dtype == \"object\" ] # Select numerical columns numerical_cols = [ cname for cname in X_train_full . columns if X_train_full [ cname ] . dtype in [ 'int64' , 'float64' ]] # Keep selected columns only my_cols = low_cardinality_cols + numerical_cols X_train = X_train_full [ my_cols ] . copy () X_valid = X_valid_full [ my_cols ] . copy () X_train . head () Type Method Unnamed: 0 Rooms 2573 h SP 3349 4 2091 h SP 2686 3 4683 u S 6065 2 8832 h VB 11346 3 10469 u S 13474 2 Next, we obtain a list of all of the categorical variables in the training data. We do this by checking the data type (or dtype) of each column. The object dtype indicates a column has text (there are other things it could theoretically be, but that's unimportant for our purposes). For this dataset, the columns with text indicate categorical variables. # Get list of categorical variables s = ( X_train . dtypes == 'object' ) object_cols = list ( s [ s ] . index ) print ( \"Categorical variables:\" ) print ( object_cols ) Categorical variables: ['Type', 'Method'] Define Function to Measure Quality of Each Approach We define a function score_dataset() to compare the three different approaches to dealing with categorical variables. This function reports the mean absolute error (MAE) from a random forest model. In general, we want the MAE to be as low as possible! from sklearn.ensemble import RandomForestRegressor from sklearn.metrics import mean_absolute_error # Function for comparing different approaches def score_dataset ( X_train , X_valid , y_train , y_valid ): model = RandomForestRegressor ( n_estimators = 100 , random_state = 0 ) model . fit ( X_train , y_train ) preds = model . predict ( X_valid ) return mean_absolute_error ( y_valid , preds ) Score from Approach 1 (Drop Categorical Variables) We drop the object columns with the select_dtypes() method. drop_X_train = X_train . select_dtypes ( exclude = [ 'object' ]) drop_X_valid = X_valid . select_dtypes ( exclude = [ 'object' ]) print ( \"MAE from Approach 1 (Drop categorical variables):\" ) print ( score_dataset ( drop_X_train , drop_X_valid , y_train , y_valid )) MAE from Approach 1 (Drop categorical variables): 345278.21768750006 Score from Approach 2 (Ordinal Encoding) Scikit-learn has a OrdinalEncoder class that can be used to get ordinal encodings. We loop over the categorical variables and apply the ordinal encoder separately to each column. In the code cell below, for each column, we randomly assign each unique value to a different integer. This is a common approach that is simpler than providing custom labels; however, we can expect an additional boost in performance if we provide better-informed labels for all ordinal variables. from sklearn.preprocessing import OrdinalEncoder # Make copy to avoid changing original data label_X_train = X_train . copy () label_X_valid = X_valid . copy () # Apply ordinal encoder to each column with categorical data ordinal_encoder = OrdinalEncoder () label_X_train [ object_cols ] = ordinal_encoder . fit_transform ( X_train [ object_cols ]) label_X_valid [ object_cols ] = ordinal_encoder . transform ( X_valid [ object_cols ]) print ( \"MAE from Approach 2 (Ordinal Encoding):\" ) print ( score_dataset ( label_X_train , label_X_valid , y_train , y_valid )) MAE from Approach 2 (Ordinal Encoding): 314139.64080978255 Fitting an ordinal encoder to a column in the training data creates a corresponding integer-valued label for each unique value that appears in the training data. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them. This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue. For instance, you can write a custom ordinal encoder to deal with new categories. The simplest approach, however, is to drop the problematic categorical columns. The code cell below save the problematic columns to a Python list bad_label_cols. Likewise, columns that can be safely ordinal encoded are stored in good_label_cols. # Categorical columns in the training data object_cols = [ col for col in X_train . columns if X_train [ col ] . dtype == \"object\" ] # Columns that can be safely ordinal encoded good_label_cols = [ col for col in object_cols if set ( X_valid [ col ]) . issubset ( set ( X_train [ col ]))] # Problematic columns that will be dropped from the dataset bad_label_cols = list ( set ( object_cols ) - set ( good_label_cols )) print ( 'Categorical columns that will be ordinal encoded:' , good_label_cols ) print ( ' \\n Categorical columns that will be dropped from the dataset:' , bad_label_cols ) Score from Approach 3 (One-Hot Encoding) We use the OneHotEncoder class from scikit-learn to get one-hot encodings. There are a number of parameters that can be used to customize its behavior. We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix). To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. For instance, to encode the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.) from sklearn.preprocessing import OneHotEncoder # Apply one-hot encoder to each column with categorical data OH_encoder = OneHotEncoder ( handle_unknown = 'ignore' , sparse = False ) OH_cols_train = pd . DataFrame ( OH_encoder . fit_transform ( X_train [ object_cols ])) OH_cols_valid = pd . DataFrame ( OH_encoder . transform ( X_valid [ object_cols ])) # One-hot encoding removed index; put it back OH_cols_train . index = X_train . index OH_cols_valid . index = X_valid . index # Remove categorical columns (will replace with one-hot encoding) num_X_train = X_train . drop ( object_cols , axis = 1 ) num_X_valid = X_valid . drop ( object_cols , axis = 1 ) # Add one-hot encoded columns to numerical features OH_X_train = pd . concat ([ num_X_train , OH_cols_train ], axis = 1 ) OH_X_valid = pd . concat ([ num_X_valid , OH_cols_valid ], axis = 1 ) print ( \"MAE from Approach 3 (One-Hot Encoding):\" ) print ( score_dataset ( OH_X_train , OH_X_valid , y_train , y_valid )) MAE from Approach 3 (One-Hot Encoding): 314342.2874402174 We refer to the number of unique entries of a categorical variable as the cardinality of that categorical variable. For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset. For this reason, we typically will only one-hot encode columns with relatively low cardinality. Then, high cardinality columns can either be dropped from the dataset, or we can use ordinal encoding. # Get number of unique entries in each column with categorical data object_nunique = list ( map ( lambda col : X_train [ col ] . nunique (), object_cols )) d = dict ( zip ( object_cols , object_nunique )) # Print number of unique entries by column, in ascending order sorted ( d . items (), key = lambda x : x [ 1 ]) to set low_cardinality_cols to a Python list containing the columns that will be one-hot encoded. Likewise, high_cardinality_cols contains a list of categorical columns that will be dropped from the dataset. # Columns that will be one-hot encoded low_cardinality_cols = [ col for col in object_cols if X_train [ col ] . nunique () < 10 ] # Columns that will be dropped from the dataset high_cardinality_cols = list ( set ( object_cols ) - set ( low_cardinality_cols )) print ( 'Categorical columns that will be one-hot encoded:' , low_cardinality_cols ) print ( ' \\n Categorical columns that will be dropped from the dataset:' , high_cardinality_cols ) Which approach is best? In this case, dropping the categorical columns (Approach 1) performed worst, since it had the highest MAE score. As for the other two approaches, since the returned MAE scores are so close in value, there doesn't appear to be any meaningful benefit to one over the other. In general, one-hot encoding (Approach 3) will typically perform best, and dropping the categorical columns (Approach 1) typically performs worst, but it varies on a case-by-case basis.","title":"Categorical Variables"},{"location":"ML/pyPlot/","text":"Much of plotting you'll do will be through the Matplotlib library, specifically within the Pyplot module. matplotlib.pyplot is a collection of functions that make plotting in python work like MATLAB. Each function makes some change to a figure, e.g., creates a figure, creates a plotting area in a figure, plots lines, annotates the plots with labels, etc. The style can be changed from classic to ggplot, mimicking the aesthetic style used in the R package ggplot2. plt.style.use('ggplot') For all matplotlib plots, first create a figure and an axes object; to show the plot, call \u201cplt.show()\u201d. The figure contains all the objects, including axes, graphics, texts, and labels. The axes is a bounding box with ticks and labels. Think of axes as an individual plot. import matplotlib.pyplot as plt fig = plt . figure () ax = plt . axes () plt . style . use ( 'ggplot' ) plt . show () We can specify the x and y axis labels and a title using plt.xlabel(), plt.ylabel() and plt.title() One can also set the limits of x- and y-axis using plt.xlim() and plt.ylim(), respectively. To create a plot legend labeling each line. We can use the method plt.legend(), in conjunction with specifying labels in the plt.plot(). The color, line style (e.g., solid, dashed, etc.), and position, size, and style of labels can be modified using optional arguments to the function. For more details check the docstring of each function and the matplotlib documentation . Aptly named, the plot function is used to plot 2-D data, as shown below: import numpy as np import matplotlib.pyplot as plt # We'll start with a parabola # Compute the parabola's x and y coordinates x = np . arange ( - 5 , 5 , 0.1 ) y = np . square ( x ) # Use matplotlib for the plot plt . plot ( x , y , 'b' ) # specify the color blue for the line plt . xlabel ( 'X-Axis Values' ) plt . ylabel ( 'Y-Axis Values' ) plt . title ( 'First Plot: A Parabola' ) plt . show () # required to actually display the plot Imshow Another Matplotlib function you'll encounter is imshow which is used to display images. Recall that an image may be considered as an array, with array elements indicating image pixel values. As a simple example, here is the identity matrix: import numpy as np import matplotlib.pyplot as plt X = np . identity ( 10 ) identity_matrix_image = plt . imshow ( X , cmap = \"Greys_r\" ) plt . show () # Now plot a random matrix, with a different colormap A = np . random . randn ( 10 , 10 ) random_matrix_image = plt . imshow ( A ) plt . show () Scatter Plot A scatter plot is used to show all the values from your data on a graph. In order to get a visual representation of our data, we have to limit our data to two features. The purple dots are first class, the green dots are second class, and the yellow dots are third class. import pandas as pd import matplotlib.pyplot as plt df = pd . read_csv ( 'titanic.csv' ) plt . xlabel ( 'Age' ) plt . ylabel ( 'Fare' ) plt . scatter ( df [ 'Age' ], df [ 'Fare' ]) plt . scatter ( df [ 'Age' ], df [ 'Fare' ], c = df [ 'Pclass' ]) Line Plot Now that we can put individual datapoints on a plot, let's see how to draw the line. The plot function does just that. The following draws a line to approximately separate the 1st class from the 2nd and 3rd class. From eyeballing, we\u2019ll put the line from (0, 85) to (80, 5). Our syntax below has a list of the x values and a list of the y values. plt . plot ([ 0 , 80 ], [ 85 , 5 ]) Bar Plot The plot() function can take a kind argument, specifying the type of the plot we want to produce. For bar plots, provide kind=\"bar\". kind=\"barh\" can be used to create a horizontal bar chart. The stacked property can be used to specify if the bars should be stacked on top of each other. import pandas as pd import matplotlib.pyplot as plt df = pd . read_csv ( 'titanic.csv' ) ( df . groupby ( 'Survived' )[ 'Fare' ] . mean ()) . plot ( kind = 'bar' ) Box Plot A box plot is used to visualize the distribution of values in a column, basically visualizing the result of the describe() function. The green line shows the median value. The box shows the upper and lower quartiles (25% of the data is greater or less than these values). The circles show the outliers, while the black lines show the min/max values excluding the outliers. df [ df [ 'Survived' ] == 1 ][ \"Fare\" ] . plot ( kind = \"box\" ) Histogram Similar to box plots, histograms show the distribution of data. Visually histograms are similar to bar charts, however, histograms display frequencies for a group of data rather than an individual data point; therefore, no spaces are present between the bars. Typically, a histogram groups data into chunks (or bins). You can manually specify the number of bins to use using the bins attribute. df [ df [ 'Survived' ] == 1 ][ \"Fare\" ] . plot ( kind = \"hist\" , bins = 10 ) Area Plot df [ df [ 'Survived' ] == 1 ][ \"Fare\" ] . plot ( kind = \"area\" ) Pie Chart Create a pie chart using kind=\"pie\". Pie charts are generally used to show percentage or proportional data. Pie charts are usually used when you have up to 6 categories. df . groupby ( \"Survived\" )[ \"Fare\" ] . sum () . plot ( kind = \"pie\" )","title":"MatplotLib"},{"location":"ML/pyPlot/#imshow","text":"Another Matplotlib function you'll encounter is imshow which is used to display images. Recall that an image may be considered as an array, with array elements indicating image pixel values. As a simple example, here is the identity matrix: import numpy as np import matplotlib.pyplot as plt X = np . identity ( 10 ) identity_matrix_image = plt . imshow ( X , cmap = \"Greys_r\" ) plt . show () # Now plot a random matrix, with a different colormap A = np . random . randn ( 10 , 10 ) random_matrix_image = plt . imshow ( A ) plt . show ()","title":"Imshow"},{"location":"ML/pyPlot/#scatter-plot","text":"A scatter plot is used to show all the values from your data on a graph. In order to get a visual representation of our data, we have to limit our data to two features. The purple dots are first class, the green dots are second class, and the yellow dots are third class. import pandas as pd import matplotlib.pyplot as plt df = pd . read_csv ( 'titanic.csv' ) plt . xlabel ( 'Age' ) plt . ylabel ( 'Fare' ) plt . scatter ( df [ 'Age' ], df [ 'Fare' ]) plt . scatter ( df [ 'Age' ], df [ 'Fare' ], c = df [ 'Pclass' ])","title":"Scatter Plot"},{"location":"ML/pyPlot/#line-plot","text":"Now that we can put individual datapoints on a plot, let's see how to draw the line. The plot function does just that. The following draws a line to approximately separate the 1st class from the 2nd and 3rd class. From eyeballing, we\u2019ll put the line from (0, 85) to (80, 5). Our syntax below has a list of the x values and a list of the y values. plt . plot ([ 0 , 80 ], [ 85 , 5 ])","title":"Line Plot"},{"location":"ML/pyPlot/#bar-plot","text":"The plot() function can take a kind argument, specifying the type of the plot we want to produce. For bar plots, provide kind=\"bar\". kind=\"barh\" can be used to create a horizontal bar chart. The stacked property can be used to specify if the bars should be stacked on top of each other. import pandas as pd import matplotlib.pyplot as plt df = pd . read_csv ( 'titanic.csv' ) ( df . groupby ( 'Survived' )[ 'Fare' ] . mean ()) . plot ( kind = 'bar' )","title":"Bar Plot"},{"location":"ML/pyPlot/#box-plot","text":"A box plot is used to visualize the distribution of values in a column, basically visualizing the result of the describe() function. The green line shows the median value. The box shows the upper and lower quartiles (25% of the data is greater or less than these values). The circles show the outliers, while the black lines show the min/max values excluding the outliers. df [ df [ 'Survived' ] == 1 ][ \"Fare\" ] . plot ( kind = \"box\" )","title":"Box Plot"},{"location":"ML/pyPlot/#histogram","text":"Similar to box plots, histograms show the distribution of data. Visually histograms are similar to bar charts, however, histograms display frequencies for a group of data rather than an individual data point; therefore, no spaces are present between the bars. Typically, a histogram groups data into chunks (or bins). You can manually specify the number of bins to use using the bins attribute. df [ df [ 'Survived' ] == 1 ][ \"Fare\" ] . plot ( kind = \"hist\" , bins = 10 )","title":"Histogram"},{"location":"ML/pyPlot/#area-plot","text":"df [ df [ 'Survived' ] == 1 ][ \"Fare\" ] . plot ( kind = \"area\" )","title":"Area Plot"},{"location":"ML/pyPlot/#pie-chart","text":"Create a pie chart using kind=\"pie\". Pie charts are generally used to show percentage or proportional data. Pie charts are usually used when you have up to 6 categories. df . groupby ( \"Survived\" )[ \"Fare\" ] . sum () . plot ( kind = \"pie\" )","title":"Pie Chart"},{"location":"ML/pylinReg/","text":"In scikit-learn, models require a two-dimensional feature matrix (X, 2darray or a pandas DataFrame) and a one-dimensional target array (Y). Here we define the feature matrix as the column RM in boston and assign it to X. Note the double brackets around 'RM' in the code below, it is to ensure the result remains a DataFrame, a 2-dimensional data structure Similarly, we define our target to be the column MEDV in boston and assign it in a variable called Y. X = boston [[ 'RM' ]] print ( X . shape ) (506, 1) Y = boston [ 'MEDV' ] print ( Y . shape ) (506,) Recall that the single bracket outputs a Pandas Series, while a double bracket outputs a Pandas DataFrame, and the model expects the feature matrix X to be a 2darray. Univariate Linear Regression from sklearn.linear_model import LinearRegression model = LinearRegression () from sklearn.model_selection import train_test_split X_train , X_test , Y_train , Y_test = train_test_split ( X , Y , test_size = 0.3 , random_state = 1 ) print ( X_train . shape ) print ( X_test . shape ) print ( Y_train . shape ) print ( Y_test . shape ) (354, 1) (152, 1) (354,) (152,) To get an objective assessment on model\u2019s predictive power, it\u2019s important to keep the testing data unseen to the built model. model . fit ( X_train , Y_train ) LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) Fitting is equal to training. It fits the model to the training data and finds the coefficients specified in the linear regression model, i.e., intercept and slope. After it is trained, the model can be used to make predictions. Parameter Estimates The linear regression model has been fitted, what it means is that both parameters, the intercept and the slope, have been learned. What are they? In Scikit-learn, by convention all model parameters have trailing underscores, for example to access the estimated intercept from the model, rounded to the 2nd decimal place for better display. print ( model . intercept_ . round ( 2 )) print ( model . coef_ . round ( 2 )) -30.57 [8.46] The two parameters represent the intercept and slope of the line fit to the data. Our fitted model is MEDV = -30.57 + 8.46 * RM. For one unit increase in RM, the median home price would go up by $8460. Prediction The predict() method estimates the median home value by computing model.intercept_ + model.coef_*RM. Note that the input has to be 2-dimensional, either a 2darray or DataFrame will work in this case. import numpy as np new_RM = np . array ([ 6.5 ]) . reshape ( - 1 , 1 ) model . predict ( new_RM ) array([24.42606323]) In addition, we can feed the testing set and get predictions for all homes. y_test_predicted = model . predict ( X_test ) print ( y_test_predicted . shape ) type ( y_test_predicted ) (152,) numpy.ndarray Evaluating the Model plt . scatter ( X_test , Y_test , label = 'testing data' ) plt . plot ( X_test , y_test_predicted , label = 'prediction' , linewidth = 3 ) plt . xlabel = ( 'RM' ) plt . ylabel ( 'MEDV' ) plt . legend ( loc = 'upper left' ) plt . show () We can measure the distance between a point to the line along the vertical line, and this distance is referred to as residual or error. A residual is the difference between the observed value of the target and the predicted value. The closer the residual is to 0, the better job our model is doing. Residual plots can reveal bias from the model and statistical measures indicate goodness-of-fit. import matplotlib.pyplot as plt residuals = Y_test - y_test_predicted #plot residuals plt . scatter ( X_test , residuals ) #plot horizontal line at 0 plt . hlines ( y = 0 , xmin = X_test . min (), xmax = X_test . max (), linestyles = '--' ) #set xlim plt . xlim (( 4 , 9 )) plt . ylabel ( 'Residuals' ) plt . show () We can also use the mean_squared_error() method under scikit-learn metrics from sklearn.metrics import mean_squared_error mse = mean_squared_error ( Y_test , y_test_predicted ) print ( mse ) 36.517214730838624 In general, the smaller the MSE, the better, yet there is no absolute good or bad threshold. We can define it based on the dependent variable, i.e., MEDV in the test set. Y_test ranges from 6.3 to 50 with a variance 92.26. Compared to the total variance, a MSE of 36.52 is not bad. To make the scale of errors to be the same as the scale of targets, root mean squared error (RMSE) is often used. It is the square root of MSE. R-squared It is the proportion of total variation explained by the model. Here, around 60% of variability in the testing data is explained by our model. Evaluating R-squared values in conjunction with residual plots quantifies model performance. model . score ( X_test , Y_test ) 0.6015774471545622 Multivariate Linear Regression The extension from univariate to multivariate linear regression is straightforward in scikit-learn. The model instantiation, fitting, and predictions are identical, the only difference being the data preparation. #Data preparation X2 = boston [[ 'RM' , 'LSTAT' ]] Y = boston [ 'MEDV' ] #Trian test split #Same random split to ensure The same splits X2_train , X2_test , Y_train , Y_test = train_test_split ( X2 , Y , test_size = 0.3 , random_state = 1 ) model2 = LinearRegression () model2 . fit ( X2_train , Y_train ) print ( model2 . intercept_ ) print ( model2 . coef_ ) y_test_predicted2 = model2 . predict ( X2_test ) mean_squared_error ( Y_test , y_test_predicted2 ) 5.316818471096063 [ 4.12674118 -0.67762654] 28.93449134108657 In general, the more features the model includes the lower the MSE would be. Yet be careful about including too many features. Some features could be random noise, thus hurt the interpretability of the model.","title":"Linear Regression"},{"location":"ML/pylinReg/#univariate-linear-regression","text":"from sklearn.linear_model import LinearRegression model = LinearRegression () from sklearn.model_selection import train_test_split X_train , X_test , Y_train , Y_test = train_test_split ( X , Y , test_size = 0.3 , random_state = 1 ) print ( X_train . shape ) print ( X_test . shape ) print ( Y_train . shape ) print ( Y_test . shape ) (354, 1) (152, 1) (354,) (152,) To get an objective assessment on model\u2019s predictive power, it\u2019s important to keep the testing data unseen to the built model. model . fit ( X_train , Y_train ) LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) Fitting is equal to training. It fits the model to the training data and finds the coefficients specified in the linear regression model, i.e., intercept and slope. After it is trained, the model can be used to make predictions.","title":"Univariate Linear Regression"},{"location":"ML/pylinReg/#parameter-estimates","text":"The linear regression model has been fitted, what it means is that both parameters, the intercept and the slope, have been learned. What are they? In Scikit-learn, by convention all model parameters have trailing underscores, for example to access the estimated intercept from the model, rounded to the 2nd decimal place for better display. print ( model . intercept_ . round ( 2 )) print ( model . coef_ . round ( 2 )) -30.57 [8.46] The two parameters represent the intercept and slope of the line fit to the data. Our fitted model is MEDV = -30.57 + 8.46 * RM. For one unit increase in RM, the median home price would go up by $8460.","title":"Parameter Estimates"},{"location":"ML/pylinReg/#prediction","text":"The predict() method estimates the median home value by computing model.intercept_ + model.coef_*RM. Note that the input has to be 2-dimensional, either a 2darray or DataFrame will work in this case. import numpy as np new_RM = np . array ([ 6.5 ]) . reshape ( - 1 , 1 ) model . predict ( new_RM ) array([24.42606323]) In addition, we can feed the testing set and get predictions for all homes. y_test_predicted = model . predict ( X_test ) print ( y_test_predicted . shape ) type ( y_test_predicted ) (152,) numpy.ndarray","title":"Prediction"},{"location":"ML/pylinReg/#evaluating-the-model","text":"plt . scatter ( X_test , Y_test , label = 'testing data' ) plt . plot ( X_test , y_test_predicted , label = 'prediction' , linewidth = 3 ) plt . xlabel = ( 'RM' ) plt . ylabel ( 'MEDV' ) plt . legend ( loc = 'upper left' ) plt . show () We can measure the distance between a point to the line along the vertical line, and this distance is referred to as residual or error. A residual is the difference between the observed value of the target and the predicted value. The closer the residual is to 0, the better job our model is doing. Residual plots can reveal bias from the model and statistical measures indicate goodness-of-fit. import matplotlib.pyplot as plt residuals = Y_test - y_test_predicted #plot residuals plt . scatter ( X_test , residuals ) #plot horizontal line at 0 plt . hlines ( y = 0 , xmin = X_test . min (), xmax = X_test . max (), linestyles = '--' ) #set xlim plt . xlim (( 4 , 9 )) plt . ylabel ( 'Residuals' ) plt . show () We can also use the mean_squared_error() method under scikit-learn metrics from sklearn.metrics import mean_squared_error mse = mean_squared_error ( Y_test , y_test_predicted ) print ( mse ) 36.517214730838624 In general, the smaller the MSE, the better, yet there is no absolute good or bad threshold. We can define it based on the dependent variable, i.e., MEDV in the test set. Y_test ranges from 6.3 to 50 with a variance 92.26. Compared to the total variance, a MSE of 36.52 is not bad. To make the scale of errors to be the same as the scale of targets, root mean squared error (RMSE) is often used. It is the square root of MSE. R-squared It is the proportion of total variation explained by the model. Here, around 60% of variability in the testing data is explained by our model. Evaluating R-squared values in conjunction with residual plots quantifies model performance. model . score ( X_test , Y_test ) 0.6015774471545622","title":"Evaluating the Model"},{"location":"ML/pylinReg/#multivariate-linear-regression","text":"The extension from univariate to multivariate linear regression is straightforward in scikit-learn. The model instantiation, fitting, and predictions are identical, the only difference being the data preparation. #Data preparation X2 = boston [[ 'RM' , 'LSTAT' ]] Y = boston [ 'MEDV' ] #Trian test split #Same random split to ensure The same splits X2_train , X2_test , Y_train , Y_test = train_test_split ( X2 , Y , test_size = 0.3 , random_state = 1 ) model2 = LinearRegression () model2 . fit ( X2_train , Y_train ) print ( model2 . intercept_ ) print ( model2 . coef_ ) y_test_predicted2 = model2 . predict ( X2_test ) mean_squared_error ( Y_test , y_test_predicted2 ) 5.316818471096063 [ 4.12674118 -0.67762654] 28.93449134108657 In general, the more features the model includes the lower the MSE would be. Yet be careful about including too many features. Some features could be random noise, thus hurt the interpretability of the model.","title":"Multivariate Linear Regression"},{"location":"PR/pyAsser/","text":"An assertion is a sanity-check that you can turn on or turn off when you have finished testing the program. An expression is tested, and if the result comes up false, an exception is raised. Assertions are carried out through use of the assert statement. Programmers often place assertions at the start of a function to check for valid input, and after a function call to check for valid output. print ( 1 ) assert 2 + 2 == 4 print ( 2 ) assert 1 + 1 == 3 print ( 3 ) 1 2 --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) <ipython-input-77-c678df5c3c33> in <module>() 2 assert 2 + 2 == 4 3 print (2) ----> 4 assert 1 + 1 == 3 5 print (3) AssertionError: The assert can take a second argument that is passed to the AssertionError raised if the assertion fails. AssertionError exceptions can be caught and handled like any other exception using the try-except statement, but if not handled, this type of exception will terminate the program. temp =- 10 assert ( temp >= 0 ), \"Colder than absolute zero!\" --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) <ipython-input-78-f713a352d793> in <module>() 1 temp=-10 ----> 2 assert (temp>=0), \"Colder than absolute zero!\" AssertionError: Colder than absolute zero!","title":"Assertions"},{"location":"PR/pyCompr/","text":"Comprehensions are a handy way to run a loop within a single line of code and to collect the results of the loop in a collection such as a list List Comprehension List comprehensions are a useful way of quickly creating lists whose contents obey a simple rule. Python allows for list comprehension in which the elements of a list are iterated over all in one line of code. List comprehensions are inspired by set-builder notation in mathematics. even_list = [ 2 , 4 , 6 , 8 ] odd_list = [ even + 1 for even in even_list ] print ( odd_list ) cubes = [ i ** 3 for i in range ( 5 )] print ( cubes ) [3, 5, 7, 9] [0, 1, 8, 27, 64] Note from above the similarities between list comprehension and a for-loop; Python has list comprehension as a compact, \"pythonic\" way of performing operations that could be done within a for-loop. A list comprehension can also contain an if statement to enforce a condition on values in the list. a = [ i ** 2 for i in range ( 10 )] evens = [ i ** 2 for i in range ( 10 ) if i ** 2 % 2 == 0 ] print ( a ) print ( evens ) [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] [0, 4, 16, 36, 64] Trying to create a list in a very extensive range will result in a MemoryError. This code shows an example where the list comprehension runs out of memory. This issue is solved by generators. results = [] for city , year in zip ( cities , years ): #int () needed because year is a string if int ( year ) > 1945 : results . append ( city + ': ' + year ) To do it better and more Pythonic Use List comprehensions #List comprehension: # [f(element) for element in iterator if condition(element)] results = [( city + ': ' + year ) for city , year in zip ( cities , years ) if int ( year ) > 1945 ] results = [( city + ': ' + year ) for city , year in zip ( cities , years ) if int ( year ) > 1945 ] Dictionary comprehension cities_by_year = { year : city for city , year in zip ( cities , years )} # Demonstrate how to use dictionary comprehensions def main (): # define a list of temperature values ctemps = [ 0 , 12 , 34 , 100 ] # Use a comprehension to build a dictionary tempDict = { t : ( t * 9 / 5 ) + 32 for t in ctemps if t < 100 } print ( tempDict ) print ( tempDict [ 12 ]) # Merge two dictionaries with a comprehension team1 = { \"Jones\" : 24 , \"Jameson\" : 18 , \"Smith\" : 58 , \"Burns\" : 7 } team2 = { \"White\" : 12 , \"Macke\" : 88 , \"Perce\" : 4 } newTeam = { k : v for team in ( team1 , team2 ) for k , v in team . items ()} print ( newTeam ) if __name__ == \"__main__\" : main () {0: 32.0, 12: 53.6, 34: 93.2} 53.6 {'Jones': 24, 'Jameson': 18, 'Smith': 58, 'Burns': 7, 'White': 12, 'Macke': 88, 'Perce': 4} Set Comprehension cities_after_1930 = { city for year , city in cities_by_year . items () if int ( year ) > 1930 } def main (): # define a list of temperature data points ctemps = [ 5 , 10 , 12 , 14 , 10 , 23 , 41 , 30 , 12 , 24 , 12 , 18 , 29 ] # build a set of unique Fahrenheit temperatures ftemps1 = [( t * 9 / 5 ) + 32 for t in ctemps ] ftemps2 = {( t * 9 / 5 ) + 32 for t in ctemps } print ( ftemps1 ) print ( ftemps2 ) # build a set from an input source sTemp = \"The quick brown fox jumped over the lazy dog\" chars = { c . upper () for c in sTemp if not c . isspace ()} print ( chars ) if __name__ == \"__main__\" : main () [41.0, 50.0, 53.6, 57.2, 50.0, 73.4, 105.8, 86.0, 53.6, 75.2, 53.6, 64.4, 84.2] {64.4, 73.4, 41.0, 105.8, 75.2, 50.0, 84.2, 53.6, 86.0, 57.2} {'G', 'M', 'E', 'B', 'J', 'U', 'R', 'N', 'W', 'P', 'Y', 'T', 'O', 'H', 'Z', 'Q', 'V', 'X', 'F', 'K', 'L', 'D', 'I', 'A', 'C'}","title":"Comprehensions"},{"location":"PR/pyCompr/#list-comprehension","text":"List comprehensions are a useful way of quickly creating lists whose contents obey a simple rule. Python allows for list comprehension in which the elements of a list are iterated over all in one line of code. List comprehensions are inspired by set-builder notation in mathematics. even_list = [ 2 , 4 , 6 , 8 ] odd_list = [ even + 1 for even in even_list ] print ( odd_list ) cubes = [ i ** 3 for i in range ( 5 )] print ( cubes ) [3, 5, 7, 9] [0, 1, 8, 27, 64] Note from above the similarities between list comprehension and a for-loop; Python has list comprehension as a compact, \"pythonic\" way of performing operations that could be done within a for-loop. A list comprehension can also contain an if statement to enforce a condition on values in the list. a = [ i ** 2 for i in range ( 10 )] evens = [ i ** 2 for i in range ( 10 ) if i ** 2 % 2 == 0 ] print ( a ) print ( evens ) [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] [0, 4, 16, 36, 64] Trying to create a list in a very extensive range will result in a MemoryError. This code shows an example where the list comprehension runs out of memory. This issue is solved by generators. results = [] for city , year in zip ( cities , years ): #int () needed because year is a string if int ( year ) > 1945 : results . append ( city + ': ' + year ) To do it better and more Pythonic Use List comprehensions #List comprehension: # [f(element) for element in iterator if condition(element)] results = [( city + ': ' + year ) for city , year in zip ( cities , years ) if int ( year ) > 1945 ] results = [( city + ': ' + year ) for city , year in zip ( cities , years ) if int ( year ) > 1945 ]","title":"List Comprehension"},{"location":"PR/pyCompr/#dictionary-comprehension","text":"cities_by_year = { year : city for city , year in zip ( cities , years )} # Demonstrate how to use dictionary comprehensions def main (): # define a list of temperature values ctemps = [ 0 , 12 , 34 , 100 ] # Use a comprehension to build a dictionary tempDict = { t : ( t * 9 / 5 ) + 32 for t in ctemps if t < 100 } print ( tempDict ) print ( tempDict [ 12 ]) # Merge two dictionaries with a comprehension team1 = { \"Jones\" : 24 , \"Jameson\" : 18 , \"Smith\" : 58 , \"Burns\" : 7 } team2 = { \"White\" : 12 , \"Macke\" : 88 , \"Perce\" : 4 } newTeam = { k : v for team in ( team1 , team2 ) for k , v in team . items ()} print ( newTeam ) if __name__ == \"__main__\" : main () {0: 32.0, 12: 53.6, 34: 93.2} 53.6 {'Jones': 24, 'Jameson': 18, 'Smith': 58, 'Burns': 7, 'White': 12, 'Macke': 88, 'Perce': 4}","title":"Dictionary comprehension"},{"location":"PR/pyCompr/#set-comprehension","text":"cities_after_1930 = { city for year , city in cities_by_year . items () if int ( year ) > 1930 } def main (): # define a list of temperature data points ctemps = [ 5 , 10 , 12 , 14 , 10 , 23 , 41 , 30 , 12 , 24 , 12 , 18 , 29 ] # build a set of unique Fahrenheit temperatures ftemps1 = [( t * 9 / 5 ) + 32 for t in ctemps ] ftemps2 = {( t * 9 / 5 ) + 32 for t in ctemps } print ( ftemps1 ) print ( ftemps2 ) # build a set from an input source sTemp = \"The quick brown fox jumped over the lazy dog\" chars = { c . upper () for c in sTemp if not c . isspace ()} print ( chars ) if __name__ == \"__main__\" : main () [41.0, 50.0, 53.6, 57.2, 50.0, 73.4, 105.8, 86.0, 53.6, 75.2, 53.6, 64.4, 84.2] {64.4, 73.4, 41.0, 105.8, 75.2, 50.0, 84.2, 53.6, 86.0, 57.2} {'G', 'M', 'E', 'B', 'J', 'U', 'R', 'N', 'W', 'P', 'Y', 'T', 'O', 'H', 'Z', 'Q', 'V', 'X', 'F', 'K', 'L', 'D', 'I', 'A', 'C'}","title":"Set Comprehension"},{"location":"PR/pyCond/","text":"Oftentimes while programming, one will want to only execute portions of code when certain conditions are met, for instance, when a variable has a certain value. This is accomplished using conditional statements: if, elif, and else. Indentation is used to define the level of nesting, for nested conditionals. Multiple if/else statements make the code long and not very readable. The elif statement is equivalent to an else/if statement. It is used to make the code shorter, more readable, and avoid indentation increase. for i in range ( 10 ): if i % 2 == 0 : # % -- modulus operator -- returns the remainder after division print ( \" {} is even\" . format ( i )) else : print ( \" {} is odd\" . format ( i )) 0 is even 1 is odd 2 is even 3 is odd 4 is even 5 is odd 6 is even 7 is odd 8 is even 9 is odd # Example using elif as well # Print the meteorological season for each month (loosely, of course, and in the Northern Hemisphere) print ( \"In the Northern Hemisphere: \\n \" ) month_integer = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 ] # i.e., January is 1, February is 2, etc... for month in month_integer : if month < 3 : print ( \"Month {} is in Winter\" . format ( month )) elif month < 6 : print ( \"Month {} is in Spring\" . format ( month )) elif month < 9 : print ( \"Month {} is in Summer\" . format ( month )) elif month < 12 : print ( \"Month {} is in Fall\" . format ( month )) else : # This will put 12 (i.e., December) into Winter print ( \"Month {} is in Winter\" . format ( month )) In the Northern Hemisphere: Month 1 is in Winter Month 2 is in Winter Month 3 is in Spring Month 4 is in Spring Month 5 is in Spring Month 6 is in Summer Month 7 is in Summer Month 8 is in Summer Month 9 is in Fall Month 10 is in Fall Month 11 is in Fall Month 12 is in Winter Ternary operator Conditional expressions provide the functionality of if statements while using less code. They shouldn't be overused, as they can easily reduce readability, but they are often useful when assigning variables. Conditional expressions are also known as applications of the ternary operator. The ternary operator checks the condition and returns the corresponding value. The ternary operator is so called because, unlike most operators, it takes three arguments. a = 3 b = 1 if a >= 5 else 42 print ( b ) #42 Match case (Switch) ##For 3.10 up value = \"one\" match value : case \"one\" : result = 1 case \"two\" : result = 2 case \"three\" | \"four\" : result = ( 3 , 4 ) case _ : result =- 1 print ( result )","title":"Conditionals"},{"location":"PR/pyCond/#ternary-operator","text":"Conditional expressions provide the functionality of if statements while using less code. They shouldn't be overused, as they can easily reduce readability, but they are often useful when assigning variables. Conditional expressions are also known as applications of the ternary operator. The ternary operator checks the condition and returns the corresponding value. The ternary operator is so called because, unlike most operators, it takes three arguments. a = 3 b = 1 if a >= 5 else 42 print ( b ) #42","title":"Ternary operator"},{"location":"PR/pyCond/#match-case-switch","text":"##For 3.10 up value = \"one\" match value : case \"one\" : result = 1 case \"two\" : result = 2 case \"three\" | \"four\" : result = ( 3 , 4 ) case _ : result =- 1 print ( result )","title":"Match case (Switch)"},{"location":"PR/pyElse/","text":"The else statement is most commonly used along with the if statement, but it can also follow a for or while loop, which gives it a different meaning. With the for or while loop, the code within it is called if the loop finishes normally (when a break statement does not cause an exit from the loop). for i in range ( 10 ): if i == 999 : break else : print ( \"Unbroken 1\" ) for i in range ( 10 ): if i == 5 : break else : print ( \"Unbroken 2\" ) Unbroken 1 The else statement can also be used with try/except statements. In this case, the code within it is only executed if no error occurs in the try statement. try : print ( 1 ) except ZeroDivisionError : print ( 2 ) else : print ( 3 ) print ( \"*********\" ) try : print ( 1 / 0 ) except ZeroDivisionError : print ( 2 ) else : print ( 3 ) 1 3 ********* 2","title":"Else-4loopsExcep"},{"location":"PR/pyExp/","text":"Exceptions ImportError: an import fails; IndexError: a list is indexed with an out-of-range number; NameError: an unknown variable is used; SyntaxError: the code can't be parsed properly; TypeError: a function is called on a value of an inappropriate type; ValueError: a function is called on a value of the correct type, but with an inappropriate value. Exception Handling To handle exceptions, and to call code when an exception occurs, you can use a try/except statement. Multiple exceptions can also be put into a single except block using parentheses, to have the except block handle all of them. An except statement without any exception specified will catch all errors. Finally To ensure some code runs no matter what errors occur, you can use a finally statement. The finally statement is placed at the bottom of a try/except statement. try : a = 0 b = 1 print ( a / b ) #print(b/a) print ( a + \"a\" ) except ZeroDivisionError : print ( \"Error!\" ) except ( ValueError , TypeError ): print ( \"Error 2!\" ) except : print ( f 'Unknown error: { sys . exc_info () } ' ) else : print ( 'No errors' ) finally : print ( \"Bye bye\" ) 0.0 Error 2! Bye bye Raising Exceptions Use raise statement Exceptions can be raised with arguments that give detail about them. print ( 1 ) raise ValueError print ( 2 ) 1 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-75-990863ff3a0f> in <module>() 1 print(1) ----> 2 raise ValueError 3 print(2) ValueError: try : name = \"123\" raise NameError ( \"Invalid Name!\" ) except NameError as e : print ( f 'Name error: { e } ' ) print ( 2 ) Name error: Invalid Name! 2","title":"Exceptions"},{"location":"PR/pyExp/#exceptions","text":"ImportError: an import fails; IndexError: a list is indexed with an out-of-range number; NameError: an unknown variable is used; SyntaxError: the code can't be parsed properly; TypeError: a function is called on a value of an inappropriate type; ValueError: a function is called on a value of the correct type, but with an inappropriate value.","title":"Exceptions"},{"location":"PR/pyExp/#exception-handling","text":"To handle exceptions, and to call code when an exception occurs, you can use a try/except statement. Multiple exceptions can also be put into a single except block using parentheses, to have the except block handle all of them. An except statement without any exception specified will catch all errors.","title":"Exception Handling"},{"location":"PR/pyExp/#finally","text":"To ensure some code runs no matter what errors occur, you can use a finally statement. The finally statement is placed at the bottom of a try/except statement. try : a = 0 b = 1 print ( a / b ) #print(b/a) print ( a + \"a\" ) except ZeroDivisionError : print ( \"Error!\" ) except ( ValueError , TypeError ): print ( \"Error 2!\" ) except : print ( f 'Unknown error: { sys . exc_info () } ' ) else : print ( 'No errors' ) finally : print ( \"Bye bye\" ) 0.0 Error 2! Bye bye","title":"Finally"},{"location":"PR/pyExp/#raising-exceptions","text":"Use raise statement Exceptions can be raised with arguments that give detail about them. print ( 1 ) raise ValueError print ( 2 ) 1 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-75-990863ff3a0f> in <module>() 1 print(1) ----> 2 raise ValueError 3 print(2) ValueError: try : name = \"123\" raise NameError ( \"Invalid Name!\" ) except NameError as e : print ( f 'Name error: { e } ' ) print ( 2 ) Name error: Invalid Name! 2","title":"Raising Exceptions"},{"location":"PR/pyOp1/","text":"Operator Name Description a + b Addition Sum of a and b a - b Subtraction Difference of a and b a * b Multiplication Product of a and b a / b True division Quotient of a and b a // b Floor division Quotient of a and b , removing fractional parts a % b Modulus Integer remainder after division of a by b a ** b Exponentiation a raised to the power of b -a Negation The negative of a a = 3 ** 2 b = 2 ** 2 ** 3 print ( a ) print ( b ) print ( 9 ** ( 1 / 2 )) #result is float print ( 20 // 6 ) # Quotient print ( 20 % 6 ) # Modulo or remainder 9 256 3.0 3 2 Decimal Decimal fixed point and floating point arithmetic For enhanced precision, the decimal module provides support for fast correctly-rounded decimal floating point arithmetic. from decimal import * getcontext () . prec = 6 Decimal ( 1 ) / Decimal ( 7 ) Decimal('0.142857')","title":"Arithmethic"},{"location":"PR/pyOp1/#decimal","text":"Decimal fixed point and floating point arithmetic For enhanced precision, the decimal module provides support for fast correctly-rounded decimal floating point arithmetic. from decimal import * getcontext () . prec = 6 Decimal ( 1 ) / Decimal ( 7 ) Decimal('0.142857')","title":"Decimal"},{"location":"PR/pyOp2/","text":"In Python, bitwise operators are used to performing bitwise calculations on integers. The integers are first converted into binary and then operations are performed on bit by bit, hence the name bitwise operators. Then the result is returned in decimal format. Note: Python bitwise operators work only on integers. Operator Name Description a & b Bitwise AND Returns 1 if both the bits are 1 else 0 a | b Bitwise OR Returns 1 if either of the bit is 1 else 0 a ~ b Bitwise NOT Returns one\u2019s complement of the number a ^ b Bitwise XOR Returns 1 if one of the bits is 1 and the other is 0 else returns false a >> b Bitwise right shift Returns 1 if both the bits are 1 else 0 a << b Bitwise left shift Returns 1 if both the bits are 1 else 0 Shift Operators These operators are used to shift the bits of a number left or right thereby multiplying or dividing the number by two respectively. They can be used when we have to multiply or divide a number by two. Bitwise right shift Shifts the bits of the number to the right and fills 0 on voids left as a result. Similar effect as of dividing the number with some power of two. Bitwise left shift Shifts the bits of the number to the left and fills 0 on voids left as a result. Similar effect as of multiplying the number with some power of two. a = 10 #1010(Binary) b = 4 #0100(Binary) # Print bitwise AND operation print ( \"a & b =\" , a & b ) #0000(Binary) # Print bitwise OR operation print ( \"a | b =\" , a | b ) #1110(Binary)=14(Decimal) # Print bitwise NOT operation print ( \"~a =\" , ~ a ) #-(1010+1)(Binary)=-(1011)=-11(Decimal) # print bitwise XOR operation print ( \"a ^ b =\" , a ^ b ) # 1110(Binary)=14(Decimal) a = 10 b = - 10 # print bitwise right shift operator print ( \"a >> 1 =\" , a >> 1 ) print ( \"b >> 1 =\" , b >> 1 ) a = 5 b = - 10 # print bitwise left shift operator print ( \"a << 1 =\" , a << 1 ) print ( \"b << 1 =\" , b << 1 ) #Hexidecimal x = 0x0a y = 0x02 z = x & y print ( f '(hex) x is { x : 02x } , y is { y : 02x } , z is { z : 02x } ' ) print ( f '(bin) x is { x : 08b } , y is { y : 08b } , z is { z : 08b } ' ) z = x << y print ( f '(bin) x is { x : 08b } , y is { y : 08b } , z is { z : 08b } ' ) a & b = 0 a | b = 14 ~a = -11 a ^ b = 14 a >> 1 = 5 b >> 1 = -5 a << 1 = 10 b << 1 = -20 (hex) x is 0a, y is 02, z is 02 (bin) x is 00001010, y is 00000010, z is 00000010 (bin) x is 00001010, y is 00000010, z is 00101000","title":"Bitwise"},{"location":"PR/pyOp2/#shift-operators","text":"These operators are used to shift the bits of a number left or right thereby multiplying or dividing the number by two respectively. They can be used when we have to multiply or divide a number by two.","title":"Shift Operators"},{"location":"PR/pyOp2/#bitwise-right-shift","text":"Shifts the bits of the number to the right and fills 0 on voids left as a result. Similar effect as of dividing the number with some power of two.","title":"Bitwise right shift"},{"location":"PR/pyOp2/#bitwise-left-shift","text":"Shifts the bits of the number to the left and fills 0 on voids left as a result. Similar effect as of multiplying the number with some power of two. a = 10 #1010(Binary) b = 4 #0100(Binary) # Print bitwise AND operation print ( \"a & b =\" , a & b ) #0000(Binary) # Print bitwise OR operation print ( \"a | b =\" , a | b ) #1110(Binary)=14(Decimal) # Print bitwise NOT operation print ( \"~a =\" , ~ a ) #-(1010+1)(Binary)=-(1011)=-11(Decimal) # print bitwise XOR operation print ( \"a ^ b =\" , a ^ b ) # 1110(Binary)=14(Decimal) a = 10 b = - 10 # print bitwise right shift operator print ( \"a >> 1 =\" , a >> 1 ) print ( \"b >> 1 =\" , b >> 1 ) a = 5 b = - 10 # print bitwise left shift operator print ( \"a << 1 =\" , a << 1 ) print ( \"b << 1 =\" , b << 1 ) #Hexidecimal x = 0x0a y = 0x02 z = x & y print ( f '(hex) x is { x : 02x } , y is { y : 02x } , z is { z : 02x } ' ) print ( f '(bin) x is { x : 08b } , y is { y : 08b } , z is { z : 08b } ' ) z = x << y print ( f '(bin) x is { x : 08b } , y is { y : 08b } , z is { z : 08b } ' ) a & b = 0 a | b = 14 ~a = -11 a ^ b = 14 a >> 1 = 5 b >> 1 = -5 a << 1 = 10 b << 1 = -20 (hex) x is 0a, y is 02, z is 02 (bin) x is 00001010, y is 00000010, z is 00000010 (bin) x is 00001010, y is 00000010, z is 00101000","title":"Bitwise left shift"},{"location":"PR/pyOp3/","text":"In-place operators allow you to write code like 'x = x + 3' more concisely, as 'x += 3'. In-place operators can be used for any numerical operation (+, -, , /, %, *, //). These operators can be used on types other than numbers, as well, such as strings. x = 2 x += 3 print ( x ) x *= 7 print ( x ) y = \"spam \" y *= 3 print ( y ) 5 35 spam spam spam","title":"In-Place"},{"location":"PR/pyOp4/","text":"Walrus operator := allows you to assign values to variables within an expression, including variables that do not exist yet. Let's suppose we want to take an integer from the user, assign it to a variable num and output it. The walrus operator accomplishes these operations at once. The walrus operator makes code more readable and can be useful in many situations. num = int ( input ()) print ( num ) #The same but using Walrus operator #Python 3.8 up print ( num := int ( input ()))","title":"Walrus"},{"location":"PR/pyOp5/","text":"Boolean type . There are two Boolean values: True and False. They can be created by comparing values, for instance by using the equal operator ==. a = True print ( a ) b = ( 1 == 3 ) print ( b ) True False -1 Comparison operators are also called Relational operators . There are != , <, <=, >, >=. Used to compare strings lexicographically print ( 3 != 2 ) print ( 8 <= 9.0 ) #different types, no problem! print ( 'Carlos' > 'Ana' ) True True True Boolean Operators Boolean logic is used to make more complicated conditions for if statements that rely on more than one condition. Python's Boolean operators are and , or , not , in , not in , is and, is not . print ( 1 == 1 and 3 > 4 ) print ( 1 == 1 or 3 > 4 ) print ( 1 == 2 and not 3 > 4 ) x = ( 'bear' , 'bunny' , 'tree' ) y = 'bear' print ( y in x ) print ( y not in x ) print ( y is x [ 0 ]) #same id print ( id ( y )) print ( id ( x [ 0 ])) False True False True False True 140097849021808 140097849021808","title":"Comparison"},{"location":"PR/pyOp5/#boolean-operators","text":"Boolean logic is used to make more complicated conditions for if statements that rely on more than one condition. Python's Boolean operators are and , or , not , in , not in , is and, is not . print ( 1 == 1 and 3 > 4 ) print ( 1 == 1 or 3 > 4 ) print ( 1 == 2 and not 3 > 4 ) x = ( 'bear' , 'bunny' , 'tree' ) y = 'bear' print ( y in x ) print ( y not in x ) print ( y is x [ 0 ]) #same id print ( id ( y )) print ( id ( x [ 0 ])) False True False True False True 140097849021808 140097849021808","title":"Boolean Operators"},{"location":"PR/pyOp6/","text":"The Operator, @ In the context of matrix multiplication, a @ b invokes a.__matmul__(b) - making this syntax: a @ b equivalent to dot(a, b) and a @= b equivalent to a = dot(a, b) where dot is, for example, the numpy matrix multiplication function and a and b are matrices.","title":"/@"},{"location":"PR/pyOp7/","text":"(Star) * Operator The single star * unpacks the sequence/collection into positional arguments, so you can do this: def sum ( a , b ): return a + b values = ( 1 , 2 ) s = sum ( * values ) print ( s ) s = sum ( 1 , 2 ) #The same print ( s ) 3 3 The double star ** does the same, only using a dictionary and thus named arguments: values = { 'a' : 1 , 'b' : 2 } s = sum ( ** values ) print ( s ) 3 Combining the two: def sum ( a , b , c , d ): return a + b + c + d values1 = ( 1 , 2 ) values2 = { 'c' : 10 , 'd' : 15 } s = sum ( * values1 , ** values2 ) print ( s ) # the same as s = sum ( 1 , 2 , c = 10 , d = 15 ) print ( s ) 28 28 Additionally you can define functions to take x and *y arguments, this allows a function to accept any number of positional and/or named arguments that aren't specifically named in the declaration. def sum ( * values ): s = 0 for v in values : s = s + v return s s = sum ( 1 , 2 , 3 , 4 , 5 ) print ( s ) 15 or with ** def get_a ( ** values ): return values [ 'a' ] s = get_a ( a = 1 , b = 2 ) # returns 1 print ( s ) 1 this can allow you to specify a large number of optional parameters without having to declare them. And again, you can combine: def sum ( * values , ** options ): s = 0 for i in values : s = s + i if \"neg\" in options : if options [ \"neg\" ]: s = - s return s s = sum ( 1 , 2 , 3 , 4 , 5 ) # returns 15 s = sum ( 1 , 2 , 3 , 4 , 5 , neg = True ) # returns -15 s = sum ( 1 , 2 , 3 , 4 , 5 , neg = False ) # returns 15","title":"(star) *"},{"location":"PR/pyOp7/#star-operator","text":"The single star * unpacks the sequence/collection into positional arguments, so you can do this: def sum ( a , b ): return a + b values = ( 1 , 2 ) s = sum ( * values ) print ( s ) s = sum ( 1 , 2 ) #The same print ( s ) 3 3 The double star ** does the same, only using a dictionary and thus named arguments: values = { 'a' : 1 , 'b' : 2 } s = sum ( ** values ) print ( s ) 3 Combining the two: def sum ( a , b , c , d ): return a + b + c + d values1 = ( 1 , 2 ) values2 = { 'c' : 10 , 'd' : 15 } s = sum ( * values1 , ** values2 ) print ( s ) # the same as s = sum ( 1 , 2 , c = 10 , d = 15 ) print ( s ) 28 28 Additionally you can define functions to take x and *y arguments, this allows a function to accept any number of positional and/or named arguments that aren't specifically named in the declaration. def sum ( * values ): s = 0 for v in values : s = s + v return s s = sum ( 1 , 2 , 3 , 4 , 5 ) print ( s ) 15 or with ** def get_a ( ** values ): return values [ 'a' ] s = get_a ( a = 1 , b = 2 ) # returns 1 print ( s ) 1 this can allow you to specify a large number of optional parameters without having to declare them. And again, you can combine: def sum ( * values , ** options ): s = 0 for i in values : s = s + i if \"neg\" in options : if options [ \"neg\" ]: s = - s return s s = sum ( 1 , 2 , 3 , 4 , 5 ) # returns 15 s = sum ( 1 , 2 , 3 , 4 , 5 , neg = True ) # returns -15 s = sum ( 1 , 2 , 3 , 4 , 5 , neg = False ) # returns 15","title":"(Star) * Operator"},{"location":"PR/pyStr1/","text":"Backslashes can also be used to escape tabs or arbitrary Unicode characters. \\n represents a new line. Similarly, \\t represents a tab. Newlines will be automatically added for strings that are created using three quotes. This makes it easier to format long, multi-line texts without the need to explicitly put \\n for line breaks. print ( \"Hugo \\' s house \\n Jane \\' s mother \\t Diana \\' s dog\" ) print ( \"\"\"This is multline text\"\"\" ) print ( \"That's \\\" cool \\\" \" ) print ( \"Look, a mountain: / \\\\ \" ) print ( \"1 \\n 2 3\" ) Hugo's house Jane's mother Diana's dog This is multline text That's \"cool\" Look, a mountain: /\\ 1 2 3","title":"Backslashes"},{"location":"PR/pyStr2/","text":"String Operations : (+) concatenation (*) multiplication - Strings can also be multiplied by integers. This produces a repeated version of the original string. User Input : The input function prompts the user for input, and returns what they enter as a string print ( \"spam\" + \" eggs\" ) print ( \"spam \" * 3 ) name = input ( \"your name is?\" ) print ( \"Hello \" + name ) spam eggs spam spam spam your name is?Carlos Hello Carlos","title":"String operations"},{"location":"PR/pyStr3/","text":"str.format() String formatting uses a string's format method to substitute a number of arguments in the string. Each argument of the format function is placed in the string at the corresponding position, which is determined using the curly braces { }. # String formatting nums = [ 1 , 2 , 3 ] msg = \"Numbers {0} {1} {2} \" . format ( nums [ 1 ], nums [ 0 ], nums [ 2 ]) print ( msg ) Numbers 2 1 3 String formatting can also be done with named arguments. a = \" {x} , {y} \" . format ( y = 12 , x = 4 ) print ( a ) 4 , 12 x = 42 print ( 'The number is {:b} ' . format ( x )) The number is 101010 count(str) returns how many times the str substring appears in the given string. upper() converts the string to uppercase. lower() converts the string to lowercase. replace(old, new) replaces all occurrences of old with new. len(str) returns the length of the string (number of characters). Note, that these functions return a new string with the corresponding manipulation Fstrings (Literal String Interpolation) After Python 3.6, to create an f-string, prefix the string with the letter \u201c f \u201d. The string itself can be formatted in much the same way that you would with str.format(). F-strings provide a concise and convenient way to embed python expressions inside string literals for formatting. Simply it is a shortcut for the format method. # Prints today's date with help # of datetime library import datetime today = datetime . datetime . today () print ( f \" { today : %B %d, %Y } \" ) July 30, 2021 name = \"Eric Idle\" f \" { name . lower () } is funny.\" eric idle is funny. x = 42 print ( f 'The number is { x : b } ' ) The number is 101010 name = 'CarPool' age = 23 print ( f \"Hello, My name is { name } and I'm { age } years old.\" ) Hello, My name is CarPool and I'm 23 years old. Template string from string import Template def main (): # Usual string formatting with format() str1 = \"Love {0} and {1} \" . format ( \"Pollo\" , \"Pitas\" ) print ( str1 ) # create a template with placeholders templ = Template ( \"Love $ {title} and $ {author} \" ) # use the substitute method with keyword arguments str2 = templ . substitute ( title = \"Pollo\" , author = \"Pitas\" ) print ( str2 ) # use the substitute method with a dictionary data = { \"author\" : \"Pitas\" , \"title\" : \"Pollo\" } str3 = templ . substitute ( data ) print ( str3 ) if __name__ == \"__main__\" : main () Love Pollo and Pitas Love Pollo and Pitas Love Pollo and Pitas","title":"String formatting"},{"location":"PR/pyStr3/#strformat","text":"String formatting uses a string's format method to substitute a number of arguments in the string. Each argument of the format function is placed in the string at the corresponding position, which is determined using the curly braces { }. # String formatting nums = [ 1 , 2 , 3 ] msg = \"Numbers {0} {1} {2} \" . format ( nums [ 1 ], nums [ 0 ], nums [ 2 ]) print ( msg ) Numbers 2 1 3 String formatting can also be done with named arguments. a = \" {x} , {y} \" . format ( y = 12 , x = 4 ) print ( a ) 4 , 12 x = 42 print ( 'The number is {:b} ' . format ( x )) The number is 101010 count(str) returns how many times the str substring appears in the given string. upper() converts the string to uppercase. lower() converts the string to lowercase. replace(old, new) replaces all occurrences of old with new. len(str) returns the length of the string (number of characters). Note, that these functions return a new string with the corresponding manipulation","title":"str.format()"},{"location":"PR/pyStr3/#fstrings-literal-string-interpolation","text":"After Python 3.6, to create an f-string, prefix the string with the letter \u201c f \u201d. The string itself can be formatted in much the same way that you would with str.format(). F-strings provide a concise and convenient way to embed python expressions inside string literals for formatting. Simply it is a shortcut for the format method. # Prints today's date with help # of datetime library import datetime today = datetime . datetime . today () print ( f \" { today : %B %d, %Y } \" ) July 30, 2021 name = \"Eric Idle\" f \" { name . lower () } is funny.\" eric idle is funny. x = 42 print ( f 'The number is { x : b } ' ) The number is 101010 name = 'CarPool' age = 23 print ( f \"Hello, My name is { name } and I'm { age } years old.\" ) Hello, My name is CarPool and I'm 23 years old.","title":"Fstrings (Literal String Interpolation)"},{"location":"PR/pyStr3/#template-string","text":"from string import Template def main (): # Usual string formatting with format() str1 = \"Love {0} and {1} \" . format ( \"Pollo\" , \"Pitas\" ) print ( str1 ) # create a template with placeholders templ = Template ( \"Love $ {title} and $ {author} \" ) # use the substitute method with keyword arguments str2 = templ . substitute ( title = \"Pollo\" , author = \"Pitas\" ) print ( str2 ) # use the substitute method with a dictionary data = { \"author\" : \"Pitas\" , \"title\" : \"Pollo\" } str3 = templ . substitute ( data ) print ( str3 ) if __name__ == \"__main__\" : main () Love Pollo and Pitas Love Pollo and Pitas Love Pollo and Pitas","title":"Template string"},{"location":"PR/pyStr4/","text":"\u201c Format specifications \u201d are used within replacement fields contained within a format string to define how individual values are presented A general convention is that an empty format specification produces the same result as if you had called str() on the value. A non-empty format specification typically modifies the result. The general form of a standard format specifier is: format_spec [[fill]align][sign][#][0][width][grouping_option][.precision][type] fill any character align \"<\" , \">\" , \"=\" , \"^\" sign \"+\" , \"-\" , \" \" width digit+ grouping_option \"_\" , \",\" precision digit+ type \"b\", \"c\" , \"d\" , \"e\" , \"E\" , \"f\" , \"F\" , \"g\" , \"G\" , \"n\" , \"o\" , \"s\" , \"x\" , \"X\" , \"%\" Fill If a valid align value is specified, it can be preceded by a fill character that can be any character and defaults to a space if omitted. It is not possible to use a literal curly brace (\u201c{\u201d or \u201c}\u201d) as the fill character in a formatted string literal or when using the str.format() method. However, it is possible to insert a curly brace with a nested replacement field. This limitation doesn\u2019t affect the format() function. Align The meaning of the various alignment options is as follows: Option Meaning '<' Forces the field to be left-aligned within the available space (this is the default for most objects) '>' Forces the field to be right-aligned within the available space (this is the default for numbers) '=' Forces the padding to be placed after the sign (if any) but before the digits. This is used for printing fields in the form \u2018+000000120\u2019. This alignment option is only valid for numeric types. It becomes the default for numbers when \u20180\u2019 immediately precedes the field width '^' Forces the field to be centered within the available space ' {:>30} ' . format ( 'right aligned' ) right aligned ' {:*^30} ' . format ( 'centered' ) # use '*' as a fill char ***********centered*********** Sign Note that unless a minimum field width is defined, the field width will always be the same size as the data to fill it, so that the alignment option has no meaning in this case. The sign option is only valid for number types, and can be one of the following: Option Meaning '+' indicates that a sign should be used for both positive as well as negative numbers. '-' indicates that a sign should be used only for negative numbers (this is the default behavior). space indicates that a leading space should be used on positive numbers, and a minus sign on negative numbers. ' {:+f} ; {:+f} ' . format ( 3.14 , - 3.14 ) # show it always +3.140000; -3.140000 ' {: f} ; {: f} ' . format ( 3.14 , - 3.14 ) # show a space for positive numbers 3.140000; -3.140000 ' {:-f} ; {:-f} ' . format ( 3.14 , - 3.14 ) # show only the minus -- same as '{:f}; {:f}' 3.140000; -3.140000 # and , and _ Option '#' option The '#' option causes the \u201calternate form\u201d to be used for the conversion. The alternate form is defined differently for different types. This option is only valid for integer, float and complex types. For integers, when binary, octal, or hexadecimal output is used, this option adds the respective prefix '0b', '0o', '0x', or '0X' to the output value. For float and complex the alternate form causes the result of the conversion to always contain a decimal-point character, even if no digits follow it. Normally, a decimal-point character appears in the result of these conversions only if a digit follows it. In addition, for 'g' and 'G' conversions, trailing zeros are not removed from the result. 'Integer in Octal: {:#o} ' . format ( 1234567 ) Correct answers: 0o4553207 'Integer in Octal: {:o} ' . format ( 1234567 ) Correct answers: 4553207 ',' option The ',' option signals the use of a comma for a thousands separator. For a locale aware separator, use the 'n' integer presentation type instead. see PEP378 ' {:,} ' . format ( 1234567890 ) 1,234,567,890 format ( 1234.5 , \"08,.1f\" ) 01,234.5 '_' option The '_' option signals the use of an underscore for a thousands separator for floating point presentation types and for integer presentation type 'd'. For integer presentation types 'b', 'o', 'x', and 'X', underscores will be inserted every 4 digits. For other presentation types, specifying this option is an error. #{:10_} for a width of 10 with _ separator. format ( 1234.5 , \"08_.1f\" ) 01_234.5 Width width is a decimal integer defining the minimum total field width, including any prefixes, separators, and other formatting characters. If not specified, then the field width will be determined by the content. When no explicit alignment is given, preceding the width field by a zero ('0') character enables sign-aware zero-padding for numeric types. This is equivalent to a fill character of '0' with an alignment type of '='. Changed in version 3.10: Preceding the width field by '0' no longer affects the default alignment for strings. Precision The precision is a decimal integer indicating how many digits should be displayed after the decimal point for presentation types 'f' and 'F', or before and after the decimal point for presentation types 'g' or 'G'. For string presentation types the field indicates the maximum field size - in other words, how many characters will be used from the field content. The precision is not allowed for integer presentation types. points = 19 total = 22 'Correct answers: {:.2%} ' . format ( points / total ) Correct answers: 86.36% Type The type determines how the data should be presented. for strings The available string presentation types are: Type Meaning 's' String format. This is the default type for strings and may be omitted. None The same as 's'. for integers The available integer presentation types are: Type Meaning 'b' Binary format. Outputs the number in base 2. 'c' Character. Converts the integer to the corresponding unicode character before printing. 'd' Octal format. Outputs the number in base 8. 'o' Character. Converts the integer to the corresponding unicode character before printing. 'x' Hex format. Outputs the number in base 16, using lower-case letters for the digits above 9. 'X' Hex format. Outputs the number in base 16, using upper-case letters for the digits above 9. In case '#' is specified, the prefix '0x' will be upper-cased to '0X' as well. 'n' Number. This is the same as 'd', except that it uses the current locale setting to insert the appropriate number separator characters. None The same as 'd'. In addition to the above presentation types, integers can be formatted with the floating point presentation types listed below (except 'n' and None). When doing so, float() is used to convert the integer to a floating point number before formatting. for float and decimal The available presentation types for float and Decimal values are: Type Meaning 'e' Scientific notation. For a given precision p, formats the number in scientific notation with the letter \u2018e\u2019 separating the coefficient from the exponent. The coefficient has one digit before and p digits after the decimal point, for a total of p + 1 significant digits. With no precision given, uses a precision of 6 digits after the decimal point for float, and shows all coefficient digits for Decimal. If no digits follow the decimal point, the decimal point is also removed unless the # option is used. 'E' Scientific notation. Same as 'e' except it uses an upper case \u2018E\u2019 as the separator character. 'f' Fixed-point notation. For a given precision p, formats the number as a decimal number with exactly p digits following the decimal point. With no precision given, uses a precision of 6 digits after the decimal point for float, and uses a precision large enough to show all coefficient digits for Decimal. If no digits follow the decimal point, the decimal point is also removed unless the # option is used. 'F' Fixed-point notation. Same as 'f', but converts nan to NAN and inf to INF. 'g' General format. For a given precision p >= 1, this rounds the number to p significant digits and then formats the result in either fixed-point format or in scientific notation, depending on its magnitude. A precision of 0 is treated as equivalent to a precision of 1. The precise rules are as follows: suppose that the result formatted with presentation type 'e' and precision p-1 would have exponent exp. Then, if m <= exp < p, where m is -4 for floats and -6 for Decimals, the number is formatted with presentation type 'f' and precision p-1-exp. Otherwise, the number is formatted with presentation type 'e' and precision p-1. In both cases insignificant trailing zeros are removed from the significand, and the decimal point is also removed if there are no remaining digits following it, unless the '#' option is used. With no precision given, uses a precision of 6 significant digits for float. For Decimal, the coefficient of the result is formed from the coefficient digits of the value; scientific notation is used for values smaller than 1e-6 in absolute value and values where the place value of the least significant digit is larger than 1, and fixed-point notation is used otherwise. Positive and negative infinity, positive and negative zero, and nans, are formatted as inf, -inf, 0, -0 and nan respectively, regardless of the precision. 'G' General format. Same as 'g' except switches to 'E' if the number gets too large. The representations of infinity and NaN are uppercased, too. 'n' Number. This is the same as 'g', except that it uses the current locale setting to insert the appropriate number separator characters. '%' Percentage. Multiplies the number by 100 and displays in fixed ('f') format, followed by a percent sign. None For float this is the same as 'g', except that when fixed-point notation is used to format the result, it always includes at least one digit past the decimal point. The precision used is as large as needed to represent the given value faithfully. For Decimal, this is the same as either 'g' or 'G' depending on the value of context.capitals for the current decimal context. The overall effect is to match the output of str() as altered by the other format modifiers.","title":"String formatting specifications"},{"location":"PR/pyStr4/#fill","text":"If a valid align value is specified, it can be preceded by a fill character that can be any character and defaults to a space if omitted. It is not possible to use a literal curly brace (\u201c{\u201d or \u201c}\u201d) as the fill character in a formatted string literal or when using the str.format() method. However, it is possible to insert a curly brace with a nested replacement field. This limitation doesn\u2019t affect the format() function.","title":"Fill"},{"location":"PR/pyStr4/#align","text":"The meaning of the various alignment options is as follows: Option Meaning '<' Forces the field to be left-aligned within the available space (this is the default for most objects) '>' Forces the field to be right-aligned within the available space (this is the default for numbers) '=' Forces the padding to be placed after the sign (if any) but before the digits. This is used for printing fields in the form \u2018+000000120\u2019. This alignment option is only valid for numeric types. It becomes the default for numbers when \u20180\u2019 immediately precedes the field width '^' Forces the field to be centered within the available space ' {:>30} ' . format ( 'right aligned' ) right aligned ' {:*^30} ' . format ( 'centered' ) # use '*' as a fill char ***********centered***********","title":"Align"},{"location":"PR/pyStr4/#sign","text":"Note that unless a minimum field width is defined, the field width will always be the same size as the data to fill it, so that the alignment option has no meaning in this case. The sign option is only valid for number types, and can be one of the following: Option Meaning '+' indicates that a sign should be used for both positive as well as negative numbers. '-' indicates that a sign should be used only for negative numbers (this is the default behavior). space indicates that a leading space should be used on positive numbers, and a minus sign on negative numbers. ' {:+f} ; {:+f} ' . format ( 3.14 , - 3.14 ) # show it always +3.140000; -3.140000 ' {: f} ; {: f} ' . format ( 3.14 , - 3.14 ) # show a space for positive numbers 3.140000; -3.140000 ' {:-f} ; {:-f} ' . format ( 3.14 , - 3.14 ) # show only the minus -- same as '{:f}; {:f}' 3.140000; -3.140000","title":"Sign"},{"location":"PR/pyStr4/#and-and-_-option","text":"","title":"# and , and _ Option"},{"location":"PR/pyStr4/#option","text":"The '#' option causes the \u201calternate form\u201d to be used for the conversion. The alternate form is defined differently for different types. This option is only valid for integer, float and complex types. For integers, when binary, octal, or hexadecimal output is used, this option adds the respective prefix '0b', '0o', '0x', or '0X' to the output value. For float and complex the alternate form causes the result of the conversion to always contain a decimal-point character, even if no digits follow it. Normally, a decimal-point character appears in the result of these conversions only if a digit follows it. In addition, for 'g' and 'G' conversions, trailing zeros are not removed from the result. 'Integer in Octal: {:#o} ' . format ( 1234567 ) Correct answers: 0o4553207 'Integer in Octal: {:o} ' . format ( 1234567 ) Correct answers: 4553207","title":"'#' option"},{"location":"PR/pyStr4/#option_1","text":"The ',' option signals the use of a comma for a thousands separator. For a locale aware separator, use the 'n' integer presentation type instead. see PEP378 ' {:,} ' . format ( 1234567890 ) 1,234,567,890 format ( 1234.5 , \"08,.1f\" ) 01,234.5","title":"',' option"},{"location":"PR/pyStr4/#_-option","text":"The '_' option signals the use of an underscore for a thousands separator for floating point presentation types and for integer presentation type 'd'. For integer presentation types 'b', 'o', 'x', and 'X', underscores will be inserted every 4 digits. For other presentation types, specifying this option is an error. #{:10_} for a width of 10 with _ separator. format ( 1234.5 , \"08_.1f\" ) 01_234.5","title":"'_' option"},{"location":"PR/pyStr4/#width","text":"width is a decimal integer defining the minimum total field width, including any prefixes, separators, and other formatting characters. If not specified, then the field width will be determined by the content. When no explicit alignment is given, preceding the width field by a zero ('0') character enables sign-aware zero-padding for numeric types. This is equivalent to a fill character of '0' with an alignment type of '='. Changed in version 3.10: Preceding the width field by '0' no longer affects the default alignment for strings.","title":"Width"},{"location":"PR/pyStr4/#precision","text":"The precision is a decimal integer indicating how many digits should be displayed after the decimal point for presentation types 'f' and 'F', or before and after the decimal point for presentation types 'g' or 'G'. For string presentation types the field indicates the maximum field size - in other words, how many characters will be used from the field content. The precision is not allowed for integer presentation types. points = 19 total = 22 'Correct answers: {:.2%} ' . format ( points / total ) Correct answers: 86.36%","title":"Precision"},{"location":"PR/pyStr4/#type","text":"The type determines how the data should be presented.","title":"Type"},{"location":"PR/pyStr4/#for-strings","text":"The available string presentation types are: Type Meaning 's' String format. This is the default type for strings and may be omitted. None The same as 's'.","title":"for strings"},{"location":"PR/pyStr4/#for-integers","text":"The available integer presentation types are: Type Meaning 'b' Binary format. Outputs the number in base 2. 'c' Character. Converts the integer to the corresponding unicode character before printing. 'd' Octal format. Outputs the number in base 8. 'o' Character. Converts the integer to the corresponding unicode character before printing. 'x' Hex format. Outputs the number in base 16, using lower-case letters for the digits above 9. 'X' Hex format. Outputs the number in base 16, using upper-case letters for the digits above 9. In case '#' is specified, the prefix '0x' will be upper-cased to '0X' as well. 'n' Number. This is the same as 'd', except that it uses the current locale setting to insert the appropriate number separator characters. None The same as 'd'. In addition to the above presentation types, integers can be formatted with the floating point presentation types listed below (except 'n' and None). When doing so, float() is used to convert the integer to a floating point number before formatting.","title":"for integers"},{"location":"PR/pyStr4/#for-float-and-decimal","text":"The available presentation types for float and Decimal values are: Type Meaning 'e' Scientific notation. For a given precision p, formats the number in scientific notation with the letter \u2018e\u2019 separating the coefficient from the exponent. The coefficient has one digit before and p digits after the decimal point, for a total of p + 1 significant digits. With no precision given, uses a precision of 6 digits after the decimal point for float, and shows all coefficient digits for Decimal. If no digits follow the decimal point, the decimal point is also removed unless the # option is used. 'E' Scientific notation. Same as 'e' except it uses an upper case \u2018E\u2019 as the separator character. 'f' Fixed-point notation. For a given precision p, formats the number as a decimal number with exactly p digits following the decimal point. With no precision given, uses a precision of 6 digits after the decimal point for float, and uses a precision large enough to show all coefficient digits for Decimal. If no digits follow the decimal point, the decimal point is also removed unless the # option is used. 'F' Fixed-point notation. Same as 'f', but converts nan to NAN and inf to INF. 'g' General format. For a given precision p >= 1, this rounds the number to p significant digits and then formats the result in either fixed-point format or in scientific notation, depending on its magnitude. A precision of 0 is treated as equivalent to a precision of 1. The precise rules are as follows: suppose that the result formatted with presentation type 'e' and precision p-1 would have exponent exp. Then, if m <= exp < p, where m is -4 for floats and -6 for Decimals, the number is formatted with presentation type 'f' and precision p-1-exp. Otherwise, the number is formatted with presentation type 'e' and precision p-1. In both cases insignificant trailing zeros are removed from the significand, and the decimal point is also removed if there are no remaining digits following it, unless the '#' option is used. With no precision given, uses a precision of 6 significant digits for float. For Decimal, the coefficient of the result is formed from the coefficient digits of the value; scientific notation is used for values smaller than 1e-6 in absolute value and values where the place value of the least significant digit is larger than 1, and fixed-point notation is used otherwise. Positive and negative infinity, positive and negative zero, and nans, are formatted as inf, -inf, 0, -0 and nan respectively, regardless of the precision. 'G' General format. Same as 'g' except switches to 'E' if the number gets too large. The representations of infinity and NaN are uppercased, too. 'n' Number. This is the same as 'g', except that it uses the current locale setting to insert the appropriate number separator characters. '%' Percentage. Multiplies the number by 100 and displays in fixed ('f') format, followed by a percent sign. None For float this is the same as 'g', except that when fixed-point notation is used to format the result, it always includes at least one digit past the decimal point. The precision used is as large as needed to represent the given value faithfully. For Decimal, this is the same as either 'g' or 'G' depending on the value of context.capitals for the current decimal context. The overall effect is to match the output of str() as altered by the other format modifiers.","title":"for float and decimal"},{"location":"PR/pyStr5/","text":"Python contains many useful built-in functions and methods to accomplish common tasks. join joins a list of strings with another string as a separator. print ( \", \" . join ([ \"spam\" , \"eggs\" , \"ham\" ])) spam, eggs, ham replace replaces one substring in a string with another. print ( \"Hello Me\" . replace ( \"Me\" , \"Ham\" )) Hello Ham startswith and endswith determine if there is a substring at the start and end of a string, respectively. find and rfind search for a substr in a larger str. returns the index or -1 if not found. rfind starts from the right end to search. (Use the in operator for boolean result) print ( \"Hello Me\" . find ( 'lo' )) print ( \"Hello Me\" . find ( 'lop' )) print ( \"Hello Me\" . rfind ( 'lo' )) print ( \"lo\" in \"Hello Me\" ) 3 -1 3 True lower and upper To change the case of a string, you can use lower and upper. split is the opposite of join turning a string with a certain separator into a list. print ( \"spam, eggs, ham\" . split ( \", \" )) ['spam', 'eggs', 'ham'] count to count the number of times a substring is present. print ( \"Me Hello Me\" . count ( \"Me\" )) print ( \"Me Hello Me\" . count ( \"Meh\" )) 2 0","title":"String functions"},{"location":"PR/pyStr5/#join","text":"joins a list of strings with another string as a separator. print ( \", \" . join ([ \"spam\" , \"eggs\" , \"ham\" ])) spam, eggs, ham","title":"join"},{"location":"PR/pyStr5/#replace","text":"replaces one substring in a string with another. print ( \"Hello Me\" . replace ( \"Me\" , \"Ham\" )) Hello Ham","title":"replace"},{"location":"PR/pyStr5/#startswith-and-endswith","text":"determine if there is a substring at the start and end of a string, respectively.","title":"startswith and endswith"},{"location":"PR/pyStr5/#find-and-rfind","text":"search for a substr in a larger str. returns the index or -1 if not found. rfind starts from the right end to search. (Use the in operator for boolean result) print ( \"Hello Me\" . find ( 'lo' )) print ( \"Hello Me\" . find ( 'lop' )) print ( \"Hello Me\" . rfind ( 'lo' )) print ( \"lo\" in \"Hello Me\" ) 3 -1 3 True","title":"find and rfind"},{"location":"PR/pyStr5/#lower-and-upper","text":"To change the case of a string, you can use lower and upper.","title":"lower and upper"},{"location":"PR/pyStr5/#split","text":"is the opposite of join turning a string with a certain separator into a list. print ( \"spam, eggs, ham\" . split ( \", \" )) ['spam', 'eggs', 'ham']","title":"split"},{"location":"PR/pyStr5/#count","text":"to count the number of times a substring is present. print ( \"Me Hello Me\" . count ( \"Me\" )) print ( \"Me Hello Me\" . count ( \"Meh\" )) 2 0","title":"count"},{"location":"PR/pyVar1/","text":"In Python, we store all pieces of data -- numbers, characters, strings, everything -- as objects, and we refer to these objects using variables. As a simple case, we can assign a variable a value using the assignment operator, which is the \"equals\" sign. Python's order of operations is the same as that of normal mathematics: parentheses first, then exponentiation, then multiplication/division, and then addition/subtraction. x = 4 y = 5 z = x + y print ( z ) stri = \"Hello\" # or stri='Hello' No difference in python between \"\" and '' print ( stri + str ( z )) a = True print ( a ) b = ( 1 == 3 ) print ( b ) 9 Hello9 True False Three tools for understanding strange objects type() function type() (what is this thing?) To inspect which type is a variable use type(). dir() function dir() (what can I do with it?) help() function help() (tell me more) print ( type ( z )) print ( type ( a )) print ( type ( stri )) print ( dir ( 2 )) #print(help(2)) <class 'int'> <class 'int'> <class 'str'> ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] Python supports addition (+), substraction(-), multiplication( ), division(/),exponentiation( *), quotient (//) and remainder(%). You can chain exponentiations together. In other words, you can rise a number to multiple powers. id() function The id() function returns identity (unique integer) of an object. print ( 'id of 5 =' , id ( 5 )) a = 5 print ( 'id of a =' , id ( a )) b = a print ( 'id of b =' , id ( b )) c = 5.0 print ( 'id of c =' , id ( c )) id of 5 = 94364870744704 id of a = 94364870744704 id of b = 94364870744704 id of c = 140097885531312 It's important to note that everything in Python is an object, even numbers, and Classes. Hence, integer 5 has a unique id. The id of the integer 5 remains constant during the lifetime. Similar is the case for float 5.5 and other objects. isinstance() function To verify the type of an object, the isinstance() function checks if the object (first argument) is an instance or subclass of classinfo class (second argument). The None Object The None object is used to represent the absence of a value. It is similar to null in other programming languages. The None object is returned by any function that doesn't explicitly return anything else.","title":"Variables"},{"location":"PR/pyVar1/#three-tools-for-understanding-strange-objects","text":"","title":"Three tools for understanding strange objects"},{"location":"PR/pyVar1/#type-function","text":"type() (what is this thing?) To inspect which type is a variable use type().","title":"type() function"},{"location":"PR/pyVar1/#dir-function","text":"dir() (what can I do with it?)","title":"dir() function"},{"location":"PR/pyVar1/#help-function","text":"help() (tell me more) print ( type ( z )) print ( type ( a )) print ( type ( stri )) print ( dir ( 2 )) #print(help(2)) <class 'int'> <class 'int'> <class 'str'> ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] Python supports addition (+), substraction(-), multiplication( ), division(/),exponentiation( *), quotient (//) and remainder(%). You can chain exponentiations together. In other words, you can rise a number to multiple powers.","title":"help() function"},{"location":"PR/pyVar1/#id-function","text":"The id() function returns identity (unique integer) of an object. print ( 'id of 5 =' , id ( 5 )) a = 5 print ( 'id of a =' , id ( a )) b = a print ( 'id of b =' , id ( b )) c = 5.0 print ( 'id of c =' , id ( c )) id of 5 = 94364870744704 id of a = 94364870744704 id of b = 94364870744704 id of c = 140097885531312 It's important to note that everything in Python is an object, even numbers, and Classes. Hence, integer 5 has a unique id. The id of the integer 5 remains constant during the lifetime. Similar is the case for float 5.5 and other objects.","title":"id() function"},{"location":"PR/pyVar1/#isinstance-function","text":"To verify the type of an object, the isinstance() function checks if the object (first argument) is an instance or subclass of classinfo class (second argument).","title":"isinstance() function"},{"location":"PR/pyVar1/#the-none-object","text":"The None object is used to represent the absence of a value. It is similar to null in other programming languages. The None object is returned by any function that doesn't explicitly return anything else.","title":"The None Object"},{"location":"PR/pyVar2/","text":"int() function:To convert it to a number str() function:To convert it to a string float() function: To convert it to a float bool() function: To convert it to a bool age = int ( input ()) print ( \"Your age is \" + str ( age ) + \" years old\" ) 15 Your age is 15 years old numbers = [ 1 , 2 , 3 , 4 , 2 , 5 ] # check if numbers is instance of list result = isinstance ( numbers , list ) print ( result ) True","title":"Type Casting"},{"location":"PR/pyVar3/","text":"The location where we can find a variable and also access it if required is called the scope of a variable. Python resolves names using the so-called LEGB rule, which is named after the Python scope for names. The letters in LEGB stand for Local, Enclosing, Global, and Built-in. When you use nested functions, names are resolved by first checking the local scope or the innermost function\u2019s local scope. Then, Python looks at all enclosing scopes of outer functions from the innermost scope to the outermost scope. If no match is found, then Python looks at the global and built-in scopes. If it can\u2019t find the name, then you\u2019ll get an error. Global Keyword Global variables are the ones that are defined and declared outside any function and are not specified to any function. They can be used by any part of the program. We only need to use the global keyword in a function if we want to do assignments or change the global variable. global is not needed for printing and accessing. Python \u201cassumes\u201d that we want a local variable due to the assignment to s inside of f(), so the first statement throws the error message. Any variable which is changed or created inside of a function is local if it hasn\u2019t been declared as a global variable. To tell Python, that we want to use the global variable, we have to use the keyword \u201cglobal\u201d a = 1 # Uses global because there is no local 'a' def f (): print ( 'Inside f() : ' , a ) # Variable 'a' is redefined as a local def g (): a = 2 print ( 'Inside g() : ' , a ) # Uses global keyword to modify global 'a' def h (): global a a = 3 print ( 'Inside h() : ' , a ) # Global scope print ( 'global : ' , a ) f () print ( 'global : ' , a ) g () print ( 'global : ' , a ) h () print ( 'global : ' , a ) global : 1 Inside f() : 1 global : 1 Inside g() : 2 global : 1 Inside h() : 3 global : 3 Nonlocal Keyword In Python, nonlocal keyword is used in the case of nested functions. This keyword works similar to the global, but rather than global, this keyword declares a variable to point to the variable of outside enclosing function, in case of nested functions. # Python program to demonstrate # nonlocal keyword print ( \"Value of a using nonlocal is : \" , end = \"\" ) def outer (): a = 5 def inner (): nonlocal a a = 10 inner () print ( a ) outer () # demonstrating without non local # inner loop not changing the value of outer a # prints 5 print ( \"Value of a without using nonlocal is : \" , end = \"\" ) def outer (): a = 5 def inner (): a = 10 inner () print ( a ) outer () Value of a using nonlocal is : 10 Value of a without using nonlocal is : 5","title":"Scope of Variables"},{"location":"PR/pyVar3/#global-keyword","text":"Global variables are the ones that are defined and declared outside any function and are not specified to any function. They can be used by any part of the program. We only need to use the global keyword in a function if we want to do assignments or change the global variable. global is not needed for printing and accessing. Python \u201cassumes\u201d that we want a local variable due to the assignment to s inside of f(), so the first statement throws the error message. Any variable which is changed or created inside of a function is local if it hasn\u2019t been declared as a global variable. To tell Python, that we want to use the global variable, we have to use the keyword \u201cglobal\u201d a = 1 # Uses global because there is no local 'a' def f (): print ( 'Inside f() : ' , a ) # Variable 'a' is redefined as a local def g (): a = 2 print ( 'Inside g() : ' , a ) # Uses global keyword to modify global 'a' def h (): global a a = 3 print ( 'Inside h() : ' , a ) # Global scope print ( 'global : ' , a ) f () print ( 'global : ' , a ) g () print ( 'global : ' , a ) h () print ( 'global : ' , a ) global : 1 Inside f() : 1 global : 1 Inside g() : 2 global : 1 Inside h() : 3 global : 3","title":"Global Keyword"},{"location":"PR/pyVar3/#nonlocal-keyword","text":"In Python, nonlocal keyword is used in the case of nested functions. This keyword works similar to the global, but rather than global, this keyword declares a variable to point to the variable of outside enclosing function, in case of nested functions. # Python program to demonstrate # nonlocal keyword print ( \"Value of a using nonlocal is : \" , end = \"\" ) def outer (): a = 5 def inner (): nonlocal a a = 10 inner () print ( a ) outer () # demonstrating without non local # inner loop not changing the value of outer a # prints 5 print ( \"Value of a without using nonlocal is : \" , end = \"\" ) def outer (): a = 5 def inner (): a = 10 inner () print ( a ) outer () Value of a using nonlocal is : 10 Value of a without using nonlocal is : 5","title":"Nonlocal Keyword"},{"location":"PR/pyVar4/","text":"del is used in Python to unset a variable or name. You can use it on variable names, but a more common use is to remove indexes from a list or dictionary. my_list1 = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ] print ( my_list1 ) # delete second element of my_list1 del my_list1 [ 1 ] print ( my_list1 ) # slice my_list1 from index 3 to 5 del my_list1 [ 3 : 5 ] print ( my_list1 ) [1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 3, 4, 5, 6, 7, 8, 9] [1, 3, 4, 7, 8, 9] my_dict1 = { \"small\" : \"big\" , \"black\" : \"white\" , \"up\" : \"down\" } print ( my_dict1 ) # delete key-value pair with key \"black\" from my_dict1 del my_dict1 [ \"black\" ] print ( my_dict1 ) {'small': 'big', 'black': 'white', 'up': 'down'} {'small': 'big', 'up': 'down'}","title":"del Keyword"},{"location":"PR/pyWhile/","text":"A while loop is used to repeat a block of code multiple times. The while loop is used in cases when the number of iterations is not known and depends on some calculations and conditions in the code block of the loop. To end a while loop prematurely, the break statement can be used. Another statement that can be used within loops is continue. Unlike break, continue jumps back to the top of the loop, rather than stopping it. Basically, the continue statement stops the current iteration and continues with the next one. i = 1 while i <= 5 : print ( i ) i += 1 print ( \"the end\" ) 1 2 3 4 5 the end","title":"While-loops"},{"location":"PR/pyfor/","text":"Looping statements allow for the repeated execution of a section of code. For instance, suppose we wanted to add up all of the integers between zero (0) and ten (10), not including ten. We could, of course, do this in one line, but we could also use a loop to add each integer one at a time. Below is the code for a simple accumulator that accomplishes this: sum = 0 for i in range ( 10 ): sum = sum + i print ( sum ) alternative_sum = 0 + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 print ( alternative_sum == sum ) 45 True Range function The range () built-in function generates the sequence of values that we loop over, and notice that range(10) does not include 10 itself. In order to output the range as a list, we need to explicitly convert it to a list, using the list() function. If range is called with one argument, it produces an object with values from 0 to that argument. If it is called with two arguments, it produces values from the first to the second. range can have a third argument, which determines the interval of the sequence produced, also called the step. We can also create list of decreasing numbers, using a negative number as the third argument. numbers = list ( range ( 10 )) print ( numbers ) numbers = list ( range ( 5 , 10 )) print ( numbers ) numbers = list ( range ( 5 , 10 , 2 )) print ( numbers ) print ( list ( range ( 20 , 5 , - 2 ))) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [5, 6, 7, 8, 9] [5, 7, 9] [20, 18, 16, 14, 12, 10, 8, 6] elements in lists In addition to looping over a sequence of integers using the range() function, we can also loop over the elements in a list, which is shown below: ingredients = [ \"flour\" , \"sugar\" , \"eggs\" , \"oil\" , \"baking soda\" ] for ingredient in ingredients : print ( ingredient ) flour sugar eggs oil baking soda Above, the for-loop iterates over the elements of the list ingredients , and within the loop each of those elements is referred to as ingredient . The use of singular/plural nouns to handle this iteration is a common Python motif, but is by no means necessary to use in your own programming. Break and Continue Similar to while loops, the break and continue statements can be used in for loops, to stop the loop or jump to the next iteration. # use the break and continue statements for x in range ( 5 , 10 ): if ( x == 7 ): break if ( x % 2 == 0 ): continue print ( x ) #using the enumerate() function to get index days = [ \"Mon\" , \"Tue\" , \"Wed\" , \"Thu\" , \"Fri\" , \"Sat\" , \"Sun\" ] for i , d in enumerate ( days ): print ( i , d ) 5 0 Mon 1 Tue 2 Wed 3 Thu 4 Fri 5 Sat 6 Sun","title":"For-loops"},{"location":"PR/pyfor/#range-function","text":"The range () built-in function generates the sequence of values that we loop over, and notice that range(10) does not include 10 itself. In order to output the range as a list, we need to explicitly convert it to a list, using the list() function. If range is called with one argument, it produces an object with values from 0 to that argument. If it is called with two arguments, it produces values from the first to the second. range can have a third argument, which determines the interval of the sequence produced, also called the step. We can also create list of decreasing numbers, using a negative number as the third argument. numbers = list ( range ( 10 )) print ( numbers ) numbers = list ( range ( 5 , 10 )) print ( numbers ) numbers = list ( range ( 5 , 10 , 2 )) print ( numbers ) print ( list ( range ( 20 , 5 , - 2 ))) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [5, 6, 7, 8, 9] [5, 7, 9] [20, 18, 16, 14, 12, 10, 8, 6]","title":"Range function"},{"location":"PR/pyfor/#elements-in-lists","text":"In addition to looping over a sequence of integers using the range() function, we can also loop over the elements in a list, which is shown below: ingredients = [ \"flour\" , \"sugar\" , \"eggs\" , \"oil\" , \"baking soda\" ] for ingredient in ingredients : print ( ingredient ) flour sugar eggs oil baking soda Above, the for-loop iterates over the elements of the list ingredients , and within the loop each of those elements is referred to as ingredient . The use of singular/plural nouns to handle this iteration is a common Python motif, but is by no means necessary to use in your own programming.","title":"elements in lists"},{"location":"PR/pyfor/#break-and-continue","text":"Similar to while loops, the break and continue statements can be used in for loops, to stop the loop or jump to the next iteration. # use the break and continue statements for x in range ( 5 , 10 ): if ( x == 7 ): break if ( x % 2 == 0 ): continue print ( x ) #using the enumerate() function to get index days = [ \"Mon\" , \"Tue\" , \"Wed\" , \"Thu\" , \"Fri\" , \"Sat\" , \"Sun\" ] for i , d in enumerate ( days ): print ( i , d ) 5 0 Mon 1 Tue 2 Wed 3 Thu 4 Fri 5 Sat 6 Sun","title":"Break and Continue"},{"location":"lib/pyBisect/","text":"The purpose of Bisect algorithm is to find a position in list where an element needs to be inserted to keep the list sorted. Python in its definition provides the bisect algorithms using the module \u201cbisect\u201d which allows to keep the list in sorted order after insertion of each element. This is essential as this reduces overhead time required to sort the list again and again after insertion of each element. Important Bisection Functions bisect(list, num, beg, end) :- This function returns the position in the sorted list, where the number passed in argument can be placed so as to maintain the resultant list in sorted order. If the element is already present in the list, the right most position where element has to be inserted is returned. This function takes 4 arguments, list which has to be worked with, number to insert, starting position in list to consider, ending position which has to be considered. bisect_left(list, num, beg, end) :- This function returns the position in the sorted list, where the number passed in argument can be placed so as to maintain the resultant list in sorted order. If the element is already present in the list, the left most position where element has to be inserted is returned. This function takes 4 arguments, list which has to be worked with, number to insert, starting position in list to consider, ending position which has to be considered. bisect_right(list, num, beg, end) :- This function works similar to the \u201cbisect()\u201d and mentioned above. insort(list, num, beg, end) :- This function returns the sorted list after inserting number in appropriate position, if the element is already present in the list, the element is inserted at the rightmost possible position. This function takes 4 arguments, list which has to be worked with, number to insert, starting position in list to consider, ending position which has to be considered. insort_left(list, num, beg, end) :- This function returns the sorted list after inserting number in appropriate position, if the element is already present in the list, the element is inserted at the leftmost possible position. This function takes 4 arguments, list which has to be worked with, number to insert, starting position in list to consider, ending position which has to be considered. insort_right(list, num, beg, end) :- This function works similar to the \u201cinsort()\u201d as mentioned above. # use the bisection functions to maintain a list in sorted order import bisect values = [ 5 , 7 , 13 , 20 , 25 , 31 , 36 , 43 , 47 , 49 , 50 , 75 ] # exercise the left and right bisection routines print ( bisect . bisect ( values , 25 )) print ( bisect . bisect_right ( values , 25 )) print ( bisect . bisect_left ( values , 25 )) # use insort to insert new items bisect . insort_right ( values , 25 ) # will insert to the right print ( values ) # bisect can be used as an array lookup using breakpoints breakpoints = [ 60 , 70 , 80 , 90 ] gradeLetters = 'FDCBA' scores = [ 81 , 68 , 53 , 91 , 90 , 82 , 76 , 71 , 84 ] def calcGrade ( score ): # use the bisect function to identify cutoff points for the letter grades i = bisect . bisect ( breakpoints , score ) return gradeLetters [ i ] results = [ calcGrade ( score ) for score in scores ] print ( results ) 5 5 4 [5, 7, 13, 20, 25, 25, 31, 36, 43, 47, 49, 50, 75] ['B', 'D', 'F', 'A', 'A', 'B', 'C', 'C', 'B']","title":"Bisect"},{"location":"lib/pyEmoji/","text":"pip install emoji pip install rich print ( ' \\N{JUGGLING} ' ) #Unicode Name print ( ' \\U0001F939 ' ) #Unicode Codepoint print ( '\ud83e\udd39' ) #Literal Character import emoji , rich print ( emoji . emojize ( ':person_juggling:' )) #pip install emoji rich . print ( ':person_juggling:' ) #pip install rich \ud83e\udd39 \ud83e\udd39 \ud83e\udd39 \ud83e\udd39 \ud83e\udd39","title":"Emoji"},{"location":"lib/pyGen/","text":"Modules are pieces of code that other people have written to fulfill common tasks, such as generating random numbers, performing mathematical operations, etc. There are three main types of modules in Python, those you write yourself, those you install from external sources, and those that are preinstalled with Python. The last type is called the standard library , and contains many useful modules. Some of the standard library's useful modules include string , re , datetime , math , random , os , multiprocessing , subprocess , socket , email , json , doctest , unittest , pdb , argparse and sys . Python 3 Module of the Week shows how to use the modules of the Python 3 standard library. Many third-party Python modules are stored on the Python Package Index (PyPI) . The best way to install these is using a program called pip. It's important to enter pip commands at the command line, not the Python interpreter. The basic way to use a module is to add import module_name at the top of your code, and then using module_name.var to access functions and values with the name var in the module. Use a comma separated list to import multiple objects. Text Processing Services string \u2014 Common string operations re \u2014 Regular expression operations Functional Programming Modules itertools \u2014 Functions creating iterators for efficient looping functools \u2014 Higher-order functions and operations on callable objects operator \u2014 Standard operators as functions DataTypes datetime \u2014 Basic date and time types calendar \u2014 General calendar-related functions Collections \u2014 Container datatypes heapq \u2014 Heap queue algorithm bisect \u2014 Array bisection algorithm array \u2014 Efficient arrays of numeric values pprint \u2014 Data pretty printer enum \u2014 Support for enumerations Numeric and Mathematical Modules numbers \u2014 Numeric abstract base classes math \u2014 Mathematical functions cmath \u2014 Mathematical functions for complex numbers decimal \u2014 Decimal fixed point and floating point arithmetic fractions \u2014 Rational numbers random \u2014 Generate pseudo-random numbers statistics \u2014 Mathematical statistics functions File Management Fast IO OS.path \u2014 Common pathname manipulations glob \u2014 Unix style pathname pattern expansion shutil \u2014 High-level file operations PyFileSystem \u2014 Common interface to any filesystem. Data Persistence pickle \u2014 Python object serialization json \u2014 JSON encoder and decoder csv \u2014 CSV File Reading and Writing Graphic User Interface GUI with Tk emoji \u2014 Several ways to print emojis Interactivity with ipywidgets \u2014 Interactive browser controls for Jupyter notebooks Networking and Internet requests \u2014 HTTP for humans BeautifulSoup \u2014 Parsing HTML and XML documents Machine Learning Pandas \u2014 Read and manipulate data Numpy \u2014 Manipulating lists and tables of numerical data Numba \u2014 Makes Python code fast Matplotlib \u2014 For creating static, animated, and interactive visualizations in Python Scikit-learn \u2014 Machine learning in Python Parallel Computing Threads Processes Asyncio Development Tools Debugging and Profiling pdb \u2014 The Python debugger Time Profiling Memory Profiling Testing Software Logging Software Packaging and Distribution","title":"General"},{"location":"lib/pyIO/","text":"File Management Opening Files The argument of the open function is the path to the file. If the file is in the current working directory of the program, you can specify only its name. You can specify the mode used to open a file by applying a second argument to the open function. Sending \"r\" means open in read mode, which is the default. Sending \"w\" means write mode, for rewriting the contents of a file. Sending \"a\" means append mode, for adding new content to the end of the file. Adding \"b\" to a mode opens it in binary mode, which is used for non-text files (such as image and sound files). Once a file has been opened and used, you should close it. This is done with the close method of the file object. Reading Files file.read(): returns all the contents file.readlines():To retrieve each line in a file, you can use the readlines method to return a list in which each element is a line in the file. Writing Files To write to files you use the write method The write method returns the number of bytes written to a file, if successful. try : myfile = open ( \"filename.txt\" , 'r+' ) #mode read and write #read all content cont = myfile . read () myfile . write ( \"New line to insert in file\" ) print ( cont ) finally : myfile . close () myfile = open ( \"textfile.txt\" , 'r+' ) #mode read and write #print each line for line in myfile : print ( line . rstrip ()) myfile . close () This is line 1 This is line 2 This is line 3 This is line 4 This is line 5 This is line 6 This is line 7 This is line 8 This is line 9 This is line 10 An alternative way of doing this is using with statements. This creates a temporary variable (often called f), which is only accessible in the indented block of the with statement. The file is automatically closed at the end of the with statement, even if exceptions occur within it. with open ( \"filename.txt\" ) as f : print ( f . read ()) # Open a file for writing and create it if it doesn't exist f = open ( \"textfile.txt\" , \"w+\" ) # Open the file for appending text to the end # f = open(\"textfile.txt\",\"a+\") # write some lines of data to the file for i in range ( 10 ): f . write ( \"This is line %d \\r\\n \" % ( i + 1 )) # close the file when done f . close () # Open the file back up and read the contents f = open ( \"textfile.txt\" , \"r\" ) if f . mode == 'r' : # check to make sure that the file was opened # use the read() function to read the entire file # contents = f.read() # print (contents) fl = f . readlines () # readlines reads the individual lines into a list for x in fl : print ( x ) This is line 1 This is line 2 This is line 3 This is line 4 This is line 5 This is line 6 This is line 7 This is line 8 This is line 9 This is line 10 Fast Input/Output # Program to show time taken in fast # I / O and normal I / O in python from sys import stdin , stdout import time # Function for fast I / O def fastIO (): # Stores the start time start = time . perf_counter () # To read single integer n = stdin . readline () # To input array arr = [ int ( x ) for x in stdin . readline () . split ()] # Output integer stdout . write ( str ( n )) # Output array stdout . write ( \" \" . join ( map ( str , arr )) + \" \\n \" ) # Stores the end time end = time . perf_counter () print ( \"Time taken in fast IO\" , end - start ) # Function for normal I / O def normalIO (): # Stores the start time start = time . perf_counter () # Input integer n = int ( input ()) # Input array arr = [ int ( x ) for x in input () . split ()] # Output integer print ( n ) # Output array for i in arr : print ( i , end = \" \" ) print () # Stores the end time end = time . perf_counter () print ( \"Time taken in normal IO: \" , end - start ) # Driver Code if __name__ == '__main__' : fastIO () normalIO () Time taken in fast IO 0.001823046999994915 23 23 23 23 Time taken in normal IO: 5.173487307000002 OS Path Module import os from os import path import datetime from datetime import date , time , timedelta import time # Print the name of the OS print ( os . name ) # Check for item existence and type print ( \"Item exists: \" , path . exists ( \"textfile.txt\" )) print ( \"Item is a file: \" , path . isfile ( \"textfile.txt\" )) print ( \"Item is a directory: \" , path . isdir ( \"textfile.txt\" )) # Work with file paths print ( \"Item's path: \" , path . realpath ( \"textfile.txt\" )) print ( \"Item's path and name: \" , path . split ( path . realpath ( \"textfile.txt\" ))) # Get the modification time t = time . ctime ( path . getmtime ( \"textfile.txt\" )) print ( t ) print ( datetime . datetime . fromtimestamp ( path . getmtime ( \"textfile.txt\" ))) # Calculate how long ago the item was modified td = datetime . datetime . now () - datetime . datetime . fromtimestamp ( path . getmtime ( \"textfile.txt\" )) print ( \"It has been \" + str ( td ) + \" since the file was modified\" ) print ( \"Or, \" + str ( td . total_seconds ()) + \" seconds\" ) posix Item exists: True Item is a file: True Item is a directory: False Item's path: /content/textfile.txt Item's path and name: ('/content', 'textfile.txt') Mon Jul 19 14:31:57 2021 2021-07-19 14:31:57.728190 It has been 0:06:55.454337 since the file was modified Or, 415.454337 seconds GLOB Module Glob module searches all path names looking for files matching a specified pattern according to the rules dictated by the Unix shell. Results so obtained are returned in arbitrary order. Some requirements need traversal through a list of files at some location, mostly having a specific pattern. Python\u2019s glob module has several functions that can help in listing files that match a given pattern under a specified folder. Pattern Rules Follow standard Unix path expansion rules. Special characters supported : two different wild-cards- *, ? and character ranges expressed in []. The pattern rules are applied to segments of the filename (stopping at the path separator, /). Paths in the pattern can be relative or absolute. Application It is useful in any situation where your program needs to look for a list of files on the file system with names matching a pattern. If you need a list of filenames that have a certain extension, prefix, or any common string in the middle, use glob instead of writing code to scan the directory contents yourself. import glob # search .py files # in the current working directory for py in glob . glob ( \"*.py\" ): print ( py ) import glob # Using character ranges [] print ( 'Finding file using character ranges [] :- ' ) print ( glob . glob ( './[0-9].*' )) # Using wildcard character * print ( ' \\n Finding file using wildcard character * :- ' ) print ( glob . glob ( '*.gif' )) # Using wildcard character ? print ( ' \\n Finding file using wildcard character ? :- ' ) print ( glob . glob ( '?.gif' )) # Using recursive attribute print ( ' \\n Finding files using recursive attribute :- ' ) print ( glob . glob ( '**/*.txt' , recursive = True )) Shutil Module: Filesystem Shell Methods import os from os import path import shutil from shutil import make_archive from zipfile import ZipFile # make a duplicate of an existing file if path . exists ( \"textfile.txt\" ): # get the path to the file in the current directory src = path . realpath ( \"textfile.txt\" ); # # let's make a backup copy by appending \"bak\" to the name dst = src + \".bak\" # # now use the shell to make a copy of the file shutil . copy ( src , dst ) # # copy over the permissions, modification times, and other info shutil . copystat ( src , dst ) # # rename the original file os . rename ( \"textfile.txt\" , \"newfile.txt\" ) # now put things into a ZIP archive root_dir , tail = path . split ( src ) shutil . make_archive ( \"archive\" , \"zip\" , root_dir ) # more fine-grained control over ZIP files with ZipFile ( \"testzip.zip\" , \"w\" ) as newzip : newzip . write ( \"newfile.txt\" ) newzip . write ( \"textfile.txt.bak\" ) PyFileSystem pip install fs pip show fs Name: fs Version: 2.4.14 Summary: Python's filesystem abstraction layer Home-page: https://github.com/PyFilesystem/pyfilesystem2 Author: Will McGugan Author-email: will@willmcgugan.com License: MIT Location: /usr/local/lib/python3.7/dist-packages Requires: appdirs, six, setuptools, pytz Required-by: # import the PyFilesystem library for OS files from fs.osfs import OSFS # TODO: open a local filesystem for the current directory with OSFS ( \".\" ) as myfs : if ( not myfs . exists ( \"testdir\" )): # create a sample data directory myfs . makedir ( \"testdir\" ) # create a file with myfs . open ( \"testdir/samplefile.txt\" , mode = 'w' ) as f : f . write ( \"This is some text\" ) # read the file contents with myfs . open ( \"testdir/samplefile.txt\" ) as f : content = f . read () print ( content ) # TODO: use the getinfo() function to return resource information info = myfs . getinfo ( \"testdir/samplefile.txt\" , namespaces = [ 'details' ]) print ( info . name ) print ( info . is_dir ) print ( info . size ) print ( info . type ) print ( info . modified ) samplefile.txt False 17 ResourceType.file 2021-12-23 04:09:10.571525+00:00 # TODO: try opening and reading a ZIP archive from fs.zipfs import ZipFS with ZipFS ( \"FileExamples.zip\" ) as thezip : if ( thezip . exists ( \"FileExamples/File1.txt\" )): with thezip . open ( \"FileExamples/File1.txt\" ) as f : content = f . read () print ( content ) from fs.osfs import OSFS # TODO: print a directory tree listing with OSFS ( \".\" ) as myfs : myfs . tree () |-- .config | |-- configurations | | `-- config_default | |-- logs | | `-- 2021.12.03 | | |-- 14.32.30.027140.log | | |-- 14.32.50.522723.log | | |-- 14.33.09.955489.log | | |-- 14.33.16.964195.log | | |-- 14.33.36.903459.log | | `-- 14.33.37.701606.log | |-- .last_opt_in_prompt.yaml | |-- .last_survey_prompt.yaml | |-- .last_update_check.json | |-- active_config | |-- config_sentinel | `-- gce |-- sample_data | |-- anscombe.json | |-- california_housing_test.csv | |-- california_housing_train.csv | |-- mnist_test.csv | |-- mnist_train_small.csv | `-- README.md `-- testdir `-- samplefile.txt # TODO: use directory operation functions # with OSFS(\".\") as myfs: # dirlist = myfs.listdir(\"testdir\") # print(dirlist) # with OSFS(\".\") as myfs: # dirlist = list(myfs.scandir(\"testdir\")) # print(dirlist) with OSFS ( \".\" ) as myfs : dirlist = list ( myfs . filterdir ( \"testdir\" , files = [ \"*.txt\" ])) print ( dirlist ) # TODO: Use resource info with scandir with OSFS ( \".\" ) as myfs : dirlist = myfs . scandir ( \"testdir\" , namespaces = [ \"details\" ]) for info in dirlist : print ( info . name , info . size ) # TODO: make a copy of a directory # with OSFS(\".\") as myfs: # myfs.copydir(\"testdir\", \"CopyOftestdir\", create=True) # TODO: remove a directory # with OSFS(\".\") as myfs: # if (myfs.exists(\"CopyOftestdir\")): # # myfs.removedir(\"CopyOftestdir\") # myfs.removetree(\"CopyOftestdir\") [<file 'samplefile.txt'>] samplefile.txt 17 # Example file for using the File System walker from fs.osfs import OSFS from fs.zipfs import ZipFS # create a basic file walker with OSFS ( \".\" ) as myfs : print ( \"-- Files --\" ) # TODO: use the files walker to process files for path in myfs . walk . files ( filter = [ \"*.txt\" ]): print ( path ) print ( \"-- Directories --\" ) # TODO: use the dirs walker for directories for path in myfs . walk . dirs (): print ( path ) # TODO: use the info property to step through items # with OSFS(\".\") as myfs: # for path, info in myfs.walk.info(namespaces=[\"details\"]): # print(path, info.is_dir, info.size) # TODO: Use the walk object by itself: # with OSFS(\"FileExamples\") as myfs: # for step in myfs.walk(): # print(step.path) # print(step.files) # print(step.dirs) # TODO: Use the walker with a ZIP # with ZipFS(\"FileExamples.zip\") as thezip: # print(\"-- Zip Contents --\") # for path in thezip.walk.files(): # print(path) -- Files -- /testdir/samplefile.txt -- Directories -- /.config /testdir /sample_data /.config/logs /.config/configurations /.config/logs/2021.12.03 from fs.osfs import OSFS # Challenge - figure out the total size of all text files in a folder structure totalsize = 0 # Create a file walker to walk the FileExamples directory with OSFS ( \".\" ) as myfs : # We need to specify the details namespace to get size info for path , info in myfs . walk . info ( namespaces = [ \"details\" ]): # Check for an ending extension of .txt if path . endswith ( \".txt\" ) and not info . is_dir : totalsize += info . size # print the final results print ( \"Total size of files is: {0} \" . format ( totalsize )) Total size of files is: 17 CSV IO # importing the csv module import csv # my data rows as dictionary objects mydict = [{ 'branch' : 'COE' , 'cgpa' : '9.0' , 'name' : 'Nikhil' , 'year' : '2' }, { 'branch' : 'COE' , 'cgpa' : '9.1' , 'name' : 'Sanchit' , 'year' : '2' }, { 'branch' : 'IT' , 'cgpa' : '9.3' , 'name' : 'Aditya' , 'year' : '2' }, { 'branch' : 'SE' , 'cgpa' : '9.5' , 'name' : 'Sagar' , 'year' : '1' }, { 'branch' : 'MCE' , 'cgpa' : '7.8' , 'name' : 'Prateek' , 'year' : '3' }, { 'branch' : 'EP' , 'cgpa' : '9.1' , 'name' : 'Sahil' , 'year' : '2' }] # field names fields = [ 'name' , 'branch' , 'year' , 'cgpa' ] # name of csv file filename = \"university_records.csv\" # writing to csv file with open ( filename , 'w' ) as csvfile : # creating a csv dict writer object writer = csv . DictWriter ( csvfile , fieldnames = fields ) # writing headers (field names) writer . writeheader () # writing data rows writer . writerows ( mydict ) # importing csv module import csv # csv file name filename = \"university_records.csv\" # initializing the titles and rows list fields = [] rows = [] # reading csv file with open ( filename , 'r' ) as csvfile : # creating a csv reader object csvreader = csv . reader ( csvfile ) # extracting field names through first row fields = next ( csvreader ) # extracting each data row one by one for row in csvreader : rows . append ( row ) # get total number of rows print ( \"Total no. of rows: %d \" % ( csvreader . line_num )) # printing the field names print ( 'Field names are:' + ', ' . join ( field for field in fields )) # printing first 5 rows print ( ' \\n First 5 rows are: \\n ' ) for row in rows [: 5 ]: # parsing each column of a row for col in row : print ( \" %10s \" % col ), print ( ' \\n ' ) Total no. of rows: 7 Field names are:name, branch, year, cgpa First 5 rows are: Nikhil COE 2 9.0 Sanchit COE 2 9.1 Aditya IT 2 9.3 Sagar SE 1 9.5 Prateek MCE 3 7.8","title":"IO & OS"},{"location":"lib/pyIO/#file-management","text":"","title":"File Management"},{"location":"lib/pyIO/#opening-files","text":"The argument of the open function is the path to the file. If the file is in the current working directory of the program, you can specify only its name. You can specify the mode used to open a file by applying a second argument to the open function. Sending \"r\" means open in read mode, which is the default. Sending \"w\" means write mode, for rewriting the contents of a file. Sending \"a\" means append mode, for adding new content to the end of the file. Adding \"b\" to a mode opens it in binary mode, which is used for non-text files (such as image and sound files). Once a file has been opened and used, you should close it. This is done with the close method of the file object.","title":"Opening Files"},{"location":"lib/pyIO/#reading-files","text":"file.read(): returns all the contents file.readlines():To retrieve each line in a file, you can use the readlines method to return a list in which each element is a line in the file.","title":"Reading Files"},{"location":"lib/pyIO/#writing-files","text":"To write to files you use the write method The write method returns the number of bytes written to a file, if successful. try : myfile = open ( \"filename.txt\" , 'r+' ) #mode read and write #read all content cont = myfile . read () myfile . write ( \"New line to insert in file\" ) print ( cont ) finally : myfile . close () myfile = open ( \"textfile.txt\" , 'r+' ) #mode read and write #print each line for line in myfile : print ( line . rstrip ()) myfile . close () This is line 1 This is line 2 This is line 3 This is line 4 This is line 5 This is line 6 This is line 7 This is line 8 This is line 9 This is line 10 An alternative way of doing this is using with statements. This creates a temporary variable (often called f), which is only accessible in the indented block of the with statement. The file is automatically closed at the end of the with statement, even if exceptions occur within it. with open ( \"filename.txt\" ) as f : print ( f . read ()) # Open a file for writing and create it if it doesn't exist f = open ( \"textfile.txt\" , \"w+\" ) # Open the file for appending text to the end # f = open(\"textfile.txt\",\"a+\") # write some lines of data to the file for i in range ( 10 ): f . write ( \"This is line %d \\r\\n \" % ( i + 1 )) # close the file when done f . close () # Open the file back up and read the contents f = open ( \"textfile.txt\" , \"r\" ) if f . mode == 'r' : # check to make sure that the file was opened # use the read() function to read the entire file # contents = f.read() # print (contents) fl = f . readlines () # readlines reads the individual lines into a list for x in fl : print ( x ) This is line 1 This is line 2 This is line 3 This is line 4 This is line 5 This is line 6 This is line 7 This is line 8 This is line 9 This is line 10","title":"Writing Files"},{"location":"lib/pyIO/#fast-inputoutput","text":"# Program to show time taken in fast # I / O and normal I / O in python from sys import stdin , stdout import time # Function for fast I / O def fastIO (): # Stores the start time start = time . perf_counter () # To read single integer n = stdin . readline () # To input array arr = [ int ( x ) for x in stdin . readline () . split ()] # Output integer stdout . write ( str ( n )) # Output array stdout . write ( \" \" . join ( map ( str , arr )) + \" \\n \" ) # Stores the end time end = time . perf_counter () print ( \"Time taken in fast IO\" , end - start ) # Function for normal I / O def normalIO (): # Stores the start time start = time . perf_counter () # Input integer n = int ( input ()) # Input array arr = [ int ( x ) for x in input () . split ()] # Output integer print ( n ) # Output array for i in arr : print ( i , end = \" \" ) print () # Stores the end time end = time . perf_counter () print ( \"Time taken in normal IO: \" , end - start ) # Driver Code if __name__ == '__main__' : fastIO () normalIO () Time taken in fast IO 0.001823046999994915 23 23 23 23 Time taken in normal IO: 5.173487307000002","title":"Fast Input/Output"},{"location":"lib/pyIO/#os-path-module","text":"import os from os import path import datetime from datetime import date , time , timedelta import time # Print the name of the OS print ( os . name ) # Check for item existence and type print ( \"Item exists: \" , path . exists ( \"textfile.txt\" )) print ( \"Item is a file: \" , path . isfile ( \"textfile.txt\" )) print ( \"Item is a directory: \" , path . isdir ( \"textfile.txt\" )) # Work with file paths print ( \"Item's path: \" , path . realpath ( \"textfile.txt\" )) print ( \"Item's path and name: \" , path . split ( path . realpath ( \"textfile.txt\" ))) # Get the modification time t = time . ctime ( path . getmtime ( \"textfile.txt\" )) print ( t ) print ( datetime . datetime . fromtimestamp ( path . getmtime ( \"textfile.txt\" ))) # Calculate how long ago the item was modified td = datetime . datetime . now () - datetime . datetime . fromtimestamp ( path . getmtime ( \"textfile.txt\" )) print ( \"It has been \" + str ( td ) + \" since the file was modified\" ) print ( \"Or, \" + str ( td . total_seconds ()) + \" seconds\" ) posix Item exists: True Item is a file: True Item is a directory: False Item's path: /content/textfile.txt Item's path and name: ('/content', 'textfile.txt') Mon Jul 19 14:31:57 2021 2021-07-19 14:31:57.728190 It has been 0:06:55.454337 since the file was modified Or, 415.454337 seconds","title":"OS Path Module"},{"location":"lib/pyIO/#glob-module","text":"Glob module searches all path names looking for files matching a specified pattern according to the rules dictated by the Unix shell. Results so obtained are returned in arbitrary order. Some requirements need traversal through a list of files at some location, mostly having a specific pattern. Python\u2019s glob module has several functions that can help in listing files that match a given pattern under a specified folder.","title":"GLOB Module"},{"location":"lib/pyIO/#pattern-rules","text":"Follow standard Unix path expansion rules. Special characters supported : two different wild-cards- *, ? and character ranges expressed in []. The pattern rules are applied to segments of the filename (stopping at the path separator, /). Paths in the pattern can be relative or absolute.","title":"Pattern Rules"},{"location":"lib/pyIO/#application","text":"It is useful in any situation where your program needs to look for a list of files on the file system with names matching a pattern. If you need a list of filenames that have a certain extension, prefix, or any common string in the middle, use glob instead of writing code to scan the directory contents yourself. import glob # search .py files # in the current working directory for py in glob . glob ( \"*.py\" ): print ( py ) import glob # Using character ranges [] print ( 'Finding file using character ranges [] :- ' ) print ( glob . glob ( './[0-9].*' )) # Using wildcard character * print ( ' \\n Finding file using wildcard character * :- ' ) print ( glob . glob ( '*.gif' )) # Using wildcard character ? print ( ' \\n Finding file using wildcard character ? :- ' ) print ( glob . glob ( '?.gif' )) # Using recursive attribute print ( ' \\n Finding files using recursive attribute :- ' ) print ( glob . glob ( '**/*.txt' , recursive = True ))","title":"Application"},{"location":"lib/pyIO/#shutil-module-filesystem-shell-methods","text":"import os from os import path import shutil from shutil import make_archive from zipfile import ZipFile # make a duplicate of an existing file if path . exists ( \"textfile.txt\" ): # get the path to the file in the current directory src = path . realpath ( \"textfile.txt\" ); # # let's make a backup copy by appending \"bak\" to the name dst = src + \".bak\" # # now use the shell to make a copy of the file shutil . copy ( src , dst ) # # copy over the permissions, modification times, and other info shutil . copystat ( src , dst ) # # rename the original file os . rename ( \"textfile.txt\" , \"newfile.txt\" ) # now put things into a ZIP archive root_dir , tail = path . split ( src ) shutil . make_archive ( \"archive\" , \"zip\" , root_dir ) # more fine-grained control over ZIP files with ZipFile ( \"testzip.zip\" , \"w\" ) as newzip : newzip . write ( \"newfile.txt\" ) newzip . write ( \"textfile.txt.bak\" )","title":"Shutil Module: Filesystem Shell Methods"},{"location":"lib/pyIO/#pyfilesystem","text":"pip install fs pip show fs Name: fs Version: 2.4.14 Summary: Python's filesystem abstraction layer Home-page: https://github.com/PyFilesystem/pyfilesystem2 Author: Will McGugan Author-email: will@willmcgugan.com License: MIT Location: /usr/local/lib/python3.7/dist-packages Requires: appdirs, six, setuptools, pytz Required-by: # import the PyFilesystem library for OS files from fs.osfs import OSFS # TODO: open a local filesystem for the current directory with OSFS ( \".\" ) as myfs : if ( not myfs . exists ( \"testdir\" )): # create a sample data directory myfs . makedir ( \"testdir\" ) # create a file with myfs . open ( \"testdir/samplefile.txt\" , mode = 'w' ) as f : f . write ( \"This is some text\" ) # read the file contents with myfs . open ( \"testdir/samplefile.txt\" ) as f : content = f . read () print ( content ) # TODO: use the getinfo() function to return resource information info = myfs . getinfo ( \"testdir/samplefile.txt\" , namespaces = [ 'details' ]) print ( info . name ) print ( info . is_dir ) print ( info . size ) print ( info . type ) print ( info . modified ) samplefile.txt False 17 ResourceType.file 2021-12-23 04:09:10.571525+00:00 # TODO: try opening and reading a ZIP archive from fs.zipfs import ZipFS with ZipFS ( \"FileExamples.zip\" ) as thezip : if ( thezip . exists ( \"FileExamples/File1.txt\" )): with thezip . open ( \"FileExamples/File1.txt\" ) as f : content = f . read () print ( content ) from fs.osfs import OSFS # TODO: print a directory tree listing with OSFS ( \".\" ) as myfs : myfs . tree () |-- .config | |-- configurations | | `-- config_default | |-- logs | | `-- 2021.12.03 | | |-- 14.32.30.027140.log | | |-- 14.32.50.522723.log | | |-- 14.33.09.955489.log | | |-- 14.33.16.964195.log | | |-- 14.33.36.903459.log | | `-- 14.33.37.701606.log | |-- .last_opt_in_prompt.yaml | |-- .last_survey_prompt.yaml | |-- .last_update_check.json | |-- active_config | |-- config_sentinel | `-- gce |-- sample_data | |-- anscombe.json | |-- california_housing_test.csv | |-- california_housing_train.csv | |-- mnist_test.csv | |-- mnist_train_small.csv | `-- README.md `-- testdir `-- samplefile.txt # TODO: use directory operation functions # with OSFS(\".\") as myfs: # dirlist = myfs.listdir(\"testdir\") # print(dirlist) # with OSFS(\".\") as myfs: # dirlist = list(myfs.scandir(\"testdir\")) # print(dirlist) with OSFS ( \".\" ) as myfs : dirlist = list ( myfs . filterdir ( \"testdir\" , files = [ \"*.txt\" ])) print ( dirlist ) # TODO: Use resource info with scandir with OSFS ( \".\" ) as myfs : dirlist = myfs . scandir ( \"testdir\" , namespaces = [ \"details\" ]) for info in dirlist : print ( info . name , info . size ) # TODO: make a copy of a directory # with OSFS(\".\") as myfs: # myfs.copydir(\"testdir\", \"CopyOftestdir\", create=True) # TODO: remove a directory # with OSFS(\".\") as myfs: # if (myfs.exists(\"CopyOftestdir\")): # # myfs.removedir(\"CopyOftestdir\") # myfs.removetree(\"CopyOftestdir\") [<file 'samplefile.txt'>] samplefile.txt 17 # Example file for using the File System walker from fs.osfs import OSFS from fs.zipfs import ZipFS # create a basic file walker with OSFS ( \".\" ) as myfs : print ( \"-- Files --\" ) # TODO: use the files walker to process files for path in myfs . walk . files ( filter = [ \"*.txt\" ]): print ( path ) print ( \"-- Directories --\" ) # TODO: use the dirs walker for directories for path in myfs . walk . dirs (): print ( path ) # TODO: use the info property to step through items # with OSFS(\".\") as myfs: # for path, info in myfs.walk.info(namespaces=[\"details\"]): # print(path, info.is_dir, info.size) # TODO: Use the walk object by itself: # with OSFS(\"FileExamples\") as myfs: # for step in myfs.walk(): # print(step.path) # print(step.files) # print(step.dirs) # TODO: Use the walker with a ZIP # with ZipFS(\"FileExamples.zip\") as thezip: # print(\"-- Zip Contents --\") # for path in thezip.walk.files(): # print(path) -- Files -- /testdir/samplefile.txt -- Directories -- /.config /testdir /sample_data /.config/logs /.config/configurations /.config/logs/2021.12.03 from fs.osfs import OSFS # Challenge - figure out the total size of all text files in a folder structure totalsize = 0 # Create a file walker to walk the FileExamples directory with OSFS ( \".\" ) as myfs : # We need to specify the details namespace to get size info for path , info in myfs . walk . info ( namespaces = [ \"details\" ]): # Check for an ending extension of .txt if path . endswith ( \".txt\" ) and not info . is_dir : totalsize += info . size # print the final results print ( \"Total size of files is: {0} \" . format ( totalsize )) Total size of files is: 17","title":"PyFileSystem"},{"location":"lib/pyIO/#csv-io","text":"# importing the csv module import csv # my data rows as dictionary objects mydict = [{ 'branch' : 'COE' , 'cgpa' : '9.0' , 'name' : 'Nikhil' , 'year' : '2' }, { 'branch' : 'COE' , 'cgpa' : '9.1' , 'name' : 'Sanchit' , 'year' : '2' }, { 'branch' : 'IT' , 'cgpa' : '9.3' , 'name' : 'Aditya' , 'year' : '2' }, { 'branch' : 'SE' , 'cgpa' : '9.5' , 'name' : 'Sagar' , 'year' : '1' }, { 'branch' : 'MCE' , 'cgpa' : '7.8' , 'name' : 'Prateek' , 'year' : '3' }, { 'branch' : 'EP' , 'cgpa' : '9.1' , 'name' : 'Sahil' , 'year' : '2' }] # field names fields = [ 'name' , 'branch' , 'year' , 'cgpa' ] # name of csv file filename = \"university_records.csv\" # writing to csv file with open ( filename , 'w' ) as csvfile : # creating a csv dict writer object writer = csv . DictWriter ( csvfile , fieldnames = fields ) # writing headers (field names) writer . writeheader () # writing data rows writer . writerows ( mydict ) # importing csv module import csv # csv file name filename = \"university_records.csv\" # initializing the titles and rows list fields = [] rows = [] # reading csv file with open ( filename , 'r' ) as csvfile : # creating a csv reader object csvreader = csv . reader ( csvfile ) # extracting field names through first row fields = next ( csvreader ) # extracting each data row one by one for row in csvreader : rows . append ( row ) # get total number of rows print ( \"Total no. of rows: %d \" % ( csvreader . line_num )) # printing the field names print ( 'Field names are:' + ', ' . join ( field for field in fields )) # printing first 5 rows print ( ' \\n First 5 rows are: \\n ' ) for row in rows [: 5 ]: # parsing each column of a row for col in row : print ( \" %10s \" % col ), print ( ' \\n ' ) Total no. of rows: 7 Field names are:name, branch, year, cgpa First 5 rows are: Nikhil COE 2 9.0 Sanchit COE 2 9.1 Aditya IT 2 9.3 Sagar SE 1 9.5 Prateek MCE 3 7.8","title":"CSV IO"},{"location":"lib/pyIter/","text":"The module itertools is a standard library that contains several functions that are useful in functional programming. Advanced iteration functions capabilities for: Infinite iterators Iterators terminating on the shortest input sequence Combinatoric iterators Infinite iterators Iterator Arguments Syntax Example count() start, [step] start, start+step, start+2*step, \u2026 count(10) --> 10 11 12 13 14 ... cycle() p p0, p1, \u2026 plast, p0, p1, \u2026 cycle('ABCD') --> A B C D A B C D ... repeat() elem [,n] elem, elem, elem, \u2026 endlessly or up to n times repeat(10, 3) --> 10 10 10 The function count() counts up infinitely from a value. from itertools import count for i in count ( 3 ): print ( i ) if i >= 11 : break 3 4 5 6 7 8 9 10 11 import itertools # use count to create a simple counter count1 = itertools . count ( 100 , 10 ) print ( next ( count1 )) print ( next ( count1 )) print ( next ( count1 )) 100 110 120 The function cycle() infinitely iterates through an iterable (for instance a list or string). import itertools # cycle iterator can be used to cycle over a collection seq1 = [ \"Joe\" , \"John\" , \"Mike\" ] cycle1 = itertools . cycle ( seq1 ) print ( next ( cycle1 )) print ( next ( cycle1 )) print ( next ( cycle1 )) print ( next ( cycle1 )) Joe John Mike Joe The function repeat() repeats an object, either infinitely or a specific number of times. A common use for repeat is to supply a stream of constant values to map or zip list ( map ( pow , range ( 10 ), itertools . repeat ( 2 ))) [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] Iterators terminating on the shortest input sequence All list Iterator Arguments Syntax Example accumulate() p [,func] p0, p0+p1, p0+p1+p2, \u2026 accumulate([1,2,3,4,5]) --> 1 3 6 10 15 dropwhile() pred, seq seq[n], seq[n+1], starting when pred fails dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1 takewhile() pred, seq seq[0], seq[1], until pred fails takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4 chain() p, q, \u2026 p0, p1, \u2026 plast, q0, q1, \u2026 chain('ABC', 'DEF') --> A B C D E F chain.from_iterable() iterable p0, p1, \u2026 plast, q0, q1, \u2026 chain.from_iterable(['ABC', 'DEF']) --> A B C D E F groupby() iterable[, key] sub-iterators grouped by value of key(v) zip_longest() p, q, \u2026 (p[0], q[0]), (p[1], q[1]), \u2026 zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D- compress() data, selectors (d[0] if s[0]), (d[1] if s[1]), \u2026 compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F filterfalse() pred, seq elements of seq where pred(elem) is false filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8 islice() seq, [start,] stop [, step] elements from seq[start:stop:step] islice('ABCDEFG', 2, None) --> C D E F G pairwise() iterable (p[0], p[1]), (p[1], p[2]) pairwise('ABCDEFG') --> AB BC CD DE EF FG starmap() func, seq func( seq[0]), func( seq[1]), \u2026 starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000 tee() it, n it1, it2, \u2026 itn splits one iterator into n accumulate() - returns a running total of values in an iterable from itertools import accumulate nums = list ( accumulate ( range ( 8 ))) print ( nums ) [0, 1, 3, 6, 10, 15, 21, 28] # accumulate creates an iterator that accumulates values vals = [ 10 , 20 , 30 , 40 , 50 , 40 , 30 ] acc = itertools . accumulate ( vals , max ) print ( list ( acc )) [10, 20, 30, 40, 50, 50, 50] takewhile() - takes items from an iterable while a predicate function remains true from itertools import accumulate , takewhile nums = list ( accumulate ( range ( 8 ))) print ( nums ) print ( list ( takewhile ( lambda x : x <= 6 , nums ))) [0, 1, 3, 6, 10, 15, 21, 28] [0, 1, 3, 6] dropwhile() - drops elements from the iterable as long as the predicate is true # advanced iteration functions in the itertools package import itertools def testFunction ( x ): return x < 40 def main (): # dropwhile and takewhile will return values until # a certain condition is met that stops them print ( list ( itertools . dropwhile ( testFunction , vals ))) print ( list ( itertools . takewhile ( testFunction , vals ))) if __name__ == \"__main__\" : main () [40, 50, 40, 30] [10, 20, 30] chain() - combines several iterables into one long one # advanced iteration functions in the itertools package import itertools def main (): # use chain to connect sequences together x = itertools . chain ( \"ABCD\" , \"1234\" ) print ( list ( x )) if __name__ == \"__main__\" : main () ['A', 'B', 'C', 'D', '1', '2', '3', '4'] Combinatoric iterators Product : cartesian product, equivalent to a nested for-loop print ( list ( itertools . product ( 'ABC' , repeat = 2 ))) [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] Permutations : r-length tuples, all possible orderings, no repeated elements print ( list ( itertools . permutations ( 'ABC' , 2 ))) [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')] from itertools import product , permutations letters = ( \"A\" , \"B\" ) print ( list ( product ( letters , range ( 2 )))) print ( list ( permutations ( letters ))) [('A', 0), ('A', 1), ('B', 0), ('B', 1)] [('A', 'B'), ('B', 'A')] Combinations : r-length tuples, in sorted order, no repeated elements print ( list ( itertools . combinations ( 'ABC' , 2 ))) [('A', 'B'), ('A', 'C'), ('B', 'C')] combinations_with_replacement : r-length tuples, in sorted order, with repeated elements print ( list ( itertools . combinations_with_replacement ( 'ABC' , 2 ))) [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')]","title":"Itertools"},{"location":"lib/pyIter/#infinite-iterators","text":"Iterator Arguments Syntax Example count() start, [step] start, start+step, start+2*step, \u2026 count(10) --> 10 11 12 13 14 ... cycle() p p0, p1, \u2026 plast, p0, p1, \u2026 cycle('ABCD') --> A B C D A B C D ... repeat() elem [,n] elem, elem, elem, \u2026 endlessly or up to n times repeat(10, 3) --> 10 10 10 The function count() counts up infinitely from a value. from itertools import count for i in count ( 3 ): print ( i ) if i >= 11 : break 3 4 5 6 7 8 9 10 11 import itertools # use count to create a simple counter count1 = itertools . count ( 100 , 10 ) print ( next ( count1 )) print ( next ( count1 )) print ( next ( count1 )) 100 110 120 The function cycle() infinitely iterates through an iterable (for instance a list or string). import itertools # cycle iterator can be used to cycle over a collection seq1 = [ \"Joe\" , \"John\" , \"Mike\" ] cycle1 = itertools . cycle ( seq1 ) print ( next ( cycle1 )) print ( next ( cycle1 )) print ( next ( cycle1 )) print ( next ( cycle1 )) Joe John Mike Joe The function repeat() repeats an object, either infinitely or a specific number of times. A common use for repeat is to supply a stream of constant values to map or zip list ( map ( pow , range ( 10 ), itertools . repeat ( 2 ))) [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]","title":"Infinite iterators"},{"location":"lib/pyIter/#iterators-terminating-on-the-shortest-input-sequence","text":"All list Iterator Arguments Syntax Example accumulate() p [,func] p0, p0+p1, p0+p1+p2, \u2026 accumulate([1,2,3,4,5]) --> 1 3 6 10 15 dropwhile() pred, seq seq[n], seq[n+1], starting when pred fails dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1 takewhile() pred, seq seq[0], seq[1], until pred fails takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4 chain() p, q, \u2026 p0, p1, \u2026 plast, q0, q1, \u2026 chain('ABC', 'DEF') --> A B C D E F chain.from_iterable() iterable p0, p1, \u2026 plast, q0, q1, \u2026 chain.from_iterable(['ABC', 'DEF']) --> A B C D E F groupby() iterable[, key] sub-iterators grouped by value of key(v) zip_longest() p, q, \u2026 (p[0], q[0]), (p[1], q[1]), \u2026 zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D- compress() data, selectors (d[0] if s[0]), (d[1] if s[1]), \u2026 compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F filterfalse() pred, seq elements of seq where pred(elem) is false filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8 islice() seq, [start,] stop [, step] elements from seq[start:stop:step] islice('ABCDEFG', 2, None) --> C D E F G pairwise() iterable (p[0], p[1]), (p[1], p[2]) pairwise('ABCDEFG') --> AB BC CD DE EF FG starmap() func, seq func( seq[0]), func( seq[1]), \u2026 starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000 tee() it, n it1, it2, \u2026 itn splits one iterator into n accumulate() - returns a running total of values in an iterable from itertools import accumulate nums = list ( accumulate ( range ( 8 ))) print ( nums ) [0, 1, 3, 6, 10, 15, 21, 28] # accumulate creates an iterator that accumulates values vals = [ 10 , 20 , 30 , 40 , 50 , 40 , 30 ] acc = itertools . accumulate ( vals , max ) print ( list ( acc )) [10, 20, 30, 40, 50, 50, 50] takewhile() - takes items from an iterable while a predicate function remains true from itertools import accumulate , takewhile nums = list ( accumulate ( range ( 8 ))) print ( nums ) print ( list ( takewhile ( lambda x : x <= 6 , nums ))) [0, 1, 3, 6, 10, 15, 21, 28] [0, 1, 3, 6] dropwhile() - drops elements from the iterable as long as the predicate is true # advanced iteration functions in the itertools package import itertools def testFunction ( x ): return x < 40 def main (): # dropwhile and takewhile will return values until # a certain condition is met that stops them print ( list ( itertools . dropwhile ( testFunction , vals ))) print ( list ( itertools . takewhile ( testFunction , vals ))) if __name__ == \"__main__\" : main () [40, 50, 40, 30] [10, 20, 30] chain() - combines several iterables into one long one # advanced iteration functions in the itertools package import itertools def main (): # use chain to connect sequences together x = itertools . chain ( \"ABCD\" , \"1234\" ) print ( list ( x )) if __name__ == \"__main__\" : main () ['A', 'B', 'C', 'D', '1', '2', '3', '4']","title":"Iterators terminating on the shortest input sequence"},{"location":"lib/pyIter/#combinatoric-iterators","text":"Product : cartesian product, equivalent to a nested for-loop print ( list ( itertools . product ( 'ABC' , repeat = 2 ))) [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] Permutations : r-length tuples, all possible orderings, no repeated elements print ( list ( itertools . permutations ( 'ABC' , 2 ))) [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')] from itertools import product , permutations letters = ( \"A\" , \"B\" ) print ( list ( product ( letters , range ( 2 )))) print ( list ( permutations ( letters ))) [('A', 0), ('A', 1), ('B', 0), ('B', 1)] [('A', 'B'), ('B', 'A')] Combinations : r-length tuples, in sorted order, no repeated elements print ( list ( itertools . combinations ( 'ABC' , 2 ))) [('A', 'B'), ('A', 'C'), ('B', 'C')] combinations_with_replacement : r-length tuples, in sorted order, with repeated elements print ( list ( itertools . combinations_with_replacement ( 'ABC' , 2 ))) [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')]","title":"Combinatoric iterators"},{"location":"lib/pyMemP/","text":"Managing memory is important in any programming logic but this becomes necessary for python. As python is used in Ml and AI where vast data are used which needs to be managed. Memory leaks, i.e. the program is out of memory after running for several hours. To manage these memory leaks memory monitoring is essential. Monitoring memory is also called profiling. As a developer, it\u2019s a necessity that we profile our program and use less memory allocation as much as possible. Using Tracemalloc Tracemalloc is a library module that traces every memory block in python. The tracing starts by using the start() during runtime. This library module can also give information about the total size, number, and average size of allocated memory blocks. # importing the module import tracemalloc # code or function for which memory # has to be monitored def app (): lt = [] for i in range ( 0 , 100000 ): lt . append ( i ) # starting the monitoring tracemalloc . start () # function call app () # displaying the memory print ( tracemalloc . get_traced_memory ()) # stopping the library tracemalloc . stop () (729, 3617551) The output is given in form of (current, peak), i.e. current memory is the memory the code is currently using and peak memory is the maximum space the program used while executing. Using Psutil Psutil is a python system library used to keep track of various resources in the system and their utilization. The library is used for profiling, limiting, and management of process resources. import os import psutil p = psutil . Process ( os . getpid ()) for i in range ( 10 ): print ( i ) for j in range ( 5 ): mem_usage = p . memory_info () . rss / 1024 / 1024 print ( \" {} {} MB\" . format ( j , mem_usage )) def memory_usage_psutil (): # return the memory usage in MB import psutil process = psutil . Process ( os . getpid ()) mem = process . get_memory_info ()[ 0 ] / float ( 2 ** 20 ) return mem The above function returns the memory usage of the current Python process in MiB. Depending on the platform it will choose the most accurate and fastest way to get this information. For example, in Windows it will use the C++ Win32 API while in Linux it will read from /proc, hiding the implementation details and proving on each platform a fast and accurate measurement. If you are looking for an easy way to get the memory consumption within Python this in my opinion your best shot. Using Memory Profiler ! pip install memory - profiler Notice the @profile this is a decorator. Any function which is decorated by this decorator, that function will be tracked. %% file sos . py \"\"\"memory_profiler example\"\"\" @profile def sum_of_diffs ( vals ): \"\"\"Compute sum of diffs\"\"\" vals2 = vals [ 1 :] total = 0 for v1 , v2 in zip ( vals , vals2 ): total += v2 - v1 return total if __name__ == '__main__' : vals = list ( range ( 1 , 1_000_000 , 3 )) print ( sum_of_diffs ( vals )) Writing sos.py ! python - m memory_profiler sos 999996 Filename: /content/sos.py Line # Mem usage Increment Occurrences Line Contents ============================================================= 3 52.160 MiB 52.160 MiB 1 @profile 4 def sum_of_diffs(vals): 5 \"\"\"Compute sum of diffs\"\"\" 6 54.738 MiB 2.578 MiB 1 vals2 = vals[1:] 7 8 54.738 MiB 0.000 MiB 1 total = 0 9 54.738 MiB 0.000 MiB 333333 for v1, v2 in zip(vals, vals2): 10 54.738 MiB 0.000 MiB 333332 total += v2 - v1 11 12 54.738 MiB 0.000 MiB 1 return total %% file sos1 . py \"\"\"memory_profiler example\"\"\" def sum_of_diffs ( vals ): \"\"\"Compute sum of diffs\"\"\" vals2 = vals [ 1 :] total = 0 for v1 , v2 in zip ( vals , vals2 ): total += v2 - v1 return total if __name__ == '__main__' : vals = list ( range ( 1 , 100_000_000 , 3 )) print ( sum_of_diffs ( vals )) Writing sos1.py mprof generates profile data ! mprof run sos1 . py mprof: Sampling memory every 0.1s running new process running as a Python program... 99999996 ! mprof plot mprofile_20211225174100 . dat <Figure size 1260x540 with 1 Axes> Reducing Memory Consumption with Slots Slots in Python is a special mechanism that is used to reduce memory of the objects. In Python, all the objects use a dynamic dictionary for adding an attribute. Slots is a static type method in this no dynamic dictionary are required for allocating attribute. # defining the class. class myCourse : # defining the slots. __slots__ = ( 'course' , 'price' ) def __init__ ( self ): # initializing the values self . course = 'MAth' self . price = 300 # create an object of gfg class a = myCourse () # print the slot print ( a . __slots__ ) # print the slot variable print ( a . course , a . price ) ('course', 'price') MAth 300 When we create objects for classes, it requires memory and the attribute are stored in the form of a dictionary. In case if we need to allocate thousands of objects, it will take a lot of memory space. slots provide a special mechanism to reduce the size of objects.It is a concept of memory optimisation on objects. As every object in Python contains a dynamic dictionary that allows adding attributes. For every instance object, we will have an instance of a dictionary that consumes more space and wastes a lot of RAM. In Python, there is no default functionality to allocate a static amount of memory while creating the object to store all its attributes. Usage of slots reduce the wastage of space and speed up the program by allocating space for a fixed amount of attributes. #Example of python object without slots class MFT ( object ): def __init__ ( self , * args , ** kwargs ): self . a = 1 self . b = 2 if __name__ == \"__main__\" : instance = MFT () print ( instance . __dict__ ) {'a': 1, 'b': 2} #Example of python object with slots class MFT ( object ): __slots__ = [ 'a' , 'b' ] def __init__ ( self , * args , ** kwargs ): self . a = 1 self . b = 2 if __name__ == \"__main__\" : instance = MFT () print ( instance . __slots__ ) ['a', 'b'] Result of using slots: Fast access to attributes Saves memory space","title":"Memory Profiling"},{"location":"lib/pyMemP/#using-tracemalloc","text":"Tracemalloc is a library module that traces every memory block in python. The tracing starts by using the start() during runtime. This library module can also give information about the total size, number, and average size of allocated memory blocks. # importing the module import tracemalloc # code or function for which memory # has to be monitored def app (): lt = [] for i in range ( 0 , 100000 ): lt . append ( i ) # starting the monitoring tracemalloc . start () # function call app () # displaying the memory print ( tracemalloc . get_traced_memory ()) # stopping the library tracemalloc . stop () (729, 3617551) The output is given in form of (current, peak), i.e. current memory is the memory the code is currently using and peak memory is the maximum space the program used while executing.","title":"Using Tracemalloc"},{"location":"lib/pyMemP/#using-psutil","text":"Psutil is a python system library used to keep track of various resources in the system and their utilization. The library is used for profiling, limiting, and management of process resources. import os import psutil p = psutil . Process ( os . getpid ()) for i in range ( 10 ): print ( i ) for j in range ( 5 ): mem_usage = p . memory_info () . rss / 1024 / 1024 print ( \" {} {} MB\" . format ( j , mem_usage )) def memory_usage_psutil (): # return the memory usage in MB import psutil process = psutil . Process ( os . getpid ()) mem = process . get_memory_info ()[ 0 ] / float ( 2 ** 20 ) return mem The above function returns the memory usage of the current Python process in MiB. Depending on the platform it will choose the most accurate and fastest way to get this information. For example, in Windows it will use the C++ Win32 API while in Linux it will read from /proc, hiding the implementation details and proving on each platform a fast and accurate measurement. If you are looking for an easy way to get the memory consumption within Python this in my opinion your best shot.","title":"Using Psutil"},{"location":"lib/pyMemP/#using-memory-profiler","text":"! pip install memory - profiler Notice the @profile this is a decorator. Any function which is decorated by this decorator, that function will be tracked. %% file sos . py \"\"\"memory_profiler example\"\"\" @profile def sum_of_diffs ( vals ): \"\"\"Compute sum of diffs\"\"\" vals2 = vals [ 1 :] total = 0 for v1 , v2 in zip ( vals , vals2 ): total += v2 - v1 return total if __name__ == '__main__' : vals = list ( range ( 1 , 1_000_000 , 3 )) print ( sum_of_diffs ( vals )) Writing sos.py ! python - m memory_profiler sos 999996 Filename: /content/sos.py Line # Mem usage Increment Occurrences Line Contents ============================================================= 3 52.160 MiB 52.160 MiB 1 @profile 4 def sum_of_diffs(vals): 5 \"\"\"Compute sum of diffs\"\"\" 6 54.738 MiB 2.578 MiB 1 vals2 = vals[1:] 7 8 54.738 MiB 0.000 MiB 1 total = 0 9 54.738 MiB 0.000 MiB 333333 for v1, v2 in zip(vals, vals2): 10 54.738 MiB 0.000 MiB 333332 total += v2 - v1 11 12 54.738 MiB 0.000 MiB 1 return total %% file sos1 . py \"\"\"memory_profiler example\"\"\" def sum_of_diffs ( vals ): \"\"\"Compute sum of diffs\"\"\" vals2 = vals [ 1 :] total = 0 for v1 , v2 in zip ( vals , vals2 ): total += v2 - v1 return total if __name__ == '__main__' : vals = list ( range ( 1 , 100_000_000 , 3 )) print ( sum_of_diffs ( vals )) Writing sos1.py mprof generates profile data ! mprof run sos1 . py mprof: Sampling memory every 0.1s running new process running as a Python program... 99999996 ! mprof plot mprofile_20211225174100 . dat <Figure size 1260x540 with 1 Axes>","title":"Using Memory Profiler"},{"location":"lib/pyMemP/#reducing-memory-consumption-with-slots","text":"Slots in Python is a special mechanism that is used to reduce memory of the objects. In Python, all the objects use a dynamic dictionary for adding an attribute. Slots is a static type method in this no dynamic dictionary are required for allocating attribute. # defining the class. class myCourse : # defining the slots. __slots__ = ( 'course' , 'price' ) def __init__ ( self ): # initializing the values self . course = 'MAth' self . price = 300 # create an object of gfg class a = myCourse () # print the slot print ( a . __slots__ ) # print the slot variable print ( a . course , a . price ) ('course', 'price') MAth 300 When we create objects for classes, it requires memory and the attribute are stored in the form of a dictionary. In case if we need to allocate thousands of objects, it will take a lot of memory space. slots provide a special mechanism to reduce the size of objects.It is a concept of memory optimisation on objects. As every object in Python contains a dynamic dictionary that allows adding attributes. For every instance object, we will have an instance of a dictionary that consumes more space and wastes a lot of RAM. In Python, there is no default functionality to allocate a static amount of memory while creating the object to store all its attributes. Usage of slots reduce the wastage of space and speed up the program by allocating space for a fixed amount of attributes. #Example of python object without slots class MFT ( object ): def __init__ ( self , * args , ** kwargs ): self . a = 1 self . b = 2 if __name__ == \"__main__\" : instance = MFT () print ( instance . __dict__ ) {'a': 1, 'b': 2} #Example of python object with slots class MFT ( object ): __slots__ = [ 'a' , 'b' ] def __init__ ( self , * args , ** kwargs ): self . a = 1 self . b = 2 if __name__ == \"__main__\" : instance = MFT () print ( instance . __slots__ ) ['a', 'b'] Result of using slots: Fast access to attributes Saves memory space","title":"Reducing Memory Consumption with Slots"},{"location":"lib/pyPack/","text":"In Python, the term packaging refers to putting modules you have written in a standard format, so that other programmers can install and use them with ease. This involves use of the modules setuptools and distutils . The first step in packaging is to organize existing files correctly. Place all of the files you want to put in a library in the same parent directory. This directory should also contain a file called __init__.py, which can be blank but must be present in the directory. This directory goes into another directory containing the readme and license, as well as an important file called setup.py. example/ LICENSE.txt README.txt setup.py example/ __init__.py example.py example2.py The next step in packaging is to write the setup.py file. This contains information necessary to assemble the package so it can be uploaded to PyPI and installed with pip (name, version, etc.). from distutils.core import setup setup ( name = 'example' , version = '0.1dev' , packages = [ 'example' ,], license = 'MIT' , long_description = open ( 'README.txt' ) . read (), ) After creating the setup.py file, upload it to PyPI, or use the command line to create a binary distribution (an executable installer). To build a source distribution, use the command line to navigate to the directory containing setup.py, and run the command python setup.py sdist . Run python setup.py bdist or, for Windows, python setup.py bdist_wininst to build a binary distribution. Use python setup.py register , followed by python setup.py sdist upload to upload a package. Finally, install a package with python setup.py install. Packaging for Users Most Python users will not want to use this module directly, but instead use the cross-version tools maintained by the Python Packaging Authority. In particular, setuptools is an enhanced alternative to distutils . For Windows, many tools are available for converting scripts to executables. For example, py2exe, can be used to package a Python script, along with the libraries it requires, into a single executable. PyInstaller and cx_Freeze serve the same purpose. For Macs, use py2app, PyInstaller or cx_Freeze.","title":"Packaging"},{"location":"lib/pyPack/#packaging-for-users","text":"Most Python users will not want to use this module directly, but instead use the cross-version tools maintained by the Python Packaging Authority. In particular, setuptools is an enhanced alternative to distutils . For Windows, many tools are available for converting scripts to executables. For example, py2exe, can be used to package a Python script, along with the libraries it requires, into a single executable. PyInstaller and cx_Freeze serve the same purpose. For Macs, use py2app, PyInstaller or cx_Freeze.","title":"Packaging for Users"},{"location":"lib/pyRandom/","text":"Python Random module is an in-built module of Python which is used to generate random numbers. These are pseudo-random numbers means these are not truly random. This module can be used to perform random actions such as generating random numbers, print random a value for a list or string, etc. # import random import random # prints a random value from the list list1 = [ 1 , 2 , 3 , 4 , 5 , 6 ] print ( random . choice ( list1 )) 3 import random random . seed ( 5 ) print ( random . random ()) print ( random . random ()) 0.6229016948897019 0.7417869892607294 # import the random module import random # declare a list sample_list = [ 1 , 2 , 3 , 4 , 5 ] print ( \"Original list : \" ) print ( sample_list ) # first shuffle random . shuffle ( sample_list ) print ( \" \\n After the first shuffle : \" ) print ( sample_list ) # second shuffle random . shuffle ( sample_list ) print ( \" \\n After the second shuffle : \" ) print ( sample_list ) Original list : [1, 2, 3, 4, 5] After the first shuffle : [3, 4, 2, 1, 5] After the second shuffle : [2, 1, 5, 4, 3] # Functions for generating random data sequences import random import string # Use the choice function to randomly select from a sequence moves = [ \"rock\" , \"paper\" , \"scissors\" ] print ( random . choice ( moves )) # Use the choices function to create a list of random elements roulette_wheel = [ \"black\" , \"red\" , \"green\" ] weights = [ 18 , 18 , 2 ] print ( random . choices ( roulette_wheel , weights , k = 10 )) # The sample function randomly selects elements from a population # without replacement (the chosen items are not replaced) chosen = random . sample ( string . ascii_uppercase , 6 ) print ( chosen ) # The shuffle function shuffles a sequence in place players = [ \"Bill\" , \"Jane\" , \"Joe\" , \"Sally\" , \"Mike\" , \"Lindsay\" ] random . shuffle ( players ) print ( players ) # to shuffle an immutable sequence, use the sample function first result = random . sample ( string . ascii_uppercase , k = len ( string . ascii_uppercase )) random . shuffle ( result ) print ( '' . join ( result )) paper ['red', 'black', 'black', 'black', 'red', 'black', 'black', 'red', 'black', 'red'] ['C', 'E', 'T', 'X', 'O', 'Y'] ['Lindsay', 'Joe', 'Sally', 'Mike', 'Bill', 'Jane'] EJYQHGKSUNCVBIFTZPWORXLDAM Criptographic random The secrets module is used for generating random numbers for managing important data such as passwords, account authentication, security tokens, and related secrets, that are cryptographically strong. This module is responsible for providing access to the most secure source of randomness. This module is present in Python 3.6 and above. # Using cryptographic-appropriate methods to generate random data # that may be sensitive. secrets module introduced in Python 3.6 import os import secrets # the urandom() function in the OS module produces random numbers that # are cryptographically safe to use for sensitive purposes result = os . urandom ( 8 ) print ([ hex ( b ) for b in result ]) # secrets.choice is the same as random.choice but more secure moves = [ \"rock\" , \"paper\" , \"scissors\" ] print ( secrets . choice ( moves )) # secrets.token_bytes generates random bytes result = secrets . token_bytes () print ( result ) # secrets.token_hex creates a random string in hexadecimal result = secrets . token_hex () print ( result ) # secrets.token_urlsafe generates characters that can be in URLs result = secrets . token_urlsafe () print ( result ) ['0x54', '0xd8', '0xb2', '0xf3', '0x68', '0xed', '0x35', '0xab'] scissors b'\\xbc\\x14\\xf5\\xc6\\x02\\xe5\\xd3W\\xcc9\\x88\\xddk\\xc7\\xb7\\xc4\\xc9\\x9a\\xcd\\xf0N\\x94\\x95\\xdd\\xfe\\xac\\xa1\\x07\\x80|L,' 4db4b731c2de8d0af94fe8563fc21f00aae04e41ba52ce56c5b9467583d3e57d tYBwYVYQXVdsXdeztE2-ki-osvgvsNnnWT2ZVLj3kng # Create a temporary password using Python import secrets import string # Function to return a temporary password given a length def generateTempPass ( numChars = 8 ): potentialChars = string . ascii_letters + string . digits + \"+=?/!@#$%*\" result = '' . join ( secrets . choice ( potentialChars ) for i in range ( numChars )) return result # Function to return a temporary password and enforce 1 number and 1 uppercase def generateBetterPass ( numChars = 8 ): potentialChars = string . ascii_letters + string . digits + \"+=?/!@#$%*\" while True : result = '' . join ( secrets . choice ( potentialChars ) for i in range ( numChars )) # if the password has at least one number and one uppercase char we can stop if ( any ( c . isupper () for c in result ) and any ( c . isdigit () for c in result )): break return result # create a temporary password print ( generateTempPass ( 10 )) # create a stronger temporary password print ( generateBetterPass ( 10 )) # create a temporary, hard-to-guess URL resultUrl = \"https://my.example.com?reset=\" resultUrl += secrets . token_urlsafe ( 15 ) print ( resultUrl ) p9oV1vn?eJ A2*Mlp7p!l https://my.example.com?reset=DhpaK2rfeYIbFs73nbl1 UUID UUID, Universal Unique Identifier, is a python library which helps in generating random objects of 128 bits as ids. It provides the uniqueness as it generates ids on the basis of time, Computer hardware (MAC etc.) Can be used as general utility to generate unique random id. Can be used in cryptography and hashing applications. Useful in generating random documents, addresses etc. # Generating unique identifiers import uuid # use the uuid4 function to create a random sequence using # the underlying os.urandom() function result = uuid . uuid4 () print ( \"UUID4: \" ) print ( result ) print ( result . hex ) print ( result . urn ) print ( \"~~~~~~~~~~~~~~~~~~~~~~~ \\n \" ) # create a UUID using uuid5, which takes a namespace and # name value. Note that this version is not crypto-safe result = uuid . uuid5 ( uuid . NAMESPACE_DNS , \"example.com\" ) print ( \"UUID5: \" ) print ( result ) print ( result . hex ) print ( result . urn ) print ( \"~~~~~~~~~~~~~~~~~~~~~~~ \\n \" ) UUID4: dfbf3df5-8647-4a91-8e51-81e1a3465ec3 dfbf3df586474a918e5181e1a3465ec3 urn:uuid:dfbf3df5-8647-4a91-8e51-81e1a3465ec3 ~~~~~~~~~~~~~~~~~~~~~~~ UUID5: cfbff0d1-9375-5685-968c-48ce8b15ae17 cfbff0d193755685968c48ce8b15ae17 urn:uuid:cfbff0d1-9375-5685-968c-48ce8b15ae17 ~~~~~~~~~~~~~~~~~~~~~~~","title":"Random"},{"location":"lib/pyRandom/#criptographic-random","text":"The secrets module is used for generating random numbers for managing important data such as passwords, account authentication, security tokens, and related secrets, that are cryptographically strong. This module is responsible for providing access to the most secure source of randomness. This module is present in Python 3.6 and above. # Using cryptographic-appropriate methods to generate random data # that may be sensitive. secrets module introduced in Python 3.6 import os import secrets # the urandom() function in the OS module produces random numbers that # are cryptographically safe to use for sensitive purposes result = os . urandom ( 8 ) print ([ hex ( b ) for b in result ]) # secrets.choice is the same as random.choice but more secure moves = [ \"rock\" , \"paper\" , \"scissors\" ] print ( secrets . choice ( moves )) # secrets.token_bytes generates random bytes result = secrets . token_bytes () print ( result ) # secrets.token_hex creates a random string in hexadecimal result = secrets . token_hex () print ( result ) # secrets.token_urlsafe generates characters that can be in URLs result = secrets . token_urlsafe () print ( result ) ['0x54', '0xd8', '0xb2', '0xf3', '0x68', '0xed', '0x35', '0xab'] scissors b'\\xbc\\x14\\xf5\\xc6\\x02\\xe5\\xd3W\\xcc9\\x88\\xddk\\xc7\\xb7\\xc4\\xc9\\x9a\\xcd\\xf0N\\x94\\x95\\xdd\\xfe\\xac\\xa1\\x07\\x80|L,' 4db4b731c2de8d0af94fe8563fc21f00aae04e41ba52ce56c5b9467583d3e57d tYBwYVYQXVdsXdeztE2-ki-osvgvsNnnWT2ZVLj3kng # Create a temporary password using Python import secrets import string # Function to return a temporary password given a length def generateTempPass ( numChars = 8 ): potentialChars = string . ascii_letters + string . digits + \"+=?/!@#$%*\" result = '' . join ( secrets . choice ( potentialChars ) for i in range ( numChars )) return result # Function to return a temporary password and enforce 1 number and 1 uppercase def generateBetterPass ( numChars = 8 ): potentialChars = string . ascii_letters + string . digits + \"+=?/!@#$%*\" while True : result = '' . join ( secrets . choice ( potentialChars ) for i in range ( numChars )) # if the password has at least one number and one uppercase char we can stop if ( any ( c . isupper () for c in result ) and any ( c . isdigit () for c in result )): break return result # create a temporary password print ( generateTempPass ( 10 )) # create a stronger temporary password print ( generateBetterPass ( 10 )) # create a temporary, hard-to-guess URL resultUrl = \"https://my.example.com?reset=\" resultUrl += secrets . token_urlsafe ( 15 ) print ( resultUrl ) p9oV1vn?eJ A2*Mlp7p!l https://my.example.com?reset=DhpaK2rfeYIbFs73nbl1","title":"Criptographic random"},{"location":"lib/pyRandom/#uuid","text":"UUID, Universal Unique Identifier, is a python library which helps in generating random objects of 128 bits as ids. It provides the uniqueness as it generates ids on the basis of time, Computer hardware (MAC etc.) Can be used as general utility to generate unique random id. Can be used in cryptography and hashing applications. Useful in generating random documents, addresses etc. # Generating unique identifiers import uuid # use the uuid4 function to create a random sequence using # the underlying os.urandom() function result = uuid . uuid4 () print ( \"UUID4: \" ) print ( result ) print ( result . hex ) print ( result . urn ) print ( \"~~~~~~~~~~~~~~~~~~~~~~~ \\n \" ) # create a UUID using uuid5, which takes a namespace and # name value. Note that this version is not crypto-safe result = uuid . uuid5 ( uuid . NAMESPACE_DNS , \"example.com\" ) print ( \"UUID5: \" ) print ( result ) print ( result . hex ) print ( result . urn ) print ( \"~~~~~~~~~~~~~~~~~~~~~~~ \\n \" ) UUID4: dfbf3df5-8647-4a91-8e51-81e1a3465ec3 dfbf3df586474a918e5181e1a3465ec3 urn:uuid:dfbf3df5-8647-4a91-8e51-81e1a3465ec3 ~~~~~~~~~~~~~~~~~~~~~~~ UUID5: cfbff0d1-9375-5685-968c-48ce8b15ae17 cfbff0d193755685968c48ce8b15ae17 urn:uuid:cfbff0d1-9375-5685-968c-48ce8b15ae17 ~~~~~~~~~~~~~~~~~~~~~~~","title":"UUID"},{"location":"lib/pySerial/","text":"Data Persistence The standard library includes a variety of modules for persisting data. The most common pattern for storing data from Python objects for reuse is to serialize them with pickle and then either write them directly to a file or store them using one of the many key-value pair database formats available with the dbm API. If you don\u2019t care about the underlying dbm format, the best persistence interface is provided by shelve. If you do care, you can use one of the other dbm-based modules directly. anydbm \u2013 Access to DBM-style databases dbhash \u2013 DBM-style API for the BSD database library dbm \u2013 Simple database interface dumbdbm \u2013 Portable DBM Implementation gdbm \u2013 GNU\u2019s version of the dbm library pickle and cPickle \u2013 Python object serialization shelve \u2013 Persistent storage of arbitrary Python objects whichdb \u2013 Identify DBM-style database formats sqlite3 \u2013 Embedded Relational Database For serializing over the web, the json module may be a better choice since its format is more portable. Serialization with Pickle The pickle module is used for implementing binary protocols for serializing and de-serializing a Python object structure. Pickling: It is a process where a Python object hierarchy is converted into a byte stream. Unpickling: It is the inverse of Pickling process where a byte stream is converted into an object hierarchy. Module Interface : dumps() \u2013 This function is called to serialize an object hierarchy. loads() \u2013 This function is called to de-serialize a data stream. # Python program to illustrate #Picle.dumps() import pickle data = [ { 'a' : 'A' , 'b' : 2 , 'c' : 3.0 } ] data_string = pickle . dumps ( data ) print ( 'PICKLE:' , data_string ) PICKLE: b'\\x80\\x03]q\\x00}q\\x01(X\\x01\\x00\\x00\\x00aq\\x02X\\x01\\x00\\x00\\x00Aq\\x03X\\x01\\x00\\x00\\x00bq\\x04K\\x02X\\x01\\x00\\x00\\x00cq\\x05G@\\x08\\x00\\x00\\x00\\x00\\x00\\x00ua.' # Python program to illustrate # pickle.loads() import pickle import pprint data1 = [ { 'a' : 'A' , 'b' : 2 , 'c' : 3.0 } ] print ( 'BEFORE:' ,) pprint . pprint ( data1 ) data1_string = pickle . dumps ( data1 ) data2 = pickle . loads ( data1_string ) print ( 'AFTER:' ,) pprint . pprint ( data2 ) print ( 'SAME?:' , ( data1 is data2 )) print ( 'EQUAL?:' , ( data1 == data2 )) BEFORE: [{'a': 'A', 'b': 2, 'c': 3.0}] AFTER: [{'a': 'A', 'b': 2, 'c': 3.0}] SAME?: False EQUAL?: True Python pickle module is used for serializing and de-serializing a Python object structure. Any object in Python can be pickled so that it can be saved on disk. What pickle does is that it \u201cserializes\u201d the object first before writing it to file. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script. # Python3 program to illustrate store # efficiently using pickle module # Module translates an in-memory Python object # into a serialized byte stream\u2014a string of # bytes that can be written to any file-like object. import pickle def storeData (): # initializing data to be stored in db Omkar = { 'key' : 'Omkar' , 'name' : 'Omkar Pathak' , 'age' : 21 , 'pay' : 40000 } Jagdish = { 'key' : 'Jagdish' , 'name' : 'Jagdish Pathak' , 'age' : 50 , 'pay' : 50000 } # database db = {} db [ 'Omkar' ] = Omkar db [ 'Jagdish' ] = Jagdish # Its important to use binary mode dbfile = open ( 'examplePickle' , 'ab' ) # source, destination pickle . dump ( db , dbfile ) dbfile . close () def loadData (): # for reading also binary mode is important dbfile = open ( 'examplePickle' , 'rb' ) db = pickle . load ( dbfile ) for keys in db : print ( keys , '=>' , db [ keys ]) dbfile . close () if __name__ == '__main__' : storeData () loadData () Omkar => {'key': 'Omkar', 'name': 'Omkar Pathak', 'age': 21, 'pay': 40000} Jagdish => {'key': 'Jagdish', 'name': 'Jagdish Pathak', 'age': 50, 'pay': 50000} Without a File # initializing data to be stored in db Omkar = { 'key' : 'Omkar' , 'name' : 'Omkar Pathak' , 'age' : 21 , 'pay' : 40000 } Jagdish = { 'key' : 'Jagdish' , 'name' : 'Jagdish Pathak' , 'age' : 50 , 'pay' : 50000 } # database db = {} db [ 'Omkar' ] = Omkar db [ 'Jagdish' ] = Jagdish # For storing b = pickle . dumps ( db ) # type(b) gives <class 'bytes'> # For loading myEntry = pickle . loads ( b ) print ( myEntry ) {'Omkar': {'key': 'Omkar', 'name': 'Omkar Pathak', 'age': 21, 'pay': 40000}, 'Jagdish': {'key': 'Jagdish', 'name': 'Jagdish Pathak', 'age': 50, 'pay': 50000}} Advantages of Using Pickle Recursive objects (objects containing references to themselves): Pickle keeps track of the objects it has already serialized, so later references to the same object won\u2019t be serialized again. (The marshal module breaks for this.) Object sharing (references to the same object in different places): This is similar to self- referencing objects; pickle stores the object once, and ensures that all other references point to the master copy. Shared objects remain shared, which can be very important for mutable objects. User-defined classes and their instances: Marshal does not support these at all, but pickle can save and restore class instances transparently. The class definition must be importable and live in the same module as when the object was stored. Serialization with JSON # import module import json # Data to be written data = { \"user\" : { \"name\" : \"satyam kumar\" , \"age\" : 21 , \"Place\" : \"Patna\" , \"Blood group\" : \"O+\" } } # Serializing json and # Writing json file with open ( \"datafile.json\" , \"w\" ) as write : json . dump ( data , write ) # importing the module import json # creating the JSON data as a string data = '{\"Name\" : \"Romy\", \"Gender\" : \"Female\"}' print ( \"Datatype before deserialization : \" + str ( type ( data ))) # deserializing the data data = json . loads ( data ) print ( \"Datatype after deserialization : \" + str ( type ( data ))) Datatype before deserialization : <class 'str'> Datatype after deserialization : <class 'dict'>","title":"Serialization"},{"location":"lib/pySerial/#serialization-with-pickle","text":"The pickle module is used for implementing binary protocols for serializing and de-serializing a Python object structure. Pickling: It is a process where a Python object hierarchy is converted into a byte stream. Unpickling: It is the inverse of Pickling process where a byte stream is converted into an object hierarchy. Module Interface : dumps() \u2013 This function is called to serialize an object hierarchy. loads() \u2013 This function is called to de-serialize a data stream. # Python program to illustrate #Picle.dumps() import pickle data = [ { 'a' : 'A' , 'b' : 2 , 'c' : 3.0 } ] data_string = pickle . dumps ( data ) print ( 'PICKLE:' , data_string ) PICKLE: b'\\x80\\x03]q\\x00}q\\x01(X\\x01\\x00\\x00\\x00aq\\x02X\\x01\\x00\\x00\\x00Aq\\x03X\\x01\\x00\\x00\\x00bq\\x04K\\x02X\\x01\\x00\\x00\\x00cq\\x05G@\\x08\\x00\\x00\\x00\\x00\\x00\\x00ua.' # Python program to illustrate # pickle.loads() import pickle import pprint data1 = [ { 'a' : 'A' , 'b' : 2 , 'c' : 3.0 } ] print ( 'BEFORE:' ,) pprint . pprint ( data1 ) data1_string = pickle . dumps ( data1 ) data2 = pickle . loads ( data1_string ) print ( 'AFTER:' ,) pprint . pprint ( data2 ) print ( 'SAME?:' , ( data1 is data2 )) print ( 'EQUAL?:' , ( data1 == data2 )) BEFORE: [{'a': 'A', 'b': 2, 'c': 3.0}] AFTER: [{'a': 'A', 'b': 2, 'c': 3.0}] SAME?: False EQUAL?: True Python pickle module is used for serializing and de-serializing a Python object structure. Any object in Python can be pickled so that it can be saved on disk. What pickle does is that it \u201cserializes\u201d the object first before writing it to file. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script. # Python3 program to illustrate store # efficiently using pickle module # Module translates an in-memory Python object # into a serialized byte stream\u2014a string of # bytes that can be written to any file-like object. import pickle def storeData (): # initializing data to be stored in db Omkar = { 'key' : 'Omkar' , 'name' : 'Omkar Pathak' , 'age' : 21 , 'pay' : 40000 } Jagdish = { 'key' : 'Jagdish' , 'name' : 'Jagdish Pathak' , 'age' : 50 , 'pay' : 50000 } # database db = {} db [ 'Omkar' ] = Omkar db [ 'Jagdish' ] = Jagdish # Its important to use binary mode dbfile = open ( 'examplePickle' , 'ab' ) # source, destination pickle . dump ( db , dbfile ) dbfile . close () def loadData (): # for reading also binary mode is important dbfile = open ( 'examplePickle' , 'rb' ) db = pickle . load ( dbfile ) for keys in db : print ( keys , '=>' , db [ keys ]) dbfile . close () if __name__ == '__main__' : storeData () loadData () Omkar => {'key': 'Omkar', 'name': 'Omkar Pathak', 'age': 21, 'pay': 40000} Jagdish => {'key': 'Jagdish', 'name': 'Jagdish Pathak', 'age': 50, 'pay': 50000}","title":"Serialization with Pickle"},{"location":"lib/pySerial/#without-a-file","text":"# initializing data to be stored in db Omkar = { 'key' : 'Omkar' , 'name' : 'Omkar Pathak' , 'age' : 21 , 'pay' : 40000 } Jagdish = { 'key' : 'Jagdish' , 'name' : 'Jagdish Pathak' , 'age' : 50 , 'pay' : 50000 } # database db = {} db [ 'Omkar' ] = Omkar db [ 'Jagdish' ] = Jagdish # For storing b = pickle . dumps ( db ) # type(b) gives <class 'bytes'> # For loading myEntry = pickle . loads ( b ) print ( myEntry ) {'Omkar': {'key': 'Omkar', 'name': 'Omkar Pathak', 'age': 21, 'pay': 40000}, 'Jagdish': {'key': 'Jagdish', 'name': 'Jagdish Pathak', 'age': 50, 'pay': 50000}}","title":"Without a File"},{"location":"lib/pySerial/#advantages-of-using-pickle","text":"Recursive objects (objects containing references to themselves): Pickle keeps track of the objects it has already serialized, so later references to the same object won\u2019t be serialized again. (The marshal module breaks for this.) Object sharing (references to the same object in different places): This is similar to self- referencing objects; pickle stores the object once, and ensures that all other references point to the master copy. Shared objects remain shared, which can be very important for mutable objects. User-defined classes and their instances: Marshal does not support these at all, but pickle can save and restore class instances transparently. The class definition must be importable and live in the same module as when the object was stored.","title":"Advantages of Using Pickle"},{"location":"lib/pySerial/#serialization-with-json","text":"# import module import json # Data to be written data = { \"user\" : { \"name\" : \"satyam kumar\" , \"age\" : 21 , \"Place\" : \"Patna\" , \"Blood group\" : \"O+\" } } # Serializing json and # Writing json file with open ( \"datafile.json\" , \"w\" ) as write : json . dump ( data , write ) # importing the module import json # creating the JSON data as a string data = '{\"Name\" : \"Romy\", \"Gender\" : \"Female\"}' print ( \"Datatype before deserialization : \" + str ( type ( data ))) # deserializing the data data = json . loads ( data ) print ( \"Datatype after deserialization : \" + str ( type ( data ))) Datatype before deserialization : <class 'str'> Datatype after deserialization : <class 'dict'>","title":"Serialization with JSON"},{"location":"lib/pyTest/","text":"Software testing can be divided into two classes, Manual testing and Automated testing. Automated testing is the execution of your tests using a script instead of a human. There are different Test Runners available in Python. Popular ones are: unittest nose or nose2 pytest Unitest It is built into the standard python library. import unittest should be the starting line of code for using it. Depends upon the python version, it should differ as later versions of Python supports unittest and earlier versions supported unittest2. One of the major problems with manual testing is that it requires time and effort. In manual testing, we test the application over some input, if it fails, either we note it down or we debug the application for that particular test input, and then we repeat the process. With unittest, all the test inputs can be provided at once and then you can test your application. In the end, you get a detailed report with all the failed test cases clearly specified, if any. The unittest module has both a built-in testing framework and a test runner. A testing framework is a set of rules which must be followed while writing test cases, while a test runner is a tool which executes these tests with a bunch of settings, and collects the results. Nose or Nose2 This is an open source application and similar to unittest only.It is compatible with numerous kinds of tests that are written using unittest framework. nose2 is the recent version one, and they are installed by using. pip install nose2 Pytest t supports unittest test cases execution. It has benefits like supporting built in assert statement, filtering of test cases, returning from last failing test etc def test_sum_numbers_using_pytest (): assert sum ([ 700 , 900 ]) == 1600 , \"Resultant should be 1600\" def test_sum_tuple_using_pytest (): assert sum (( 700 , 1900 )) == 1600 , \"Resultant should be 1600\"","title":"Testing"},{"location":"lib/pyTest/#unitest","text":"It is built into the standard python library. import unittest should be the starting line of code for using it. Depends upon the python version, it should differ as later versions of Python supports unittest and earlier versions supported unittest2. One of the major problems with manual testing is that it requires time and effort. In manual testing, we test the application over some input, if it fails, either we note it down or we debug the application for that particular test input, and then we repeat the process. With unittest, all the test inputs can be provided at once and then you can test your application. In the end, you get a detailed report with all the failed test cases clearly specified, if any. The unittest module has both a built-in testing framework and a test runner. A testing framework is a set of rules which must be followed while writing test cases, while a test runner is a tool which executes these tests with a bunch of settings, and collects the results.","title":"Unitest"},{"location":"lib/pyTest/#nose-or-nose2","text":"This is an open source application and similar to unittest only.It is compatible with numerous kinds of tests that are written using unittest framework. nose2 is the recent version one, and they are installed by using. pip install nose2","title":"Nose or Nose2"},{"location":"lib/pyTest/#pytest","text":"t supports unittest test cases execution. It has benefits like supporting built in assert statement, filtering of test cases, returning from last failing test etc def test_sum_numbers_using_pytest (): assert sum ([ 700 , 900 ]) == 1600 , \"Resultant should be 1600\" def test_sum_tuple_using_pytest (): assert sum (( 700 , 1900 )) == 1600 , \"Resultant should be 1600\"","title":"Pytest"},{"location":"lib/pyTimeP/","text":"In Python, we have three modules that help us find the execution time of a program. Using Timeit Module Python timeit module is often used to measure the execution time of small code snippets. We can also use the timeit() function which executes an anonymous function with a number of executions. It temporarily turns off garbage collection (the process of collecting unwanted variables whose use has been over and clears them by marking them as garbage values to free up the memory) during calculating the time of execution. How is the \"timeit\" command better than \"time\"? It averages results and ignores warm up. # importing the module import timeit # using the timeit method and lambda # expression to get the execution time of # the function. t = timeit . timeit ( lambda : \"print('Hello World!')\" ) # printing the execution time print ( t ) 0.08696221099944523 # importing the module import timeit # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # using the timeit method and lambda # expression to get the execution time of # the function, number defines how many # times we execute this function t = timeit . timeit ( lambda : print_square ( 3 ), number = 10 ) # printing the execution time print ( t ) 4.83900021208683e-06 Now, practically to estimate the execution time of a program we generally do not use the value obtained once as the ultimate correct value, because the execution of a program may depend upon os and availability of hardware at a particular instant of time. So generally we take multiple values of execution time and generally the average computed gives us the best possible answer. For this, we would use the timeit.repeat() method instead of timeit.timeit() which takes a repeat parameter and saves you the trouble of creating a loop and storing the values in the array. # importing the module import timeit # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # using the repeat method and lambda # expression to get the execution time of # the function, number defines how many # times we execute this function and the # repeat defines the number of times the # time calculation needs to be done. t = timeit . repeat ( lambda : print_square ( 3 ), number = 10 , repeat = 5 ) # printing the execution time print ( t ) [5.1380002332734875e-06, 3.6009996620123275e-06, 3.5189996197004803e-06, 3.484999979264103e-06, 3.50700065609999e-06] Also, we can use the timeit.default_timer() which basically records the time at the instant when the method is called. So we call the method just before and after the lines of the code for which we want to calculate the execution time and then basically the difference between the two times give us the result. So for finding the time we record the times using the timeit.defaultTimer() method, and then we print the difference between the two times in the last line. # importing the module import timeit # sample function that returns # square of the value passed def print_square ( x ): return ( x ** 2 ) # records the time at this instant # of the program start = timeit . default_timer () # calls the function print_square ( 3 ) # records the time at this instant # of the program end = timeit . default_timer () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 3.099999958067201e-05 \"\"\"Using \"timeit\"\"\" from timeit import timeit items = { 'a' : 1 , 'b' : 2 , } default = - 1 def use_catch ( key ): \"\"\"Use try/catch to get a key with default\"\"\" try : return items [ key ] except KeyError : return default def use_get ( key ): \"\"\"Use dict.get to get a key with default\"\"\" return items . get ( key , default ) if __name__ == '__main__' : # Key is in the dictionary print ( 'catch' , timeit ( 'use_catch(\"a\")' , 'from __main__ import use_catch' )) print ( 'get' , timeit ( 'use_get(\"a\")' , 'from __main__ import use_get' )) # Key is missing from the dictionary print ( 'catch' , timeit ( 'use_catch(\"x\")' , 'from __main__ import use_catch' )) print ( 'get' , timeit ( 'use_get(\"x\")' , 'from __main__ import use_get' )) catch 0.12401290399975551 get 0.16413491899947985 catch 0.32834199399985664 get 0.17250985499958915 Using Time Module We can use the time.perf_counter() method in the same way as the timeit.default_timer() method discussed above. It can use the highest possible resolution clock and gives you the most accurate result. In fact the timeit.default_timer() also uses time.perf_counter() as it\u2019s base. This also records the time before and after the required lines of code whose execution or elapsed time needs to be calculated. Then we subtract the recorded time before the start of the lines from the recorded time after the lines of the code. # importing the module import time # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # records the time at this instant of the # program start = time . perf_counter () # calls the function print_square ( 3 ) # records the time at this instant of the # program end = time . perf_counter () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 2.8733999897667672e-05 To measure the elapsed time or execution time of a block of code in nanoseconds, we can use the time.time_ns() function. This follows the same syntax as the time.perf_counter() function, like recording the time before and after the lines of the code and then subtracting the values and then printing them to the screen, but it records in nanoseconds instead of seconds. # importing the module import time # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # records the time in nanoseceonds at # this instant of the program start = time . time_ns () # calls the function print_square ( 3 ) # records the time in nanoseceonds at this # instant of the program end = time . time_ns () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 50676 \"\"\"Measuring time\"\"\" from time import perf_counter def upto_for ( n ): \"\"\"Sum 1...n with a for loop\"\"\" total = 0 for i in range ( n ): total += i return total def upto_sum ( n ): \"\"\"Sum 1...n with built-in sum and range\"\"\" return sum ( range ( n )) if __name__ == '__main__' : n = 1_000_000 start = perf_counter () upto_for ( n ) duration = perf_counter () - start print ( 'upto_for' , duration ) start = perf_counter () upto_sum ( n ) duration = perf_counter () - start print ( 'upto_sum' , duration ) upto_for 0.0630132690002938 upto_sum 0.018293597999218036 Using Datetime Module Datetime module can also be used to find the time elapsed or spent in a code block provided you are not looking for high precision. the datetime.now() also works the same way as the timeit.default_timer() or time.perf_counter() but lacks the same precision as those. It returns the result in HH:MM:SS format. This function is generally used for getting the current time and not a preferred use case for calculating execution time. However, these can be programs that take quite some time to execute like training ML/AI models, web scraping large websites, etc. # importing the module from datetime import datetime # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # records the time at this instant of # the program in HH:MM:SS format start = datetime . now () # calls the function print_square ( 3 ) # records the time at this instant of the # program in HH:MM:SS format end = datetime . now () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 0:00:00.000034 %Timeit Magic inline import numpy as np import pandas as pd data = pd . Series ( np . random . randint ( 50 , 60 , 10_000 )) #Outliers data [ 7 ] = 3 data [ 1003 ] = 100 def find_outliers ( data ): \"\"\"Find outliers in data, return indices of outliers\"\"\" out = data [( data - data . mean ()) . abs () > 2 * data . std ()] return out . index find_outliers ( data ) Int64Index([7, 1003], dtype='int64') % timeit find_outliers ( data ) 1000 loops, best of 5: 629 \u00b5s per loop %prun -s cumulative find_outliers(data) Using cprofile Python includes a built in module called cProfile which is used to measure the execution time of a program.cProfiler module provides all information about how long the program is executing and how many times the function get called in a program. How does cProfile work? It records every function entry and exit. # importing cProfile import cProfile cProfile . run ( \"10 + 10\" ) 3 function calls in 0.000 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.000 0.000 <string>:1(<module>) 1 0.000 0.000 0.000 0.000 {built-in method builtins.exec} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} # importing cProfile import cProfile def f (): print ( \"hello\" ) cProfile . run ( 'f()' ) hello 39 function calls in 0.000 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.000 0.000 <ipython-input-46-7b34c7345cd2>:4(f) 1 0.000 0.000 0.000 0.000 <string>:1(<module>) 3 0.000 0.000 0.000 0.000 iostream.py:195(schedule) 2 0.000 0.000 0.000 0.000 iostream.py:307(_is_master_process) 2 0.000 0.000 0.000 0.000 iostream.py:320(_schedule_flush) 2 0.000 0.000 0.000 0.000 iostream.py:382(write) 3 0.000 0.000 0.000 0.000 iostream.py:93(_event_pipe) 3 0.000 0.000 0.000 0.000 socket.py:480(send) 3 0.000 0.000 0.000 0.000 threading.py:1050(_wait_for_tstate_lock) 3 0.000 0.000 0.000 0.000 threading.py:1092(is_alive) 3 0.000 0.000 0.000 0.000 threading.py:507(is_set) 1 0.000 0.000 0.000 0.000 {built-in method builtins.exec} 2 0.000 0.000 0.000 0.000 {built-in method builtins.isinstance} 1 0.000 0.000 0.000 0.000 {built-in method builtins.print} 2 0.000 0.000 0.000 0.000 {built-in method posix.getpid} 3 0.000 0.000 0.000 0.000 {method 'acquire' of '_thread.lock' objects} 3 0.000 0.000 0.000 0.000 {method 'append' of 'collections.deque' objects} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} Using line_profiler Python provides a built-in module to measure execution time and the module name is LineProfiler.It gives detailed report on time consumed by a program. ! pip install line_profiler # importing line_profiler module from line_profiler import LineProfiler def peek ( rk ): print ( rk ) rk = \"risk\" profile = LineProfiler ( peek ( rk )) profile . print_stats () risk Timer unit: 1e-06 s % load_ext line_profiler % lprun - f find_outliers","title":"Time Profiling"},{"location":"lib/pyTimeP/#using-timeit-module","text":"Python timeit module is often used to measure the execution time of small code snippets. We can also use the timeit() function which executes an anonymous function with a number of executions. It temporarily turns off garbage collection (the process of collecting unwanted variables whose use has been over and clears them by marking them as garbage values to free up the memory) during calculating the time of execution. How is the \"timeit\" command better than \"time\"? It averages results and ignores warm up. # importing the module import timeit # using the timeit method and lambda # expression to get the execution time of # the function. t = timeit . timeit ( lambda : \"print('Hello World!')\" ) # printing the execution time print ( t ) 0.08696221099944523 # importing the module import timeit # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # using the timeit method and lambda # expression to get the execution time of # the function, number defines how many # times we execute this function t = timeit . timeit ( lambda : print_square ( 3 ), number = 10 ) # printing the execution time print ( t ) 4.83900021208683e-06 Now, practically to estimate the execution time of a program we generally do not use the value obtained once as the ultimate correct value, because the execution of a program may depend upon os and availability of hardware at a particular instant of time. So generally we take multiple values of execution time and generally the average computed gives us the best possible answer. For this, we would use the timeit.repeat() method instead of timeit.timeit() which takes a repeat parameter and saves you the trouble of creating a loop and storing the values in the array. # importing the module import timeit # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # using the repeat method and lambda # expression to get the execution time of # the function, number defines how many # times we execute this function and the # repeat defines the number of times the # time calculation needs to be done. t = timeit . repeat ( lambda : print_square ( 3 ), number = 10 , repeat = 5 ) # printing the execution time print ( t ) [5.1380002332734875e-06, 3.6009996620123275e-06, 3.5189996197004803e-06, 3.484999979264103e-06, 3.50700065609999e-06] Also, we can use the timeit.default_timer() which basically records the time at the instant when the method is called. So we call the method just before and after the lines of the code for which we want to calculate the execution time and then basically the difference between the two times give us the result. So for finding the time we record the times using the timeit.defaultTimer() method, and then we print the difference between the two times in the last line. # importing the module import timeit # sample function that returns # square of the value passed def print_square ( x ): return ( x ** 2 ) # records the time at this instant # of the program start = timeit . default_timer () # calls the function print_square ( 3 ) # records the time at this instant # of the program end = timeit . default_timer () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 3.099999958067201e-05 \"\"\"Using \"timeit\"\"\" from timeit import timeit items = { 'a' : 1 , 'b' : 2 , } default = - 1 def use_catch ( key ): \"\"\"Use try/catch to get a key with default\"\"\" try : return items [ key ] except KeyError : return default def use_get ( key ): \"\"\"Use dict.get to get a key with default\"\"\" return items . get ( key , default ) if __name__ == '__main__' : # Key is in the dictionary print ( 'catch' , timeit ( 'use_catch(\"a\")' , 'from __main__ import use_catch' )) print ( 'get' , timeit ( 'use_get(\"a\")' , 'from __main__ import use_get' )) # Key is missing from the dictionary print ( 'catch' , timeit ( 'use_catch(\"x\")' , 'from __main__ import use_catch' )) print ( 'get' , timeit ( 'use_get(\"x\")' , 'from __main__ import use_get' )) catch 0.12401290399975551 get 0.16413491899947985 catch 0.32834199399985664 get 0.17250985499958915","title":"Using Timeit Module"},{"location":"lib/pyTimeP/#using-time-module","text":"We can use the time.perf_counter() method in the same way as the timeit.default_timer() method discussed above. It can use the highest possible resolution clock and gives you the most accurate result. In fact the timeit.default_timer() also uses time.perf_counter() as it\u2019s base. This also records the time before and after the required lines of code whose execution or elapsed time needs to be calculated. Then we subtract the recorded time before the start of the lines from the recorded time after the lines of the code. # importing the module import time # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # records the time at this instant of the # program start = time . perf_counter () # calls the function print_square ( 3 ) # records the time at this instant of the # program end = time . perf_counter () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 2.8733999897667672e-05 To measure the elapsed time or execution time of a block of code in nanoseconds, we can use the time.time_ns() function. This follows the same syntax as the time.perf_counter() function, like recording the time before and after the lines of the code and then subtracting the values and then printing them to the screen, but it records in nanoseconds instead of seconds. # importing the module import time # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # records the time in nanoseceonds at # this instant of the program start = time . time_ns () # calls the function print_square ( 3 ) # records the time in nanoseceonds at this # instant of the program end = time . time_ns () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 50676 \"\"\"Measuring time\"\"\" from time import perf_counter def upto_for ( n ): \"\"\"Sum 1...n with a for loop\"\"\" total = 0 for i in range ( n ): total += i return total def upto_sum ( n ): \"\"\"Sum 1...n with built-in sum and range\"\"\" return sum ( range ( n )) if __name__ == '__main__' : n = 1_000_000 start = perf_counter () upto_for ( n ) duration = perf_counter () - start print ( 'upto_for' , duration ) start = perf_counter () upto_sum ( n ) duration = perf_counter () - start print ( 'upto_sum' , duration ) upto_for 0.0630132690002938 upto_sum 0.018293597999218036","title":"Using Time Module"},{"location":"lib/pyTimeP/#using-datetime-module","text":"Datetime module can also be used to find the time elapsed or spent in a code block provided you are not looking for high precision. the datetime.now() also works the same way as the timeit.default_timer() or time.perf_counter() but lacks the same precision as those. It returns the result in HH:MM:SS format. This function is generally used for getting the current time and not a preferred use case for calculating execution time. However, these can be programs that take quite some time to execute like training ML/AI models, web scraping large websites, etc. # importing the module from datetime import datetime # sample function that returns square # of the value passed def print_square ( x ): return ( x ** 2 ) # records the time at this instant of # the program in HH:MM:SS format start = datetime . now () # calls the function print_square ( 3 ) # records the time at this instant of the # program in HH:MM:SS format end = datetime . now () # printing the execution time by subtracting # the time before the function from # the time after the function print ( end - start ) 0:00:00.000034","title":"Using Datetime Module"},{"location":"lib/pyTimeP/#timeit-magic-inline","text":"import numpy as np import pandas as pd data = pd . Series ( np . random . randint ( 50 , 60 , 10_000 )) #Outliers data [ 7 ] = 3 data [ 1003 ] = 100 def find_outliers ( data ): \"\"\"Find outliers in data, return indices of outliers\"\"\" out = data [( data - data . mean ()) . abs () > 2 * data . std ()] return out . index find_outliers ( data ) Int64Index([7, 1003], dtype='int64') % timeit find_outliers ( data ) 1000 loops, best of 5: 629 \u00b5s per loop %prun -s cumulative find_outliers(data)","title":"%Timeit Magic inline"},{"location":"lib/pyTimeP/#using-cprofile","text":"Python includes a built in module called cProfile which is used to measure the execution time of a program.cProfiler module provides all information about how long the program is executing and how many times the function get called in a program. How does cProfile work? It records every function entry and exit. # importing cProfile import cProfile cProfile . run ( \"10 + 10\" ) 3 function calls in 0.000 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.000 0.000 <string>:1(<module>) 1 0.000 0.000 0.000 0.000 {built-in method builtins.exec} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} # importing cProfile import cProfile def f (): print ( \"hello\" ) cProfile . run ( 'f()' ) hello 39 function calls in 0.000 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.000 0.000 <ipython-input-46-7b34c7345cd2>:4(f) 1 0.000 0.000 0.000 0.000 <string>:1(<module>) 3 0.000 0.000 0.000 0.000 iostream.py:195(schedule) 2 0.000 0.000 0.000 0.000 iostream.py:307(_is_master_process) 2 0.000 0.000 0.000 0.000 iostream.py:320(_schedule_flush) 2 0.000 0.000 0.000 0.000 iostream.py:382(write) 3 0.000 0.000 0.000 0.000 iostream.py:93(_event_pipe) 3 0.000 0.000 0.000 0.000 socket.py:480(send) 3 0.000 0.000 0.000 0.000 threading.py:1050(_wait_for_tstate_lock) 3 0.000 0.000 0.000 0.000 threading.py:1092(is_alive) 3 0.000 0.000 0.000 0.000 threading.py:507(is_set) 1 0.000 0.000 0.000 0.000 {built-in method builtins.exec} 2 0.000 0.000 0.000 0.000 {built-in method builtins.isinstance} 1 0.000 0.000 0.000 0.000 {built-in method builtins.print} 2 0.000 0.000 0.000 0.000 {built-in method posix.getpid} 3 0.000 0.000 0.000 0.000 {method 'acquire' of '_thread.lock' objects} 3 0.000 0.000 0.000 0.000 {method 'append' of 'collections.deque' objects} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects}","title":"Using cprofile"},{"location":"lib/pyTimeP/#using-line_profiler","text":"Python provides a built-in module to measure execution time and the module name is LineProfiler.It gives detailed report on time consumed by a program. ! pip install line_profiler # importing line_profiler module from line_profiler import LineProfiler def peek ( rk ): print ( rk ) rk = \"risk\" profile = LineProfiler ( peek ( rk )) profile . print_stats () risk Timer unit: 1e-06 s % load_ext line_profiler % lprun - f find_outliers","title":"Using line_profiler"},{"location":"lib/pydatetime/","text":"Datetime from datetime import date from datetime import time from datetime import datetime ## DATE OBJECTS # Get today's date from the simple today() method from the date class today = date . today () print ( \"Today's date is \" , today ) # print out the date's individual components print ( \"Date Components: \" , today . day , today . month , today . year ) # retrieve today's weekday (0=Monday, 6=Sunday) print ( \"Today's Weekday #: \" , today . weekday ()) days = [ \"monday\" , \"tuesday\" , \"wednesday\" , \"thursday\" , \"friday\" , \"saturday\" , \"sunday\" ] print ( \"Which is a \" + days [ today . weekday ()]) ## DATETIME OBJECTS # Get today's date from the datetime class today = datetime . now () print ( \"The current date and time is \" , today ) # Get the current time t = datetime . time ( datetime . now ()) print ( \"The current time is \" , t ) Today's date is 2021-12-22 Date Components: 22 12 2021 Today's Weekday #: 2 Which is a wednesday The current date and time is 2021-12-22 20:01:50.628110 The current time is 20:01:50.631578 Pendulum The pendulum is one of the popular Python DateTime libraries to ease DateTime manipulation. It provides a cleaner and easier to use API. It simplifies the problem of complex date manipulations involving timezones which are not handled correctly in native datetime instances. It inherits from the standard datetime library but provides better functionality. So you can introduce Pendulums Datetime instances in projects which are already using built-in datetime class (except for the libraries that check the type of the objects by using the type function like sqlite3). from datetime import date from datetime import time from datetime import datetime ! pip install pendulum import pendulum dt1 = pendulum . datetime ( 2021 , 12 , 24 ) print ( dt1 ) #local() creates datetime instance with local timezone local = pendulum . local ( 2020 , 11 , 27 ) print ( local ) print ( local . timezone . name ) # Importing library import pendulum # Getting current UTC time utc_time = pendulum . now ( 'UTC' ) # Switching current timezone to # Kolkata timezone using in_timezone(). kolkata_time = utc_time . in_timezone ( 'Asia/Kolkata' ) print ( 'Current Date Time in Kolkata =' , kolkata_time ) # Generating Sydney timezone sydney_tz = pendulum . timezone ( 'Australia/Sydney' ) # Switching current timezone to # Sydney timezone using convert(). sydney_time = sydney_tz . convert ( utc_time ) print ( 'Current Date Time in Sydney =' , sydney_time ) 2021-12-24T00:00:00+00:00 2020-11-27T00:00:00+00:00 Etc/UTC Current Date Time in Kolkata = 2021-12-23T01:36:55.336688+05:30 Current Date Time in Sydney = 2021-12-23T07:06:55.336688+11:00 # Importing the library import pendulum # creating datetime instance dt = pendulum . datetime ( 2020 , 11 , 27 ) print ( dt ) # Manipulating datetime object using add() dt = dt . add ( years = 5 ) print ( dt ) # Manipulating datetime object using subtract() dt = dt . subtract ( months = 1 ) print ( dt ) # Similarly you can add or subtract # months,weeks,days,hours,minutes # individually or all at a time. dt = dt . add ( years = 3 , months = 2 , days = 6 , hours = 12 , minutes = 30 , seconds = 45 ) print ( dt ) 2020-11-27T00:00:00+00:00 2025-11-27T00:00:00+00:00 2025-10-27T00:00:00+00:00 2029-01-02T12:30:45+00:00 dt_here = pendulum . now () dt_there = dt_here . in_timezone ( \"Europe/London\" ) print ( dt_there ) 2021-12-22T20:27:11.672167+00:00 Formatting # Times and dates can be formatted using a set of predefined string # control codes now = datetime . now () # get the current date and time #### Date Formatting #### # %y/%Y - Year, %a/%A - weekday, %b/%B - month, %d - day of month print ( now . strftime ( \"The current year is: %Y\" )) # full year with century print ( now . strftime ( \" %a , %d %B, %y\" )) # abbreviated day, num, full month, abbreviated year # %c - locale's date and time, %x - locale's date, %X - locale's time print ( now . strftime ( \"Locale date and time: %c \" )) print ( now . strftime ( \"Locale date: %x \" )) print ( now . strftime ( \"Locale time: %X \" )) #### Time Formatting #### # %I/%H - 12/24 Hour, %M - minute, %S - second, %p - locale's AM/PM print ( now . strftime ( \"Current time: %I:%M:%S %p\" )) # 12-Hour:Minute:Second:AM print ( now . strftime ( \"24-hour time: %H:%M\" )) # 24-Hour:Minute The current year is: 2021 Mon, 19 July, 21 Locale date and time: Mon Jul 19 14:22:20 2021 Locale date: 07/19/21 Locale time: 14:22:20 Current time: 02:22:20 PM 24-hour time: 14:22 import pendulum # Creating new DateTime instance dt = pendulum . datetime ( 2021 , 12 , 27 , 12 , 30 , 15 ) print ( dt ) # Formatting date-time dt . to_day_datetime_string () formatted_str = dt . format ( 'dddd Do [of] MMMM YYYY HH:mm:ss A' , locale = 'fr' ) print ( formatted_str ) new_str = dt . strftime ( '%Y-%m- %d %H:%M:%S %Z%z' ) print ( new_str ) 2021-12-27T12:30:15+00:00 lundi 27e of d\u00e9cembre 2021 12:30:15 PM 2021-12-27 12:30:15 UTC+0000 import pendulum dt = pendulum . parse ( '1997-11-21T22:00:00' , tz = 'Asia/Calcutta' ) print ( dt ) # parsing of non standard string dt = pendulum . from_format ( '2020/11/21' , 'YYYY/MM/DD' ) print ( dt ) 1997-11-21T22:00:00+05:30 2020-11-21T00:00:00+00:00 Time Deltas from datetime import date from datetime import time from datetime import datetime from datetime import timedelta # construct a basic timedelta and print it print ( timedelta ( days = 365 , hours = 5 , minutes = 1 )) # print today's date now = datetime . now () print ( now ) print ( \"today is: \" , now ) # print today's date one year from now print ( \"one year from now it will be: \" , now + timedelta ( days = 365 )) # create a timedelta that uses more than one argument print ( \"in two weeks and 3 days it will be: \" , now + timedelta ( weeks = 2 , days = 3 )) # calculate the date 1 week ago, formatted as a string t = datetime . now () - timedelta ( weeks = 1 ) s = t . strftime ( \"%A %B %d , %Y\" ) print ( \"one week ago it was \" + s ) ### How many days until April Fools' Day? today = date . today () # get today's date afd = date ( today . year , 4 , 1 ) # get April Fool's for the same year # use date comparison to see if April Fool's has already gone for this year # if it has, use the replace() function to get the date for next year if afd < today : print ( \"April Fool's day already went by %d days ago\" % (( today - afd ) . days )) afd = afd . replace ( year = today . year + 1 ) # if so, get the date for next year # Now calculate the amount of time until April Fool's Day time_to_afd = afd - today print ( \"It's just\" , time_to_afd . days , \"days until next April Fools' Day!\" ) 365 days, 5:01:00 2021-07-19 14:28:46.250025 today is: 2021-07-19 14:28:46.250025 one year from now it will be: 2022-07-19 14:28:46.250025 in two weeks and 3 days it will be: 2021-08-05 14:28:46.250025 one week ago it was Monday July 12, 2021 April Fool's day already went by 109 days ago It's just 256 days until next April Fools' Day! import pendulum time_delta = pendulum . duration ( days = 2 , hours = 10 , years = 2 ) print ( time_delta ) # Date when i am writing this code is 2020-11-27. print ( 'future date =' , pendulum . now () + time_delta ) 2 years 2 days 10 hours future date = 2023-12-25T06:10:31.649124+00:00 dt9 = pendulum . datetime ( 2022 , 10 , 13 ) di = dt9 . diff_for_humans ( pendulum . today ()) print ( di ) 9 months after Calendar import calendar # create a plain text calendar c = calendar . TextCalendar ( calendar . SUNDAY ) str_te = c . formatmonth ( 2017 , 1 , 0 , 0 ) print ( str_te ) # loop over the days of a month # zeroes mean that the day of the week is in an overlapping month for i in c . itermonthdays ( 2017 , 8 ): print ( i ) # The Calendar module provides useful utilities for the given locale, # such as the names of days and months in both full and abbreviated forms for name in calendar . month_name : print ( name ) for day in calendar . day_name : print ( day ) # Calculate days based on a rule: For example, consider # a team meeting on the first Friday of every month. # To figure out what days that would be for each month, # we can use this script: print ( \"Team meetings will be on:\" ) for m in range ( 1 , 13 ): # returns an array of weeks that represent the month cal = calendar . monthcalendar ( 2017 , m ) # The first Friday has to be within the first two weeks weekone = cal [ 0 ] weektwo = cal [ 1 ] if weekone [ calendar . FRIDAY ] != 0 : meetday = weekone [ calendar . FRIDAY ] else : # if the first friday isn't in the first week, it must be in the second meetday = weektwo [ calendar . FRIDAY ] print ( \" %10s %2d \" % ( calendar . month_name [ m ], meetday )) January 2017 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 0 0 January February March April May June July August September October November December Monday Tuesday Wednesday Thursday Friday Saturday Sunday Team meetings will be on: January 6 February 3 March 3 April 7 May 5 June 2 July 7 August 4 September 1 October 6 November 3 December 1","title":"Dates and Time"},{"location":"lib/pydatetime/#datetime","text":"from datetime import date from datetime import time from datetime import datetime ## DATE OBJECTS # Get today's date from the simple today() method from the date class today = date . today () print ( \"Today's date is \" , today ) # print out the date's individual components print ( \"Date Components: \" , today . day , today . month , today . year ) # retrieve today's weekday (0=Monday, 6=Sunday) print ( \"Today's Weekday #: \" , today . weekday ()) days = [ \"monday\" , \"tuesday\" , \"wednesday\" , \"thursday\" , \"friday\" , \"saturday\" , \"sunday\" ] print ( \"Which is a \" + days [ today . weekday ()]) ## DATETIME OBJECTS # Get today's date from the datetime class today = datetime . now () print ( \"The current date and time is \" , today ) # Get the current time t = datetime . time ( datetime . now ()) print ( \"The current time is \" , t ) Today's date is 2021-12-22 Date Components: 22 12 2021 Today's Weekday #: 2 Which is a wednesday The current date and time is 2021-12-22 20:01:50.628110 The current time is 20:01:50.631578","title":"Datetime"},{"location":"lib/pydatetime/#pendulum","text":"The pendulum is one of the popular Python DateTime libraries to ease DateTime manipulation. It provides a cleaner and easier to use API. It simplifies the problem of complex date manipulations involving timezones which are not handled correctly in native datetime instances. It inherits from the standard datetime library but provides better functionality. So you can introduce Pendulums Datetime instances in projects which are already using built-in datetime class (except for the libraries that check the type of the objects by using the type function like sqlite3). from datetime import date from datetime import time from datetime import datetime ! pip install pendulum import pendulum dt1 = pendulum . datetime ( 2021 , 12 , 24 ) print ( dt1 ) #local() creates datetime instance with local timezone local = pendulum . local ( 2020 , 11 , 27 ) print ( local ) print ( local . timezone . name ) # Importing library import pendulum # Getting current UTC time utc_time = pendulum . now ( 'UTC' ) # Switching current timezone to # Kolkata timezone using in_timezone(). kolkata_time = utc_time . in_timezone ( 'Asia/Kolkata' ) print ( 'Current Date Time in Kolkata =' , kolkata_time ) # Generating Sydney timezone sydney_tz = pendulum . timezone ( 'Australia/Sydney' ) # Switching current timezone to # Sydney timezone using convert(). sydney_time = sydney_tz . convert ( utc_time ) print ( 'Current Date Time in Sydney =' , sydney_time ) 2021-12-24T00:00:00+00:00 2020-11-27T00:00:00+00:00 Etc/UTC Current Date Time in Kolkata = 2021-12-23T01:36:55.336688+05:30 Current Date Time in Sydney = 2021-12-23T07:06:55.336688+11:00 # Importing the library import pendulum # creating datetime instance dt = pendulum . datetime ( 2020 , 11 , 27 ) print ( dt ) # Manipulating datetime object using add() dt = dt . add ( years = 5 ) print ( dt ) # Manipulating datetime object using subtract() dt = dt . subtract ( months = 1 ) print ( dt ) # Similarly you can add or subtract # months,weeks,days,hours,minutes # individually or all at a time. dt = dt . add ( years = 3 , months = 2 , days = 6 , hours = 12 , minutes = 30 , seconds = 45 ) print ( dt ) 2020-11-27T00:00:00+00:00 2025-11-27T00:00:00+00:00 2025-10-27T00:00:00+00:00 2029-01-02T12:30:45+00:00 dt_here = pendulum . now () dt_there = dt_here . in_timezone ( \"Europe/London\" ) print ( dt_there ) 2021-12-22T20:27:11.672167+00:00","title":"Pendulum"},{"location":"lib/pydatetime/#formatting","text":"# Times and dates can be formatted using a set of predefined string # control codes now = datetime . now () # get the current date and time #### Date Formatting #### # %y/%Y - Year, %a/%A - weekday, %b/%B - month, %d - day of month print ( now . strftime ( \"The current year is: %Y\" )) # full year with century print ( now . strftime ( \" %a , %d %B, %y\" )) # abbreviated day, num, full month, abbreviated year # %c - locale's date and time, %x - locale's date, %X - locale's time print ( now . strftime ( \"Locale date and time: %c \" )) print ( now . strftime ( \"Locale date: %x \" )) print ( now . strftime ( \"Locale time: %X \" )) #### Time Formatting #### # %I/%H - 12/24 Hour, %M - minute, %S - second, %p - locale's AM/PM print ( now . strftime ( \"Current time: %I:%M:%S %p\" )) # 12-Hour:Minute:Second:AM print ( now . strftime ( \"24-hour time: %H:%M\" )) # 24-Hour:Minute The current year is: 2021 Mon, 19 July, 21 Locale date and time: Mon Jul 19 14:22:20 2021 Locale date: 07/19/21 Locale time: 14:22:20 Current time: 02:22:20 PM 24-hour time: 14:22 import pendulum # Creating new DateTime instance dt = pendulum . datetime ( 2021 , 12 , 27 , 12 , 30 , 15 ) print ( dt ) # Formatting date-time dt . to_day_datetime_string () formatted_str = dt . format ( 'dddd Do [of] MMMM YYYY HH:mm:ss A' , locale = 'fr' ) print ( formatted_str ) new_str = dt . strftime ( '%Y-%m- %d %H:%M:%S %Z%z' ) print ( new_str ) 2021-12-27T12:30:15+00:00 lundi 27e of d\u00e9cembre 2021 12:30:15 PM 2021-12-27 12:30:15 UTC+0000 import pendulum dt = pendulum . parse ( '1997-11-21T22:00:00' , tz = 'Asia/Calcutta' ) print ( dt ) # parsing of non standard string dt = pendulum . from_format ( '2020/11/21' , 'YYYY/MM/DD' ) print ( dt ) 1997-11-21T22:00:00+05:30 2020-11-21T00:00:00+00:00","title":"Formatting"},{"location":"lib/pydatetime/#time-deltas","text":"from datetime import date from datetime import time from datetime import datetime from datetime import timedelta # construct a basic timedelta and print it print ( timedelta ( days = 365 , hours = 5 , minutes = 1 )) # print today's date now = datetime . now () print ( now ) print ( \"today is: \" , now ) # print today's date one year from now print ( \"one year from now it will be: \" , now + timedelta ( days = 365 )) # create a timedelta that uses more than one argument print ( \"in two weeks and 3 days it will be: \" , now + timedelta ( weeks = 2 , days = 3 )) # calculate the date 1 week ago, formatted as a string t = datetime . now () - timedelta ( weeks = 1 ) s = t . strftime ( \"%A %B %d , %Y\" ) print ( \"one week ago it was \" + s ) ### How many days until April Fools' Day? today = date . today () # get today's date afd = date ( today . year , 4 , 1 ) # get April Fool's for the same year # use date comparison to see if April Fool's has already gone for this year # if it has, use the replace() function to get the date for next year if afd < today : print ( \"April Fool's day already went by %d days ago\" % (( today - afd ) . days )) afd = afd . replace ( year = today . year + 1 ) # if so, get the date for next year # Now calculate the amount of time until April Fool's Day time_to_afd = afd - today print ( \"It's just\" , time_to_afd . days , \"days until next April Fools' Day!\" ) 365 days, 5:01:00 2021-07-19 14:28:46.250025 today is: 2021-07-19 14:28:46.250025 one year from now it will be: 2022-07-19 14:28:46.250025 in two weeks and 3 days it will be: 2021-08-05 14:28:46.250025 one week ago it was Monday July 12, 2021 April Fool's day already went by 109 days ago It's just 256 days until next April Fools' Day! import pendulum time_delta = pendulum . duration ( days = 2 , hours = 10 , years = 2 ) print ( time_delta ) # Date when i am writing this code is 2020-11-27. print ( 'future date =' , pendulum . now () + time_delta ) 2 years 2 days 10 hours future date = 2023-12-25T06:10:31.649124+00:00 dt9 = pendulum . datetime ( 2022 , 10 , 13 ) di = dt9 . diff_for_humans ( pendulum . today ()) print ( di ) 9 months after","title":"Time Deltas"},{"location":"lib/pydatetime/#calendar","text":"import calendar # create a plain text calendar c = calendar . TextCalendar ( calendar . SUNDAY ) str_te = c . formatmonth ( 2017 , 1 , 0 , 0 ) print ( str_te ) # loop over the days of a month # zeroes mean that the day of the week is in an overlapping month for i in c . itermonthdays ( 2017 , 8 ): print ( i ) # The Calendar module provides useful utilities for the given locale, # such as the names of days and months in both full and abbreviated forms for name in calendar . month_name : print ( name ) for day in calendar . day_name : print ( day ) # Calculate days based on a rule: For example, consider # a team meeting on the first Friday of every month. # To figure out what days that would be for each month, # we can use this script: print ( \"Team meetings will be on:\" ) for m in range ( 1 , 13 ): # returns an array of weeks that represent the month cal = calendar . monthcalendar ( 2017 , m ) # The first Friday has to be within the first two weeks weekone = cal [ 0 ] weektwo = cal [ 1 ] if weekone [ calendar . FRIDAY ] != 0 : meetday = weekone [ calendar . FRIDAY ] else : # if the first friday isn't in the first week, it must be in the second meetday = weektwo [ calendar . FRIDAY ] print ( \" %10s %2d \" % ( calendar . month_name [ m ], meetday )) January 2017 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 0 0 January February March April May June July August September October November December Monday Tuesday Wednesday Thursday Friday Saturday Sunday Team meetings will be on: January 6 February 3 March 3 April 7 May 5 June 2 July 7 August 4 September 1 October 6 November 3 December 1","title":"Calendar"},{"location":"lib/pylog/","text":"Logging is a means of tracking events that happen when some software runs. Logging is important for software developing, debugging and running. If you don\u2019t have any logging record and your program crashes, there are very little chances that you detect the cause of the problem. And if you detect the cause, it will consume a lot of time. With logging, you can leave a trail of breadcrumbs so that if something goes wrong, we can determine the cause of the problem. Python has a built-in module logging which allows writing status messages to a file or any other output streams. The Basics Basics of using the logging module to record the events in a file are very simple. For that, simply import the module from the library. Create and configure the logger. It can have several parameters. But importantly, pass the name of the file in which you want to record the events. Here the format of the logger can also be set. By default, the file works in append mode but we can change that to write mode if required. Also, the level of the logger can be set which acts as the threshold for tracking based on the numeric values assigned to each level. There are several attributes which can be passed as parameters. The list of all those parameters is given in Python Library. The user can choose the required attribute according to the requirement. After that, create an object and use the various methods as shown in the example. #importing module import logging #Create and configure logger logging . basicConfig ( filename = \"newfile.log\" , format = ' %(asctime)s %(message)s ' , filemode = 'w' ) #Creating an object logger = logging . getLogger () #Setting the threshold of logger to DEBUG logger . setLevel ( logging . DEBUG ) #Test messages logger . debug ( \"Harmless debug Message\" ) logger . info ( \"Just an information\" ) logger . warning ( \"Its a Warning\" ) logger . error ( \"Did you try to divide by zero\" ) logger . critical ( \"Internet is down\" ) import logging extData = { 'user' : 'caal@example.com' } def anotherFunction (): logging . debug ( \"This is a debug-level log message\" , extra = extData ) def main (): # set the output file and debug level, and # use a custom formatting specification fmtStr = \" %(asctime)s : %(levelname)s : %(funcName)s Line: %(lineno)d User: %(user)s %(message)s \" dateStr = \"%m/ %d /%Y %I:%M:%S %p\" logging . basicConfig ( filename = \"output.log\" , level = logging . DEBUG , format = fmtStr , datefmt = dateStr ) logging . info ( \"This is an info-level log message\" , extra = extData ) logging . warning ( \"This is a warning-level message\" , extra = extData ) anotherFunction () if __name__ == \"__main__\" : main ()","title":"Logging"},{"location":"lib/pylog/#the-basics","text":"Basics of using the logging module to record the events in a file are very simple. For that, simply import the module from the library. Create and configure the logger. It can have several parameters. But importantly, pass the name of the file in which you want to record the events. Here the format of the logger can also be set. By default, the file works in append mode but we can change that to write mode if required. Also, the level of the logger can be set which acts as the threshold for tracking based on the numeric values assigned to each level. There are several attributes which can be passed as parameters. The list of all those parameters is given in Python Library. The user can choose the required attribute according to the requirement. After that, create an object and use the various methods as shown in the example. #importing module import logging #Create and configure logger logging . basicConfig ( filename = \"newfile.log\" , format = ' %(asctime)s %(message)s ' , filemode = 'w' ) #Creating an object logger = logging . getLogger () #Setting the threshold of logger to DEBUG logger . setLevel ( logging . DEBUG ) #Test messages logger . debug ( \"Harmless debug Message\" ) logger . info ( \"Just an information\" ) logger . warning ( \"Its a Warning\" ) logger . error ( \"Did you try to divide by zero\" ) logger . critical ( \"Internet is down\" ) import logging extData = { 'user' : 'caal@example.com' } def anotherFunction (): logging . debug ( \"This is a debug-level log message\" , extra = extData ) def main (): # set the output file and debug level, and # use a custom formatting specification fmtStr = \" %(asctime)s : %(levelname)s : %(funcName)s Line: %(lineno)d User: %(user)s %(message)s \" dateStr = \"%m/ %d /%Y %I:%M:%S %p\" logging . basicConfig ( filename = \"output.log\" , level = logging . DEBUG , format = fmtStr , datefmt = dateStr ) logging . info ( \"This is an info-level log message\" , extra = extData ) logging . warning ( \"This is a warning-level message\" , extra = extData ) anotherFunction () if __name__ == \"__main__\" : main ()","title":"The Basics"}]}